{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages, which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission if necessary. \n",
    "\n",
    "> **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the iPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission. \n",
    "\n",
    "In addition to implementing code, there is a writeup to complete. The writeup should be completed in a separate file, which can be either a markdown file or a pdf document. There is a [write up template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) that can be used to guide the writing process. Completing the code template and writeup template will cover all of the [rubric points](https://review.udacity.com/#!/rubrics/481/view) for this project.\n",
    "\n",
    "The [rubric](https://review.udacity.com/#!/rubrics/481/view) contains \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. The stand out suggestions are optional. If you decide to pursue the \"stand out suggestions\", you can include the code in this Ipython notebook and also discuss the results in the writeup file.\n",
    "\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "#import tensorflow as tf\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = 'traffic-signs-data/train.p'\n",
    "validation_file='traffic-signs-data/valid.p'\n",
    "testing_file = 'traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allay\\Anaconda3\\envs\\selfdriving\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES**\n",
    "\n",
    "Complete the basic data summary below. Use python, numpy and/or pandas methods to calculate the data summary rather than hard coding the results. For example, the [pandas shape method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shape.html) might be useful for calculating some of the summary results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42]\n"
     ]
    }
   ],
   "source": [
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "import numpy as np\n",
    "# TODO: Number of training examples\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "# TODO: Number of validation examples\n",
    "n_validation = X_valid.shape[0]\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = X_train.shape[1:]\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_validation)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include an exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the German Traffic Signs Dataset using the pickled file(s). This is open ended, suggestions include: plotting traffic sign images, plotting the count of each sign, etc. \n",
    "\n",
    "The [Matplotlib](http://matplotlib.org/) [examples](http://matplotlib.org/examples/index.html) and [gallery](http://matplotlib.org/gallery.html) pages are a great resource for doing visualizations in Python.\n",
    "\n",
    "**NOTE:** It's recommended you start with something simple first. If you wish to do more, come back to it after you've completed the rest of the sections. It can be interesting to look at the distribution of classes in the training, validation and test set. Is the distribution the same? Are there more examples of some classes than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Index:  8400\n",
      "Training Label:  4\n",
      "Training Image: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADFCAYAAAARxr1AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x238e33c44e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(image.reshape((32,32,3)))\n",
    "print('Training Index: ', index)\n",
    "print('Training Label: ',y_train[index])\n",
    "print('Training Image: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAE/CAYAAADlpzo+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x238e5489828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data distrbution\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 5]\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1,43])\n",
    "\n",
    "plt.bar(n_classes, counts, tick_label=n_classes, width=0.8, align='center')\n",
    "plt.title('Distribution of Training Data across Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3EAAAE/CAYAAADouUp5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIeWJgfTiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x238e563ec18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_classes, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 5]\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1,43])\n",
    "\n",
    "plt.bar(n_classes, counts, tick_label=n_classes, width=0.8, align='center')\n",
    "plt.title('Distribution of Testing Data across Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimally, the image data should be normalized so that the data has mean zero and equal variance. For image data, `(pixel - 128)/ 128` is a quick way to approximately normalize the data and can be used in this project. \n",
    "\n",
    "Other pre-processing steps are optional. You can try different techniques to see if it improves performance. \n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_features_normal = False\n",
    "is_labels_encod = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Grayscale Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799, 32, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rgb2gray(rgb):\n",
    "  return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "train_features = np.array([rgb2gray(feature) for feature in X_train])\n",
    "test_features = np.array([rgb2gray(feature) for feature in X_test])\n",
    "valid_features = np.array([rgb2gray(feature) for feature in X_valid])\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA08AAAFgCAYAAABjW0LQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvdn2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x238e56fb748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X_train[50].reshape((32,32,3)))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(train_features[50], cmap= plt.get_cmap('gray'))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Preprocess the data here. It is required to normalize the data. Other preprocessing steps could include \n",
    "\n",
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    Xmin = np.min(image_data) #0\n",
    "    Xmax = np.max(image_data) #255\n",
    "    a = 0.1\n",
    "    b = 0.9\n",
    "    #print(\"Xmin:\", Xmin, \"Xmax:\", Xmax)\n",
    "    return a + (((image_data-Xmin)*(b-a))/(Xmax- Xmin))\n",
    "\n",
    "if not is_features_normal:\n",
    "    train_features = normalize_grayscale(train_features)\n",
    "    valid_features = normalize_grayscale(valid_features)\n",
    "    test_features = normalize_grayscale(test_features)\n",
    "    is_features_normal = True\n",
    "### converting to grayscale, etc.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2388002f0f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAEyCAYAAACbGke8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlf8DUYcOxCkOfdsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x238e5a35ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_features[50], cmap= plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "if not is_labels_encod:\n",
    "    # Turn labels into numbers and apply One-Hot Encoding\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(y_train)\n",
    "    train_labels = encoder.transform(y_train)\n",
    "    valid_labels = encoder.transform(y_valid)\n",
    "    test_labels = encoder.transform(y_test)\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    train_labels = train_labels.astype(np.float32)\n",
    "    test_labels = test_labels.astype(np.float32)\n",
    "    is_labels_encod = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[50], train_labels[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TESTING #### \n",
    "### NOT USING LABEL BINARIZER ######\n",
    "# train_labels = y_train.copy()\n",
    "# valid_labels = y_valid.copy()\n",
    "# test_labels = y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADFCAYAAAARxr1AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x238e557b5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, len(X_train))\n",
    "image = train_features[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(image.reshape((32,32)),cmap='gray')\n",
    "print(train_labels[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32))\n",
    "y = tf.placeholder(tf.int32, (None, 43))\n",
    "#one_hot_y = tf.one_hot(y, 43)\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and initialize model parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "#import tensorflow as tf\n",
    "# Store layers weight & bias\n",
    "mean_wt = 0 \n",
    "stanDev = 0.1\n",
    "\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean=mean_wt, stddev=stanDev)),\n",
    "    'wc2': tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mean_wt, stddev=stanDev)),\n",
    "    'fc1': tf.Variable(tf.truncated_normal(shape=(400, 200), mean=mean_wt, stddev=stanDev)),\n",
    "    'fc2': tf.Variable(tf.truncated_normal(shape=(200, 100), mean=mean_wt, stddev=stanDev)),\n",
    "    'out': tf.Variable(tf.truncated_normal(shape=(100, len(n_classes)), mean=mean_wt, stddev=stanDev))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.zeros(6)),\n",
    "    'bc2': tf.Variable(tf.zeros(16)),\n",
    "    'bf1': tf.Variable(tf.zeros(200)),\n",
    "    'bf2': tf.Variable(tf.zeros(100)),\n",
    "    'out': tf.Variable(tf.zeros(len(n_classes)))\n",
    "}\n",
    "\n",
    "strides ={\n",
    "    'conv1': [1,1,1,1],\n",
    "    'maxPool1':[1,2,2,1],\n",
    "    'conv2' : [1,1,1,1],\n",
    "    'maxPool2':[1,2,2,1]\n",
    "}\n",
    "\n",
    "filters ={\n",
    "    'maxPool1': [1,2,2,1],\n",
    "    'maxPool2': [1,2,2,1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LeNet(x, weights, biases, strides, filters):\n",
    "    x = tf.reshape(x,(-1,32,32,1))\n",
    "    ### Layer 1 ###\n",
    "    # convolution\n",
    "    conv_layer1 = tf.nn.conv2d(x, weights['wc1'], strides=strides['conv1'],padding='VALID') + biases['bc1']\n",
    "    #print(tf.shape(conv_layer1))\n",
    "    # activation\n",
    "    conv_layer1 = tf.nn.relu(conv_layer1)\n",
    "    # pooling\n",
    "    conv_layer1 = tf.nn.max_pool(conv_layer1, ksize=filters['maxPool1'],strides=strides['maxPool1'],padding='VALID')\n",
    "    ### Layer 2 ###\n",
    "    # convolution\n",
    "    conv_layer2 = tf.nn.conv2d(conv_layer1, weights['wc2'], strides=strides['conv2'], padding='VALID') + biases['bc2']\n",
    "    # activation\n",
    "    conv_layer2 = tf.nn.relu(conv_layer2)\n",
    "    # pooling\n",
    "    conv_layer2 = tf.nn.max_pool(conv_layer2, ksize=filters['maxPool2'],strides=strides['maxPool2'],padding='VALID')\n",
    "    ### Layer 3 ###\n",
    "    # flatten\n",
    "    flatten = tf.contrib.layers.flatten(conv_layer2)\n",
    "    ### Layer 4 ###\n",
    "    # fully connected\n",
    "    fc1 = tf.matmul(flatten, weights['fc1']) + biases['bf1']\n",
    "    # activation\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    ### Layer 5 ###\n",
    "    # fully connected\n",
    "    fc2 = tf.matmul(fc1, weights['fc2']) + biases['bf2']\n",
    "    # activation\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    ### Layer 6 ###\n",
    "     # fully connected\n",
    "    logits = tf.matmul(fc2, weights['out']) + biases['out']\n",
    "    \n",
    "    return logits, weights['fc1'], weights['fc2'], weights['out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Allay\\Anaconda3\\envs\\selfdriving\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-20-44bb62de3ee2>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "logits, fc1_w, fc2_w, fc3_w = LeNet(x, weights, biases, strides, filters)\n",
    "# Calculate loss\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "# Regularize\n",
    "beta = 0.01\n",
    "regularizer = tf.nn.l2_loss(fc1_w) + tf.nn.l2_loss(fc2_w) + tf.nn.l2_loss(fc3_w)\n",
    "cost = tf.reduce_mean(loss_operation + beta * regularizer)\n",
    "\n",
    "# Define loss and optimizer\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_operation = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, batch_size):\n",
    "        batch_x, batch_y = X_data[offset:offset+batch_size], y_data[offset:offset+batch_size]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "#n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "#dropout = 0.75  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "Epoch  1, Batch   1 -Loss:     7.6940 Training Accuracy: 0.024081 Validation Accuracy: 0.040590\n",
      "Epoch  1, Batch   2 -Loss:     7.6245 Training Accuracy: 0.052042 Validation Accuracy: 0.057143\n",
      "Epoch  1, Batch   3 -Loss:     7.5491 Training Accuracy: 0.043622 Validation Accuracy: 0.042857\n",
      "Epoch  1, Batch   4 -Loss:     7.4742 Training Accuracy: 0.043622 Validation Accuracy: 0.039456\n",
      "Epoch  1, Batch   5 -Loss:     7.4025 Training Accuracy: 0.046927 Validation Accuracy: 0.047846\n",
      "Epoch  1, Batch   6 -Loss:     7.3283 Training Accuracy: 0.048047 Validation Accuracy: 0.047846\n",
      "Epoch  1, Batch   7 -Loss:     7.2707 Training Accuracy: 0.048565 Validation Accuracy: 0.047166\n",
      "Epoch  1, Batch   8 -Loss:     7.1868 Training Accuracy: 0.048392 Validation Accuracy: 0.048073\n",
      "Epoch  1, Batch   9 -Loss:     7.1318 Training Accuracy: 0.050777 Validation Accuracy: 0.052381\n",
      "Epoch  1, Batch  10 -Loss:     7.0618 Training Accuracy: 0.053335 Validation Accuracy: 0.063719\n",
      "Epoch  1, Batch  11 -Loss:     6.9822 Training Accuracy: 0.053019 Validation Accuracy: 0.067120\n",
      "Epoch  1, Batch  12 -Loss:     6.9091 Training Accuracy: 0.053364 Validation Accuracy: 0.068481\n",
      "Epoch  1, Batch  13 -Loss:     6.8633 Training Accuracy: 0.055433 Validation Accuracy: 0.065986\n",
      "Epoch  1, Batch  14 -Loss:     6.7756 Training Accuracy: 0.061668 Validation Accuracy: 0.061905\n",
      "Epoch  1, Batch  15 -Loss:     6.7109 Training Accuracy: 0.064657 Validation Accuracy: 0.063039\n",
      "Epoch  1, Batch  16 -Loss:     6.6560 Training Accuracy: 0.060088 Validation Accuracy: 0.064626\n",
      "Epoch  1, Batch  17 -Loss:     6.5873 Training Accuracy: 0.060778 Validation Accuracy: 0.065760\n",
      "Epoch  1, Batch  18 -Loss:     6.4638 Training Accuracy: 0.058364 Validation Accuracy: 0.062585\n",
      "Epoch  1, Batch  19 -Loss:     6.4281 Training Accuracy: 0.061381 Validation Accuracy: 0.056689\n",
      "Epoch  1, Batch  20 -Loss:     6.3149 Training Accuracy: 0.057128 Validation Accuracy: 0.054649\n",
      "Epoch  1, Batch  21 -Loss:     6.2421 Training Accuracy: 0.056898 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  22 -Loss:     6.2064 Training Accuracy: 0.056898 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  23 -Loss:     6.1082 Training Accuracy: 0.056898 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  24 -Loss:     6.0812 Training Accuracy: 0.056898 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  25 -Loss:     5.9736 Training Accuracy: 0.056898 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  26 -Loss:     5.8585 Training Accuracy: 0.059599 Validation Accuracy: 0.059184\n",
      "Epoch  1, Batch  27 -Loss:     5.9319 Training Accuracy: 0.081123 Validation Accuracy: 0.077324\n",
      "Epoch  1, Batch  28 -Loss:     5.8442 Training Accuracy: 0.057789 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  29 -Loss:     5.9513 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  30 -Loss:     5.7737 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  31 -Loss:     5.7040 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  32 -Loss:     5.6790 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  33 -Loss:     5.6402 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  34 -Loss:     5.6487 Training Accuracy: 0.057703 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  35 -Loss:     5.5072 Training Accuracy: 0.054542 Validation Accuracy: 0.057823\n",
      "Epoch  1, Batch  36 -Loss:     5.5131 Training Accuracy: 0.051093 Validation Accuracy: 0.048299\n",
      "Epoch  1, Batch  37 -Loss:     5.5223 Training Accuracy: 0.051007 Validation Accuracy: 0.047619\n",
      "Epoch  1, Batch  38 -Loss:     5.4048 Training Accuracy: 0.074140 Validation Accuracy: 0.067800\n",
      "Epoch  1, Batch  39 -Loss:     5.5174 Training Accuracy: 0.065519 Validation Accuracy: 0.074150\n",
      "Epoch  1, Batch  40 -Loss:     5.3358 Training Accuracy: 0.055059 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  41 -Loss:     5.2542 Training Accuracy: 0.054829 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  42 -Loss:     5.2693 Training Accuracy: 0.054513 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  43 -Loss:     5.2441 Training Accuracy: 0.054341 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  44 -Loss:     5.2272 Training Accuracy: 0.055117 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  45 -Loss:     5.1566 Training Accuracy: 0.055576 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  46 -Loss:     5.1366 Training Accuracy: 0.063508 Validation Accuracy: 0.068254\n",
      "Epoch  1, Batch  47 -Loss:     5.1085 Training Accuracy: 0.078278 Validation Accuracy: 0.080045\n",
      "Epoch  1, Batch  48 -Loss:     5.2342 Training Accuracy: 0.079830 Validation Accuracy: 0.073243\n",
      "Epoch  1, Batch  49 -Loss:     5.1918 Training Accuracy: 0.058105 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  50 -Loss:     5.1368 Training Accuracy: 0.057789 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  51 -Loss:     5.1149 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  52 -Loss:     5.1719 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  53 -Loss:     4.9656 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  54 -Loss:     5.0287 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  55 -Loss:     4.9323 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  56 -Loss:     4.9715 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  57 -Loss:     4.9175 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  58 -Loss:     4.8868 Training Accuracy: 0.057760 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  59 -Loss:     4.8643 Training Accuracy: 0.057789 Validation Accuracy: 0.053968\n",
      "Epoch  1, Batch  60 -Loss:     4.9521 Training Accuracy: 0.058680 Validation Accuracy: 0.052608\n",
      "Epoch  1, Batch  61 -Loss:     4.7469 Training Accuracy: 0.060806 Validation Accuracy: 0.055329\n",
      "Epoch  1, Batch  62 -Loss:     4.7736 Training Accuracy: 0.068450 Validation Accuracy: 0.062812\n",
      "Epoch  1, Batch  63 -Loss:     4.7602 Training Accuracy: 0.071439 Validation Accuracy: 0.065533\n",
      "Epoch  1, Batch  64 -Loss:     4.7667 Training Accuracy: 0.067013 Validation Accuracy: 0.062812\n",
      "Epoch  1, Batch  65 -Loss:     4.7251 Training Accuracy: 0.081209 Validation Accuracy: 0.075057\n",
      "Epoch  1, Batch  66 -Loss:     4.6307 Training Accuracy: 0.089830 Validation Accuracy: 0.078458\n",
      "Epoch  1, Batch  67 -Loss:     4.6789 Training Accuracy: 0.086813 Validation Accuracy: 0.079592\n",
      "Epoch  1, Batch  68 -Loss:     4.7488 Training Accuracy: 0.080089 Validation Accuracy: 0.074603\n",
      "Epoch  1, Batch  69 -Loss:     4.6249 Training Accuracy: 0.089083 Validation Accuracy: 0.080726\n",
      "Epoch  1, Batch  70 -Loss:     4.5462 Training Accuracy: 0.088709 Validation Accuracy: 0.080272\n",
      "Epoch  1, Batch  71 -Loss:     4.6739 Training Accuracy: 0.093106 Validation Accuracy: 0.081859\n",
      "Epoch  1, Batch  72 -Loss:     4.4577 Training Accuracy: 0.093250 Validation Accuracy: 0.092063\n",
      "Epoch  1, Batch  73 -Loss:     4.5426 Training Accuracy: 0.072416 Validation Accuracy: 0.069615\n",
      "Epoch  1, Batch  74 -Loss:     4.5551 Training Accuracy: 0.061065 Validation Accuracy: 0.065306\n",
      "Epoch  1, Batch  75 -Loss:     4.5878 Training Accuracy: 0.076525 Validation Accuracy: 0.075057\n",
      "Epoch  1, Batch  76 -Loss:     4.6147 Training Accuracy: 0.093537 Validation Accuracy: 0.094558\n",
      "Epoch  1, Batch  77 -Loss:     4.5478 Training Accuracy: 0.098020 Validation Accuracy: 0.093878\n",
      "Epoch  1, Batch  78 -Loss:     4.4494 Training Accuracy: 0.111871 Validation Accuracy: 0.109297\n",
      "Epoch  1, Batch  79 -Loss:     4.4403 Training Accuracy: 0.098566 Validation Accuracy: 0.096825\n",
      "Epoch  1, Batch  80 -Loss:     4.3994 Training Accuracy: 0.062732 Validation Accuracy: 0.062132\n",
      "Epoch  1, Batch  81 -Loss:     4.4318 Training Accuracy: 0.057157 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  82 -Loss:     4.4695 Training Accuracy: 0.056898 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  83 -Loss:     4.3602 Training Accuracy: 0.056898 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  84 -Loss:     4.2393 Training Accuracy: 0.056898 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  85 -Loss:     4.2364 Training Accuracy: 0.056898 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  86 -Loss:     4.2848 Training Accuracy: 0.056898 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  87 -Loss:     4.3354 Training Accuracy: 0.056898 Validation Accuracy: 0.054422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch  88 -Loss:     4.2522 Training Accuracy: 0.057128 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch  89 -Loss:     4.2384 Training Accuracy: 0.069916 Validation Accuracy: 0.069161\n",
      "Epoch  1, Batch  90 -Loss:     4.3117 Training Accuracy: 0.090261 Validation Accuracy: 0.087302\n",
      "Epoch  1, Batch  91 -Loss:     4.2758 Training Accuracy: 0.086755 Validation Accuracy: 0.090249\n",
      "Epoch  1, Batch  92 -Loss:     4.2848 Training Accuracy: 0.066611 Validation Accuracy: 0.068027\n",
      "Epoch  1, Batch  93 -Loss:     4.1069 Training Accuracy: 0.057588 Validation Accuracy: 0.057143\n",
      "Epoch  1, Batch  94 -Loss:     4.0991 Training Accuracy: 0.060059 Validation Accuracy: 0.062132\n",
      "Epoch  1, Batch  95 -Loss:     4.1970 Training Accuracy: 0.069715 Validation Accuracy: 0.081633\n",
      "Epoch  1, Batch  96 -Loss:     4.1154 Training Accuracy: 0.082876 Validation Accuracy: 0.104989\n",
      "Epoch  1, Batch  97 -Loss:     4.1640 Training Accuracy: 0.088020 Validation Accuracy: 0.106576\n",
      "Epoch  1, Batch  98 -Loss:     4.1255 Training Accuracy: 0.093164 Validation Accuracy: 0.109977\n",
      "Epoch  1, Batch  99 -Loss:     4.1200 Training Accuracy: 0.080893 Validation Accuracy: 0.093197\n",
      "Epoch  1, Batch 100 -Loss:     4.1011 Training Accuracy: 0.067042 Validation Accuracy: 0.071655\n",
      "Epoch  1, Batch 101 -Loss:     4.0916 Training Accuracy: 0.066927 Validation Accuracy: 0.071655\n",
      "Epoch  1, Batch 102 -Loss:     4.1178 Training Accuracy: 0.073939 Validation Accuracy: 0.073923\n",
      "Epoch  1, Batch 103 -Loss:     4.0457 Training Accuracy: 0.075290 Validation Accuracy: 0.075057\n",
      "Epoch  1, Batch 104 -Loss:     4.1300 Training Accuracy: 0.075807 Validation Accuracy: 0.075057\n",
      "Epoch  1, Batch 105 -Loss:     4.0543 Training Accuracy: 0.069082 Validation Accuracy: 0.071202\n",
      "Epoch  1, Batch 106 -Loss:     4.0071 Training Accuracy: 0.058019 Validation Accuracy: 0.063039\n",
      "Epoch  1, Batch 107 -Loss:     3.9236 Training Accuracy: 0.055921 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch 108 -Loss:     4.0810 Training Accuracy: 0.055777 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch 109 -Loss:     4.0378 Training Accuracy: 0.055490 Validation Accuracy: 0.054422\n",
      "Epoch  1, Batch 110 -Loss:     3.9636 Training Accuracy: 0.083451 Validation Accuracy: 0.089116\n",
      "Epoch  1, Batch 111 -Loss:     4.0071 Training Accuracy: 0.105060 Validation Accuracy: 0.113605\n",
      "Epoch  1, Batch 112 -Loss:     3.9362 Training Accuracy: 0.086439 Validation Accuracy: 0.085261\n",
      "Epoch  1, Batch 113 -Loss:     3.9987 Training Accuracy: 0.077560 Validation Accuracy: 0.076417\n",
      "Epoch  1, Batch 114 -Loss:     3.8861 Training Accuracy: 0.094141 Validation Accuracy: 0.097959\n",
      "Epoch  1, Batch 115 -Loss:     3.9238 Training Accuracy: 0.101124 Validation Accuracy: 0.105215\n",
      "Epoch  1, Batch 116 -Loss:     4.0082 Training Accuracy: 0.104716 Validation Accuracy: 0.107029\n",
      "Epoch  1, Batch 117 -Loss:     3.9881 Training Accuracy: 0.099371 Validation Accuracy: 0.101361\n",
      "Epoch  1, Batch 118 -Loss:     3.8963 Training Accuracy: 0.103825 Validation Accuracy: 0.102721\n",
      "Epoch  1, Batch 119 -Loss:     3.8817 Training Accuracy: 0.117561 Validation Accuracy: 0.112245\n",
      "Epoch  1, Batch 120 -Loss:     3.8776 Training Accuracy: 0.155493 Validation Accuracy: 0.142630\n",
      "Epoch  1, Batch 121 -Loss:     3.7744 Training Accuracy: 0.134113 Validation Accuracy: 0.132426\n",
      "Epoch  1, Batch 122 -Loss:     3.8813 Training Accuracy: 0.094773 Validation Accuracy: 0.095238\n",
      "Epoch  1, Batch 123 -Loss:     3.9480 Training Accuracy: 0.071123 Validation Accuracy: 0.068254\n",
      "Epoch  1, Batch 124 -Loss:     3.8707 Training Accuracy: 0.069715 Validation Accuracy: 0.064172\n",
      "Epoch  1, Batch 125 -Loss:     3.7908 Training Accuracy: 0.082790 Validation Accuracy: 0.079819\n",
      "Epoch  1, Batch 126 -Loss:     3.8927 Training Accuracy: 0.099917 Validation Accuracy: 0.093878\n",
      "Epoch  1, Batch 127 -Loss:     3.6687 Training Accuracy: 0.122733 Validation Accuracy: 0.107483\n",
      "Epoch  1, Batch 128 -Loss:     3.7730 Training Accuracy: 0.127992 Validation Accuracy: 0.122902\n",
      "Epoch  1, Batch 129 -Loss:     3.8148 Training Accuracy: 0.120923 Validation Accuracy: 0.117687\n",
      "Epoch  1, Batch 130 -Loss:     3.7489 Training Accuracy: 0.118049 Validation Accuracy: 0.114966\n",
      "Epoch  1, Batch 131 -Loss:     3.8380 Training Accuracy: 0.121699 Validation Accuracy: 0.121995\n",
      "Epoch  1, Batch 132 -Loss:     3.6846 Training Accuracy: 0.133739 Validation Accuracy: 0.131519\n",
      "Epoch  1, Batch 133 -Loss:     3.8017 Training Accuracy: 0.163597 Validation Accuracy: 0.153968\n",
      "Epoch  1, Batch 134 -Loss:     3.7886 Training Accuracy: 0.195753 Validation Accuracy: 0.195238\n",
      "Epoch  1, Batch 135 -Loss:     3.6253 Training Accuracy: 0.203195 Validation Accuracy: 0.216100\n",
      "Epoch  1, Batch 136 -Loss:     3.6675 Training Accuracy: 0.197103 Validation Accuracy: 0.209297\n",
      "Epoch  1, Batch 137 -Loss:     3.6545 Training Accuracy: 0.201098 Validation Accuracy: 0.209070\n",
      "Epoch  1, Batch 138 -Loss:     3.5629 Training Accuracy: 0.200149 Validation Accuracy: 0.197959\n",
      "Epoch  1, Batch 139 -Loss:     3.6535 Training Accuracy: 0.207305 Validation Accuracy: 0.205442\n",
      "Epoch  1, Batch 140 -Loss:     3.6023 Training Accuracy: 0.208368 Validation Accuracy: 0.204535\n",
      "Epoch  1, Batch 141 -Loss:     3.5106 Training Accuracy: 0.208224 Validation Accuracy: 0.193424\n",
      "Epoch  1, Batch 142 -Loss:     3.5330 Training Accuracy: 0.218483 Validation Accuracy: 0.210431\n",
      "Epoch  1, Batch 143 -Loss:     3.5870 Training Accuracy: 0.238168 Validation Accuracy: 0.259184\n",
      "Epoch  1, Batch 144 -Loss:     3.7084 Training Accuracy: 0.253254 Validation Accuracy: 0.256916\n",
      "Epoch  1, Batch 145 -Loss:     3.4411 Training Accuracy: 0.255180 Validation Accuracy: 0.243084\n",
      "Epoch  1, Batch 146 -Loss:     3.4885 Training Accuracy: 0.230093 Validation Accuracy: 0.217914\n",
      "Epoch  1, Batch 147 -Loss:     3.4171 Training Accuracy: 0.212908 Validation Accuracy: 0.208844\n",
      "Epoch  1, Batch 148 -Loss:     3.5422 Training Accuracy: 0.200638 Validation Accuracy: 0.197052\n",
      "Epoch  1, Batch 149 -Loss:     3.4200 Training Accuracy: 0.203598 Validation Accuracy: 0.205215\n",
      "Epoch  1, Batch 150 -Loss:     3.4431 Training Accuracy: 0.214805 Validation Accuracy: 0.207256\n",
      "Epoch  1, Batch 151 -Loss:     3.3992 Training Accuracy: 0.250927 Validation Accuracy: 0.238776\n",
      "Epoch  1, Batch 152 -Loss:     3.2924 Training Accuracy: 0.266818 Validation Accuracy: 0.259864\n",
      "Epoch  1, Batch 153 -Loss:     3.3568 Training Accuracy: 0.276675 Validation Accuracy: 0.273016\n",
      "Epoch  1, Batch 154 -Loss:     3.4676 Training Accuracy: 0.274175 Validation Accuracy: 0.272336\n",
      "Epoch  1, Batch 155 -Loss:     3.1820 Training Accuracy: 0.272479 Validation Accuracy: 0.280726\n",
      "Epoch  1, Batch 156 -Loss:     3.2730 Training Accuracy: 0.279433 Validation Accuracy: 0.270295\n",
      "Epoch  1, Batch 157 -Loss:     3.1972 Training Accuracy: 0.275094 Validation Accuracy: 0.246712\n",
      "Epoch  1, Batch 158 -Loss:     3.0961 Training Accuracy: 0.269318 Validation Accuracy: 0.230159\n",
      "Epoch  1, Batch 159 -Loss:     3.1887 Training Accuracy: 0.274663 Validation Accuracy: 0.228798\n",
      "Epoch  1, Batch 160 -Loss:     3.2988 Training Accuracy: 0.281646 Validation Accuracy: 0.236054\n",
      "Epoch  1, Batch 161 -Loss:     3.1728 Training Accuracy: 0.305900 Validation Accuracy: 0.267120\n",
      "Epoch  1, Batch 162 -Loss:     3.1698 Training Accuracy: 0.309061 Validation Accuracy: 0.279138\n",
      "Epoch  1, Batch 163 -Loss:     3.1246 Training Accuracy: 0.310842 Validation Accuracy: 0.294331\n",
      "Epoch  1, Batch 164 -Loss:     3.0486 Training Accuracy: 0.320900 Validation Accuracy: 0.305669\n",
      "Epoch  1, Batch 165 -Loss:     2.9736 Training Accuracy: 0.324032 Validation Accuracy: 0.291156\n",
      "Epoch  1, Batch 166 -Loss:     3.2825 Training Accuracy: 0.305526 Validation Accuracy: 0.276644\n",
      "Epoch  1, Batch 167 -Loss:     3.0829 Training Accuracy: 0.307423 Validation Accuracy: 0.268481\n",
      "Epoch  1, Batch 168 -Loss:     3.0593 Training Accuracy: 0.314980 Validation Accuracy: 0.275057\n",
      "Epoch  1, Batch 169 -Loss:     3.0605 Training Accuracy: 0.325124 Validation Accuracy: 0.286621\n",
      "Epoch  1, Batch 170 -Loss:     2.8914 Training Accuracy: 0.340039 Validation Accuracy: 0.300227\n",
      "Epoch  1, Batch 171 -Loss:     2.9387 Training Accuracy: 0.337337 Validation Accuracy: 0.300227\n",
      "Epoch  1, Batch 172 -Loss:     2.8499 Training Accuracy: 0.336217 Validation Accuracy: 0.296599\n",
      "Epoch  1, Batch 173 -Loss:     3.1172 Training Accuracy: 0.346361 Validation Accuracy: 0.306349\n",
      "Epoch  1, Batch 174 -Loss:     2.7850 Training Accuracy: 0.342452 Validation Accuracy: 0.306122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 175 -Loss:     2.9415 Training Accuracy: 0.342740 Validation Accuracy: 0.313832\n",
      "Epoch  1, Batch 176 -Loss:     2.7790 Training Accuracy: 0.336504 Validation Accuracy: 0.308617\n",
      "Epoch  1, Batch 177 -Loss:     2.7711 Training Accuracy: 0.325268 Validation Accuracy: 0.297732\n",
      "Epoch  1, Batch 178 -Loss:     2.9245 Training Accuracy: 0.313112 Validation Accuracy: 0.279819\n",
      "Epoch  1, Batch 179 -Loss:     2.7053 Training Accuracy: 0.329377 Validation Accuracy: 0.309751\n",
      "Epoch  1, Batch 180 -Loss:     2.9918 Training Accuracy: 0.373287 Validation Accuracy: 0.342630\n",
      "Epoch  1, Batch 181 -Loss:     2.8528 Training Accuracy: 0.390643 Validation Accuracy: 0.366213\n",
      "Epoch  1, Batch 182 -Loss:     2.8888 Training Accuracy: 0.383172 Validation Accuracy: 0.356916\n",
      "Epoch  1, Batch 183 -Loss:     2.7259 Training Accuracy: 0.349435 Validation Accuracy: 0.313832\n",
      "Epoch  1, Batch 184 -Loss:     2.7190 Training Accuracy: 0.338803 Validation Accuracy: 0.308390\n",
      "Epoch  1, Batch 185 -Loss:     2.6622 Training Accuracy: 0.344177 Validation Accuracy: 0.310658\n",
      "Epoch  1, Batch 186 -Loss:     2.7497 Training Accuracy: 0.371534 Validation Accuracy: 0.332200\n",
      "Epoch  1, Batch 187 -Loss:     2.8260 Training Accuracy: 0.394293 Validation Accuracy: 0.361905\n",
      "Epoch  1, Batch 188 -Loss:     2.4583 Training Accuracy: 0.400529 Validation Accuracy: 0.358277\n",
      "Epoch  1, Batch 189 -Loss:     2.4323 Training Accuracy: 0.372827 Validation Accuracy: 0.345125\n",
      "Epoch  1, Batch 190 -Loss:     2.8115 Training Accuracy: 0.347481 Validation Accuracy: 0.307256\n",
      "Epoch  1, Batch 191 -Loss:     2.6746 Training Accuracy: 0.352539 Validation Accuracy: 0.303401\n",
      "Epoch  1, Batch 192 -Loss:     2.8174 Training Accuracy: 0.371764 Validation Accuracy: 0.324943\n",
      "Epoch  1, Batch 193 -Loss:     2.5794 Training Accuracy: 0.373890 Validation Accuracy: 0.333787\n",
      "Epoch  1, Batch 194 -Loss:     2.7108 Training Accuracy: 0.388316 Validation Accuracy: 0.351701\n",
      "Epoch  1, Batch 195 -Loss:     2.4076 Training Accuracy: 0.407483 Validation Accuracy: 0.362812\n",
      "Epoch  1, Batch 196 -Loss:     2.5446 Training Accuracy: 0.411018 Validation Accuracy: 0.358730\n",
      "Epoch  1, Batch 197 -Loss:     2.5500 Training Accuracy: 0.400213 Validation Accuracy: 0.348526\n",
      "Epoch  1, Batch 198 -Loss:     2.3318 Training Accuracy: 0.400270 Validation Accuracy: 0.351247\n",
      "Epoch  1, Batch 199 -Loss:     2.5740 Training Accuracy: 0.401391 Validation Accuracy: 0.365306\n",
      "Epoch  1, Batch 200 -Loss:     2.3404 Training Accuracy: 0.402081 Validation Accuracy: 0.363719\n",
      "Epoch  1, Batch 201 -Loss:     2.3615 Training Accuracy: 0.413115 Validation Accuracy: 0.374150\n",
      "Epoch  1, Batch 202 -Loss:     2.4936 Training Accuracy: 0.417828 Validation Accuracy: 0.378005\n",
      "Epoch  1, Batch 203 -Loss:     2.5230 Training Accuracy: 0.412483 Validation Accuracy: 0.383673\n",
      "Epoch  1, Batch 204 -Loss:     2.3595 Training Accuracy: 0.432196 Validation Accuracy: 0.398639\n",
      "Epoch  1, Batch 205 -Loss:     2.4837 Training Accuracy: 0.441881 Validation Accuracy: 0.393878\n",
      "Epoch  1, Batch 206 -Loss:     2.5558 Training Accuracy: 0.428863 Validation Accuracy: 0.384354\n",
      "Epoch  1, Batch 207 -Loss:     2.5112 Training Accuracy: 0.415730 Validation Accuracy: 0.366893\n",
      "Epoch  1, Batch 208 -Loss:     2.4836 Training Accuracy: 0.406391 Validation Accuracy: 0.363039\n",
      "Epoch  1, Batch 209 -Loss:     2.6202 Training Accuracy: 0.402684 Validation Accuracy: 0.369388\n",
      "Epoch  1, Batch 210 -Loss:     2.3323 Training Accuracy: 0.406075 Validation Accuracy: 0.370975\n",
      "Epoch  1, Batch 211 -Loss:     2.3655 Training Accuracy: 0.408575 Validation Accuracy: 0.365533\n",
      "Epoch  1, Batch 212 -Loss:     2.4261 Training Accuracy: 0.431507 Validation Accuracy: 0.382540\n",
      "Epoch  1, Batch 213 -Loss:     2.3319 Training Accuracy: 0.445013 Validation Accuracy: 0.397052\n",
      "Epoch  1, Batch 214 -Loss:     2.4703 Training Accuracy: 0.451105 Validation Accuracy: 0.405215\n",
      "Epoch  1, Batch 215 -Loss:     2.2690 Training Accuracy: 0.455559 Validation Accuracy: 0.404535\n",
      "Epoch  1, Batch 216 -Loss:     2.2093 Training Accuracy: 0.440501 Validation Accuracy: 0.386168\n",
      "Epoch  1, Batch 217 -Loss:     2.1709 Training Accuracy: 0.418834 Validation Accuracy: 0.372789\n",
      "Epoch  1, Batch 218 -Loss:     2.4022 Training Accuracy: 0.414495 Validation Accuracy: 0.373696\n",
      "Epoch  1, Batch 219 -Loss:     2.3391 Training Accuracy: 0.435041 Validation Accuracy: 0.396825\n",
      "Epoch  1, Batch 220 -Loss:     2.3048 Training Accuracy: 0.440128 Validation Accuracy: 0.409751\n",
      "Epoch  1, Batch 221 -Loss:     2.5021 Training Accuracy: 0.444467 Validation Accuracy: 0.419955\n",
      "Epoch  1, Batch 222 -Loss:     2.2936 Training Accuracy: 0.444409 Validation Accuracy: 0.416100\n",
      "Epoch  1, Batch 223 -Loss:     2.4188 Training Accuracy: 0.437082 Validation Accuracy: 0.398186\n",
      "Epoch  1, Batch 224 -Loss:     2.2365 Training Accuracy: 0.417023 Validation Accuracy: 0.385034\n",
      "Epoch  1, Batch 225 -Loss:     2.3146 Training Accuracy: 0.415242 Validation Accuracy: 0.372336\n",
      "Epoch  1, Batch 226 -Loss:     2.2027 Training Accuracy: 0.448375 Validation Accuracy: 0.384354\n",
      "Epoch  1, Batch 227 -Loss:     2.3587 Training Accuracy: 0.455186 Validation Accuracy: 0.401587\n",
      "Epoch  1, Batch 228 -Loss:     2.2708 Training Accuracy: 0.450358 Validation Accuracy: 0.406349\n",
      "Epoch  1, Batch 229 -Loss:     2.2002 Training Accuracy: 0.466307 Validation Accuracy: 0.421995\n",
      "Epoch  1, Batch 230 -Loss:     2.2244 Training Accuracy: 0.484123 Validation Accuracy: 0.431746\n",
      "Epoch  1, Batch 231 -Loss:     2.0263 Training Accuracy: 0.465962 Validation Accuracy: 0.405896\n",
      "Epoch  1, Batch 232 -Loss:     2.3630 Training Accuracy: 0.470330 Validation Accuracy: 0.416327\n",
      "Epoch  1, Batch 233 -Loss:     2.2469 Training Accuracy: 0.478261 Validation Accuracy: 0.423356\n",
      "Epoch  1, Batch 234 -Loss:     2.2477 Training Accuracy: 0.481709 Validation Accuracy: 0.428118\n",
      "Epoch  1, Batch 235 -Loss:     2.4312 Training Accuracy: 0.480272 Validation Accuracy: 0.437188\n",
      "Epoch  1, Batch 236 -Loss:     2.2259 Training Accuracy: 0.478951 Validation Accuracy: 0.434921\n",
      "Epoch  1, Batch 237 -Loss:     2.2278 Training Accuracy: 0.459122 Validation Accuracy: 0.405896\n",
      "Epoch  1, Batch 238 -Loss:     2.2365 Training Accuracy: 0.456421 Validation Accuracy: 0.404082\n",
      "Epoch  1, Batch 239 -Loss:     2.3067 Training Accuracy: 0.474238 Validation Accuracy: 0.414512\n",
      "Epoch  1, Batch 240 -Loss:     2.3223 Training Accuracy: 0.498175 Validation Accuracy: 0.425397\n",
      "Epoch  1, Batch 241 -Loss:     2.3597 Training Accuracy: 0.491997 Validation Accuracy: 0.423129\n",
      "Epoch  1, Batch 242 -Loss:     2.3900 Training Accuracy: 0.482571 Validation Accuracy: 0.414966\n",
      "Epoch  1, Batch 243 -Loss:     2.0934 Training Accuracy: 0.486824 Validation Accuracy: 0.427664\n",
      "Epoch  1, Batch 244 -Loss:     1.9280 Training Accuracy: 0.469841 Validation Accuracy: 0.422222\n",
      "Epoch  1, Batch 245 -Loss:     2.2186 Training Accuracy: 0.448519 Validation Accuracy: 0.399320\n",
      "Epoch  1, Batch 246 -Loss:     2.0640 Training Accuracy: 0.437972 Validation Accuracy: 0.387982\n",
      "Epoch  1, Batch 247 -Loss:     2.1684 Training Accuracy: 0.459151 Validation Accuracy: 0.396145\n",
      "Epoch  1, Batch 248 -Loss:     2.0994 Training Accuracy: 0.494325 Validation Accuracy: 0.434240\n",
      "Epoch  1, Batch 249 -Loss:     1.9640 Training Accuracy: 0.504009 Validation Accuracy: 0.439683\n",
      "Epoch  1, Batch 250 -Loss:     2.1211 Training Accuracy: 0.488146 Validation Accuracy: 0.429478\n",
      "Epoch  1, Batch 251 -Loss:     2.1738 Training Accuracy: 0.472427 Validation Accuracy: 0.412698\n",
      "Epoch  1, Batch 252 -Loss:     2.0700 Training Accuracy: 0.476795 Validation Accuracy: 0.412245\n",
      "Epoch  1, Batch 253 -Loss:     2.3700 Training Accuracy: 0.498721 Validation Accuracy: 0.421315\n",
      "Epoch  1, Batch 254 -Loss:     2.3760 Training Accuracy: 0.509153 Validation Accuracy: 0.434921\n",
      "Epoch  1, Batch 255 -Loss:     1.9951 Training Accuracy: 0.519728 Validation Accuracy: 0.446712\n",
      "Epoch  1, Batch 256 -Loss:     2.1686 Training Accuracy: 0.520302 Validation Accuracy: 0.458050\n",
      "Epoch  1, Batch 257 -Loss:     2.0097 Training Accuracy: 0.510791 Validation Accuracy: 0.452834\n",
      "Epoch  1, Batch 258 -Loss:     2.0028 Training Accuracy: 0.499756 Validation Accuracy: 0.448753\n",
      "Epoch  1, Batch 259 -Loss:     1.7888 Training Accuracy: 0.491278 Validation Accuracy: 0.446032\n",
      "Epoch  1, Batch 260 -Loss:     2.1461 Training Accuracy: 0.491307 Validation Accuracy: 0.435828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 261 -Loss:     1.8764 Training Accuracy: 0.501537 Validation Accuracy: 0.434240\n",
      "Epoch  1, Batch 262 -Loss:     2.0416 Training Accuracy: 0.515590 Validation Accuracy: 0.439683\n",
      "Epoch  1, Batch 263 -Loss:     2.0466 Training Accuracy: 0.515877 Validation Accuracy: 0.445351\n",
      "Epoch  1, Batch 264 -Loss:     2.1692 Training Accuracy: 0.527429 Validation Accuracy: 0.450340\n",
      "Epoch  1, Batch 265 -Loss:     2.0547 Training Accuracy: 0.530044 Validation Accuracy: 0.454649\n",
      "Epoch  1, Batch 266 -Loss:     2.0834 Training Accuracy: 0.524325 Validation Accuracy: 0.463039\n",
      "Epoch  1, Batch 267 -Loss:     2.1941 Training Accuracy: 0.532659 Validation Accuracy: 0.469388\n",
      "Epoch  1, Batch 268 -Loss:     1.9359 Training Accuracy: 0.542947 Validation Accuracy: 0.465306\n",
      "Epoch  1, Batch 269 -Loss:     1.9466 Training Accuracy: 0.545418 Validation Accuracy: 0.468707\n",
      "Epoch  1, Batch 270 -Loss:     1.8925 Training Accuracy: 0.542113 Validation Accuracy: 0.462812\n",
      "Epoch  1, Batch 271 -Loss:     1.8936 Training Accuracy: 0.536797 Validation Accuracy: 0.460998\n",
      "Epoch  1, Batch 272 -Loss:     1.8323 Training Accuracy: 0.522084 Validation Accuracy: 0.455556\n",
      "Epoch  2, Batch   1 -Loss:     1.9812 Training Accuracy: 0.541452 Validation Accuracy: 0.474376\n",
      "Epoch  2, Batch   2 -Loss:     2.0849 Training Accuracy: 0.554355 Validation Accuracy: 0.490249\n",
      "Epoch  2, Batch   3 -Loss:     2.0481 Training Accuracy: 0.557430 Validation Accuracy: 0.494104\n",
      "Epoch  2, Batch   4 -Loss:     1.8740 Training Accuracy: 0.560706 Validation Accuracy: 0.492971\n",
      "Epoch  2, Batch   5 -Loss:     1.7702 Training Accuracy: 0.558263 Validation Accuracy: 0.482540\n",
      "Epoch  2, Batch   6 -Loss:     1.8755 Training Accuracy: 0.544757 Validation Accuracy: 0.455102\n",
      "Epoch  2, Batch   7 -Loss:     2.0340 Training Accuracy: 0.549154 Validation Accuracy: 0.451474\n",
      "Epoch  2, Batch   8 -Loss:     1.8342 Training Accuracy: 0.547861 Validation Accuracy: 0.451474\n",
      "Epoch  2, Batch   9 -Loss:     2.0596 Training Accuracy: 0.551654 Validation Accuracy: 0.464172\n",
      "Epoch  2, Batch  10 -Loss:     1.9089 Training Accuracy: 0.555447 Validation Accuracy: 0.475057\n",
      "Epoch  2, Batch  11 -Loss:     1.7451 Training Accuracy: 0.564384 Validation Accuracy: 0.485034\n",
      "Epoch  2, Batch  12 -Loss:     1.9685 Training Accuracy: 0.561166 Validation Accuracy: 0.485714\n",
      "Epoch  2, Batch  13 -Loss:     1.8748 Training Accuracy: 0.538809 Validation Accuracy: 0.475283\n",
      "Epoch  2, Batch  14 -Loss:     1.9668 Training Accuracy: 0.540274 Validation Accuracy: 0.464399\n",
      "Epoch  2, Batch  15 -Loss:     1.7952 Training Accuracy: 0.543033 Validation Accuracy: 0.466440\n",
      "Epoch  2, Batch  16 -Loss:     1.7199 Training Accuracy: 0.544757 Validation Accuracy: 0.477324\n",
      "Epoch  2, Batch  17 -Loss:     2.0429 Training Accuracy: 0.540619 Validation Accuracy: 0.480499\n",
      "Epoch  2, Batch  18 -Loss:     2.0045 Training Accuracy: 0.550188 Validation Accuracy: 0.480272\n",
      "Epoch  2, Batch  19 -Loss:     1.8684 Training Accuracy: 0.554844 Validation Accuracy: 0.472109\n",
      "Epoch  2, Batch  20 -Loss:     1.7946 Training Accuracy: 0.544067 Validation Accuracy: 0.460544\n",
      "Epoch  2, Batch  21 -Loss:     1.8435 Training Accuracy: 0.534096 Validation Accuracy: 0.452608\n",
      "Epoch  2, Batch  22 -Loss:     1.7260 Training Accuracy: 0.540935 Validation Accuracy: 0.464172\n",
      "Epoch  2, Batch  23 -Loss:     1.7911 Training Accuracy: 0.573723 Validation Accuracy: 0.497052\n",
      "Epoch  2, Batch  24 -Loss:     1.7736 Training Accuracy: 0.588235 Validation Accuracy: 0.520181\n",
      "Epoch  2, Batch  25 -Loss:     1.7624 Training Accuracy: 0.582919 Validation Accuracy: 0.515193\n",
      "Epoch  2, Batch  26 -Loss:     1.9082 Training Accuracy: 0.576597 Validation Accuracy: 0.521315\n",
      "Epoch  2, Batch  27 -Loss:     1.6873 Training Accuracy: 0.588322 Validation Accuracy: 0.541950\n",
      "Epoch  2, Batch  28 -Loss:     1.8316 Training Accuracy: 0.596626 Validation Accuracy: 0.540590\n",
      "Epoch  2, Batch  29 -Loss:     1.7689 Training Accuracy: 0.585390 Validation Accuracy: 0.511111\n",
      "Epoch  2, Batch  30 -Loss:     1.7859 Training Accuracy: 0.561654 Validation Accuracy: 0.487755\n",
      "Epoch  2, Batch  31 -Loss:     1.9594 Training Accuracy: 0.575821 Validation Accuracy: 0.502948\n",
      "Epoch  2, Batch  32 -Loss:     1.5913 Training Accuracy: 0.602115 Validation Accuracy: 0.553515\n",
      "Epoch  2, Batch  33 -Loss:     1.8038 Training Accuracy: 0.604443 Validation Accuracy: 0.560091\n",
      "Epoch  2, Batch  34 -Loss:     1.8739 Training Accuracy: 0.605448 Validation Accuracy: 0.562132\n",
      "Epoch  2, Batch  35 -Loss:     1.6259 Training Accuracy: 0.617633 Validation Accuracy: 0.547166\n",
      "Epoch  2, Batch  36 -Loss:     1.8972 Training Accuracy: 0.591684 Validation Accuracy: 0.517460\n",
      "Epoch  2, Batch  37 -Loss:     1.7403 Training Accuracy: 0.565361 Validation Accuracy: 0.490930\n",
      "Epoch  2, Batch  38 -Loss:     1.8154 Training Accuracy: 0.547659 Validation Accuracy: 0.473243\n",
      "Epoch  2, Batch  39 -Loss:     1.8321 Training Accuracy: 0.569557 Validation Accuracy: 0.485488\n",
      "Epoch  2, Batch  40 -Loss:     1.7691 Training Accuracy: 0.579241 Validation Accuracy: 0.508163\n",
      "Epoch  2, Batch  41 -Loss:     1.8681 Training Accuracy: 0.582747 Validation Accuracy: 0.526077\n",
      "Epoch  2, Batch  42 -Loss:     1.8215 Training Accuracy: 0.586770 Validation Accuracy: 0.530612\n",
      "Epoch  2, Batch  43 -Loss:     1.6616 Training Accuracy: 0.593408 Validation Accuracy: 0.531519\n",
      "Epoch  2, Batch  44 -Loss:     1.9433 Training Accuracy: 0.601368 Validation Accuracy: 0.532200\n",
      "Epoch  2, Batch  45 -Loss:     1.8798 Training Accuracy: 0.598408 Validation Accuracy: 0.537868\n",
      "Epoch  2, Batch  46 -Loss:     1.7390 Training Accuracy: 0.612862 Validation Accuracy: 0.540590\n",
      "Epoch  2, Batch  47 -Loss:     1.9672 Training Accuracy: 0.626541 Validation Accuracy: 0.531973\n",
      "Epoch  2, Batch  48 -Loss:     1.9348 Training Accuracy: 0.623955 Validation Accuracy: 0.528798\n",
      "Epoch  2, Batch  49 -Loss:     1.8368 Training Accuracy: 0.615650 Validation Accuracy: 0.521769\n",
      "Epoch  2, Batch  50 -Loss:     1.7257 Training Accuracy: 0.614098 Validation Accuracy: 0.527211\n",
      "Epoch  2, Batch  51 -Loss:     1.7006 Training Accuracy: 0.624501 Validation Accuracy: 0.545805\n",
      "Epoch  2, Batch  52 -Loss:     1.7231 Training Accuracy: 0.628179 Validation Accuracy: 0.552154\n",
      "Epoch  2, Batch  53 -Loss:     1.9683 Training Accuracy: 0.629846 Validation Accuracy: 0.550113\n",
      "Epoch  2, Batch  54 -Loss:     1.9304 Training Accuracy: 0.624501 Validation Accuracy: 0.544671\n",
      "Epoch  2, Batch  55 -Loss:     1.7675 Training Accuracy: 0.623639 Validation Accuracy: 0.552608\n",
      "Epoch  2, Batch  56 -Loss:     1.8852 Training Accuracy: 0.626397 Validation Accuracy: 0.547846\n",
      "Epoch  2, Batch  57 -Loss:     1.6232 Training Accuracy: 0.631110 Validation Accuracy: 0.541043\n",
      "Epoch  2, Batch  58 -Loss:     1.6738 Training Accuracy: 0.633610 Validation Accuracy: 0.547392\n",
      "Epoch  2, Batch  59 -Loss:     1.6409 Training Accuracy: 0.637719 Validation Accuracy: 0.570295\n",
      "Epoch  2, Batch  60 -Loss:     1.8483 Training Accuracy: 0.625909 Validation Accuracy: 0.564172\n",
      "Epoch  2, Batch  61 -Loss:     1.5840 Training Accuracy: 0.620363 Validation Accuracy: 0.562812\n",
      "Epoch  2, Batch  62 -Loss:     1.7547 Training Accuracy: 0.633352 Validation Accuracy: 0.572109\n",
      "Epoch  2, Batch  63 -Loss:     1.7663 Training Accuracy: 0.638524 Validation Accuracy: 0.581179\n",
      "Epoch  2, Batch  64 -Loss:     1.6832 Training Accuracy: 0.632863 Validation Accuracy: 0.577324\n",
      "Epoch  2, Batch  65 -Loss:     1.7747 Training Accuracy: 0.631283 Validation Accuracy: 0.568481\n",
      "Epoch  2, Batch  66 -Loss:     1.5999 Training Accuracy: 0.618035 Validation Accuracy: 0.542177\n",
      "Epoch  2, Batch  67 -Loss:     1.5862 Training Accuracy: 0.614817 Validation Accuracy: 0.536054\n",
      "Epoch  2, Batch  68 -Loss:     1.6146 Training Accuracy: 0.615334 Validation Accuracy: 0.541043\n",
      "Epoch  2, Batch  69 -Loss:     1.6088 Training Accuracy: 0.623581 Validation Accuracy: 0.556689\n",
      "Epoch  2, Batch  70 -Loss:     1.6477 Training Accuracy: 0.627288 Validation Accuracy: 0.563492\n",
      "Epoch  2, Batch  71 -Loss:     1.6599 Training Accuracy: 0.633064 Validation Accuracy: 0.559637\n",
      "Epoch  2, Batch  72 -Loss:     1.6022 Training Accuracy: 0.644760 Validation Accuracy: 0.566893\n",
      "Epoch  2, Batch  73 -Loss:     1.5673 Training Accuracy: 0.649128 Validation Accuracy: 0.576871\n",
      "Epoch  2, Batch  74 -Loss:     1.5976 Training Accuracy: 0.641743 Validation Accuracy: 0.586168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch  75 -Loss:     1.7800 Training Accuracy: 0.629587 Validation Accuracy: 0.572336\n",
      "Epoch  2, Batch  76 -Loss:     1.7858 Training Accuracy: 0.633581 Validation Accuracy: 0.578458\n",
      "Epoch  2, Batch  77 -Loss:     1.6945 Training Accuracy: 0.636915 Validation Accuracy: 0.586168\n",
      "Epoch  2, Batch  78 -Loss:     2.0445 Training Accuracy: 0.632576 Validation Accuracy: 0.577098\n",
      "Epoch  2, Batch  79 -Loss:     1.5590 Training Accuracy: 0.621857 Validation Accuracy: 0.554875\n",
      "Epoch  2, Batch  80 -Loss:     1.4449 Training Accuracy: 0.613840 Validation Accuracy: 0.539683\n",
      "Epoch  2, Batch  81 -Loss:     1.6281 Training Accuracy: 0.629386 Validation Accuracy: 0.563946\n",
      "Epoch  2, Batch  82 -Loss:     1.6822 Training Accuracy: 0.642633 Validation Accuracy: 0.579365\n",
      "Epoch  2, Batch  83 -Loss:     1.6803 Training Accuracy: 0.642087 Validation Accuracy: 0.584354\n",
      "Epoch  2, Batch  84 -Loss:     1.8129 Training Accuracy: 0.628782 Validation Accuracy: 0.575057\n",
      "Epoch  2, Batch  85 -Loss:     1.6835 Training Accuracy: 0.637949 Validation Accuracy: 0.586168\n",
      "Epoch  2, Batch  86 -Loss:     1.5654 Training Accuracy: 0.664559 Validation Accuracy: 0.602721\n",
      "Epoch  2, Batch  87 -Loss:     1.6733 Training Accuracy: 0.664272 Validation Accuracy: 0.603855\n",
      "Epoch  2, Batch  88 -Loss:     1.7421 Training Accuracy: 0.654703 Validation Accuracy: 0.582086\n",
      "Epoch  2, Batch  89 -Loss:     1.7252 Training Accuracy: 0.640794 Validation Accuracy: 0.548526\n",
      "Epoch  2, Batch  90 -Loss:     1.7612 Training Accuracy: 0.626139 Validation Accuracy: 0.524717\n",
      "Epoch  2, Batch  91 -Loss:     1.6790 Training Accuracy: 0.596425 Validation Accuracy: 0.505669\n",
      "Epoch  2, Batch  92 -Loss:     1.6657 Training Accuracy: 0.599184 Validation Accuracy: 0.509297\n",
      "Epoch  2, Batch  93 -Loss:     1.6771 Training Accuracy: 0.635018 Validation Accuracy: 0.556689\n",
      "Epoch  2, Batch  94 -Loss:     1.6435 Training Accuracy: 0.658295 Validation Accuracy: 0.593197\n",
      "Epoch  2, Batch  95 -Loss:     1.5566 Training Accuracy: 0.675221 Validation Accuracy: 0.609524\n",
      "Epoch  2, Batch  96 -Loss:     1.6056 Training Accuracy: 0.675537 Validation Accuracy: 0.608163\n",
      "Epoch  2, Batch  97 -Loss:     1.5763 Training Accuracy: 0.650220 Validation Accuracy: 0.561451\n",
      "Epoch  2, Batch  98 -Loss:     1.6586 Training Accuracy: 0.626167 Validation Accuracy: 0.547619\n",
      "Epoch  2, Batch  99 -Loss:     1.8481 Training Accuracy: 0.614874 Validation Accuracy: 0.549433\n",
      "Epoch  2, Batch 100 -Loss:     1.4882 Training Accuracy: 0.629443 Validation Accuracy: 0.568707\n",
      "Epoch  2, Batch 101 -Loss:     1.8306 Training Accuracy: 0.653036 Validation Accuracy: 0.607710\n",
      "Epoch  2, Batch 102 -Loss:     1.6263 Training Accuracy: 0.656686 Validation Accuracy: 0.609524\n",
      "Epoch  2, Batch 103 -Loss:     1.7997 Training Accuracy: 0.650593 Validation Accuracy: 0.605896\n",
      "Epoch  2, Batch 104 -Loss:     1.6762 Training Accuracy: 0.647576 Validation Accuracy: 0.595465\n",
      "Epoch  2, Batch 105 -Loss:     1.6716 Training Accuracy: 0.653582 Validation Accuracy: 0.586168\n",
      "Epoch  2, Batch 106 -Loss:     1.7118 Training Accuracy: 0.666312 Validation Accuracy: 0.585488\n",
      "Epoch  2, Batch 107 -Loss:     1.5584 Training Accuracy: 0.663496 Validation Accuracy: 0.587982\n",
      "Epoch  2, Batch 108 -Loss:     1.4435 Training Accuracy: 0.658438 Validation Accuracy: 0.576417\n",
      "Epoch  2, Batch 109 -Loss:     1.6198 Training Accuracy: 0.661801 Validation Accuracy: 0.580272\n",
      "Epoch  2, Batch 110 -Loss:     1.5138 Training Accuracy: 0.662663 Validation Accuracy: 0.583900\n",
      "Epoch  2, Batch 111 -Loss:     1.6861 Training Accuracy: 0.658151 Validation Accuracy: 0.585488\n",
      "Epoch  2, Batch 112 -Loss:     1.6360 Training Accuracy: 0.652691 Validation Accuracy: 0.575283\n",
      "Epoch  2, Batch 113 -Loss:     1.5442 Training Accuracy: 0.648266 Validation Accuracy: 0.576190\n",
      "Epoch  2, Batch 114 -Loss:     1.7338 Training Accuracy: 0.660191 Validation Accuracy: 0.595011\n",
      "Epoch  2, Batch 115 -Loss:     1.5342 Training Accuracy: 0.680106 Validation Accuracy: 0.609977\n",
      "Epoch  2, Batch 116 -Loss:     1.5981 Training Accuracy: 0.673956 Validation Accuracy: 0.597506\n",
      "Epoch  2, Batch 117 -Loss:     1.6624 Training Accuracy: 0.661283 Validation Accuracy: 0.593197\n",
      "Epoch  2, Batch 118 -Loss:     1.5876 Training Accuracy: 0.659358 Validation Accuracy: 0.591610\n",
      "Epoch  2, Batch 119 -Loss:     1.5952 Training Accuracy: 0.670853 Validation Accuracy: 0.601134\n",
      "Epoch  2, Batch 120 -Loss:     1.6157 Training Accuracy: 0.683985 Validation Accuracy: 0.622676\n",
      "Epoch  2, Batch 121 -Loss:     1.4740 Training Accuracy: 0.677060 Validation Accuracy: 0.607710\n",
      "Epoch  2, Batch 122 -Loss:     1.6728 Training Accuracy: 0.663726 Validation Accuracy: 0.585488\n",
      "Epoch  2, Batch 123 -Loss:     1.5282 Training Accuracy: 0.658668 Validation Accuracy: 0.581633\n",
      "Epoch  2, Batch 124 -Loss:     1.4753 Training Accuracy: 0.651858 Validation Accuracy: 0.578685\n",
      "Epoch  2, Batch 125 -Loss:     1.6369 Training Accuracy: 0.656456 Validation Accuracy: 0.582540\n",
      "Epoch  2, Batch 126 -Loss:     1.6883 Training Accuracy: 0.679157 Validation Accuracy: 0.603401\n",
      "Epoch  2, Batch 127 -Loss:     1.6271 Training Accuracy: 0.691801 Validation Accuracy: 0.631746\n",
      "Epoch  2, Batch 128 -Loss:     1.5852 Training Accuracy: 0.678698 Validation Accuracy: 0.630159\n",
      "Epoch  2, Batch 129 -Loss:     1.6581 Training Accuracy: 0.670220 Validation Accuracy: 0.628118\n",
      "Epoch  2, Batch 130 -Loss:     1.6356 Training Accuracy: 0.671197 Validation Accuracy: 0.620635\n",
      "Epoch  2, Batch 131 -Loss:     1.5469 Training Accuracy: 0.665766 Validation Accuracy: 0.607256\n",
      "Epoch  2, Batch 132 -Loss:     1.5777 Training Accuracy: 0.650622 Validation Accuracy: 0.591156\n",
      "Epoch  2, Batch 133 -Loss:     1.6934 Training Accuracy: 0.642950 Validation Accuracy: 0.577098\n",
      "Epoch  2, Batch 134 -Loss:     1.6861 Training Accuracy: 0.659818 Validation Accuracy: 0.586168\n",
      "Epoch  2, Batch 135 -Loss:     1.5367 Training Accuracy: 0.658697 Validation Accuracy: 0.586395\n",
      "Epoch  2, Batch 136 -Loss:     1.6390 Training Accuracy: 0.653726 Validation Accuracy: 0.581859\n",
      "Epoch  2, Batch 137 -Loss:     1.4076 Training Accuracy: 0.642691 Validation Accuracy: 0.579592\n",
      "Epoch  2, Batch 138 -Loss:     1.4640 Training Accuracy: 0.648409 Validation Accuracy: 0.595465\n",
      "Epoch  2, Batch 139 -Loss:     1.5426 Training Accuracy: 0.651628 Validation Accuracy: 0.602721\n",
      "Epoch  2, Batch 140 -Loss:     1.5641 Training Accuracy: 0.650105 Validation Accuracy: 0.597052\n",
      "Epoch  2, Batch 141 -Loss:     1.5857 Training Accuracy: 0.658870 Validation Accuracy: 0.592517\n",
      "Epoch  2, Batch 142 -Loss:     1.5714 Training Accuracy: 0.659329 Validation Accuracy: 0.595465\n",
      "Epoch  2, Batch 143 -Loss:     1.6076 Training Accuracy: 0.663611 Validation Accuracy: 0.600000\n",
      "Epoch  2, Batch 144 -Loss:     1.6040 Training Accuracy: 0.675652 Validation Accuracy: 0.617914\n",
      "Epoch  2, Batch 145 -Loss:     1.6078 Training Accuracy: 0.692319 Validation Accuracy: 0.635374\n",
      "Epoch  2, Batch 146 -Loss:     1.7194 Training Accuracy: 0.691083 Validation Accuracy: 0.631519\n",
      "Epoch  2, Batch 147 -Loss:     1.5167 Training Accuracy: 0.686801 Validation Accuracy: 0.635147\n",
      "Epoch  2, Batch 148 -Loss:     1.5479 Training Accuracy: 0.686686 Validation Accuracy: 0.641950\n",
      "Epoch  2, Batch 149 -Loss:     1.5703 Training Accuracy: 0.691054 Validation Accuracy: 0.649887\n",
      "Epoch  2, Batch 150 -Loss:     1.5037 Training Accuracy: 0.684388 Validation Accuracy: 0.640136\n",
      "Epoch  2, Batch 151 -Loss:     1.4136 Training Accuracy: 0.678554 Validation Accuracy: 0.629025\n",
      "Epoch  2, Batch 152 -Loss:     1.5232 Training Accuracy: 0.673698 Validation Accuracy: 0.625850\n",
      "Epoch  2, Batch 153 -Loss:     1.5399 Training Accuracy: 0.678037 Validation Accuracy: 0.625624\n",
      "Epoch  2, Batch 154 -Loss:     1.5817 Training Accuracy: 0.674416 Validation Accuracy: 0.613832\n",
      "Epoch  2, Batch 155 -Loss:     1.4647 Training Accuracy: 0.665163 Validation Accuracy: 0.606803\n",
      "Epoch  2, Batch 156 -Loss:     1.5834 Training Accuracy: 0.685451 Validation Accuracy: 0.630839\n",
      "Epoch  2, Batch 157 -Loss:     1.5244 Training Accuracy: 0.705767 Validation Accuracy: 0.655782\n",
      "Epoch  2, Batch 158 -Loss:     1.4081 Training Accuracy: 0.713066 Validation Accuracy: 0.665306\n",
      "Epoch  2, Batch 159 -Loss:     1.6308 Training Accuracy: 0.707980 Validation Accuracy: 0.652834\n",
      "Epoch  2, Batch 160 -Loss:     1.3523 Training Accuracy: 0.698928 Validation Accuracy: 0.631746\n",
      "Epoch  2, Batch 161 -Loss:     1.4754 Training Accuracy: 0.690652 Validation Accuracy: 0.617687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 162 -Loss:     1.4462 Training Accuracy: 0.685853 Validation Accuracy: 0.619955\n",
      "Epoch  2, Batch 163 -Loss:     1.4880 Training Accuracy: 0.696399 Validation Accuracy: 0.625850\n",
      "Epoch  2, Batch 164 -Loss:     1.4476 Training Accuracy: 0.699474 Validation Accuracy: 0.627438\n",
      "Epoch  2, Batch 165 -Loss:     1.3793 Training Accuracy: 0.692779 Validation Accuracy: 0.626077\n",
      "Epoch  2, Batch 166 -Loss:     1.5800 Training Accuracy: 0.694187 Validation Accuracy: 0.632880\n",
      "Epoch  2, Batch 167 -Loss:     1.4742 Training Accuracy: 0.695020 Validation Accuracy: 0.632653\n",
      "Epoch  2, Batch 168 -Loss:     1.4378 Training Accuracy: 0.703210 Validation Accuracy: 0.641497\n",
      "Epoch  2, Batch 169 -Loss:     1.5282 Training Accuracy: 0.705911 Validation Accuracy: 0.636281\n",
      "Epoch  2, Batch 170 -Loss:     1.4448 Training Accuracy: 0.696715 Validation Accuracy: 0.627664\n",
      "Epoch  2, Batch 171 -Loss:     1.4530 Training Accuracy: 0.703555 Validation Accuracy: 0.642177\n",
      "Epoch  2, Batch 172 -Loss:     1.3276 Training Accuracy: 0.706658 Validation Accuracy: 0.637188\n",
      "Epoch  2, Batch 173 -Loss:     1.3333 Training Accuracy: 0.698181 Validation Accuracy: 0.617234\n",
      "Epoch  2, Batch 174 -Loss:     1.4429 Training Accuracy: 0.706256 Validation Accuracy: 0.620181\n",
      "Epoch  2, Batch 175 -Loss:     1.5320 Training Accuracy: 0.709848 Validation Accuracy: 0.633560\n",
      "Epoch  2, Batch 176 -Loss:     1.4309 Training Accuracy: 0.703986 Validation Accuracy: 0.640136\n",
      "Epoch  2, Batch 177 -Loss:     1.4179 Training Accuracy: 0.696773 Validation Accuracy: 0.649660\n",
      "Epoch  2, Batch 178 -Loss:     1.4071 Training Accuracy: 0.696629 Validation Accuracy: 0.643764\n",
      "Epoch  2, Batch 179 -Loss:     1.5466 Training Accuracy: 0.702060 Validation Accuracy: 0.645351\n",
      "Epoch  2, Batch 180 -Loss:     1.4155 Training Accuracy: 0.699417 Validation Accuracy: 0.634921\n",
      "Epoch  2, Batch 181 -Loss:     1.6039 Training Accuracy: 0.692376 Validation Accuracy: 0.629705\n",
      "Epoch  2, Batch 182 -Loss:     1.4904 Training Accuracy: 0.694560 Validation Accuracy: 0.628798\n",
      "Epoch  2, Batch 183 -Loss:     1.6250 Training Accuracy: 0.705710 Validation Accuracy: 0.655102\n",
      "Epoch  2, Batch 184 -Loss:     1.5066 Training Accuracy: 0.711831 Validation Accuracy: 0.676190\n",
      "Epoch  2, Batch 185 -Loss:     1.5302 Training Accuracy: 0.724906 Validation Accuracy: 0.685488\n",
      "Epoch  2, Batch 186 -Loss:     1.5688 Training Accuracy: 0.723814 Validation Accuracy: 0.671202\n",
      "Epoch  2, Batch 187 -Loss:     1.3541 Training Accuracy: 0.707923 Validation Accuracy: 0.648073\n",
      "Epoch  2, Batch 188 -Loss:     1.5403 Training Accuracy: 0.692118 Validation Accuracy: 0.631293\n",
      "Epoch  2, Batch 189 -Loss:     1.5529 Training Accuracy: 0.692549 Validation Accuracy: 0.619274\n",
      "Epoch  2, Batch 190 -Loss:     1.3863 Training Accuracy: 0.705193 Validation Accuracy: 0.635147\n",
      "Epoch  2, Batch 191 -Loss:     1.3638 Training Accuracy: 0.717549 Validation Accuracy: 0.655782\n",
      "Epoch  2, Batch 192 -Loss:     1.5193 Training Accuracy: 0.712980 Validation Accuracy: 0.662585\n",
      "Epoch  2, Batch 193 -Loss:     1.6737 Training Accuracy: 0.706946 Validation Accuracy: 0.656009\n",
      "Epoch  2, Batch 194 -Loss:     1.3518 Training Accuracy: 0.712061 Validation Accuracy: 0.667574\n",
      "Epoch  2, Batch 195 -Loss:     1.4277 Training Accuracy: 0.710049 Validation Accuracy: 0.666440\n",
      "Epoch  2, Batch 196 -Loss:     1.5812 Training Accuracy: 0.711860 Validation Accuracy: 0.664172\n",
      "Epoch  2, Batch 197 -Loss:     1.5594 Training Accuracy: 0.704704 Validation Accuracy: 0.655329\n",
      "Epoch  2, Batch 198 -Loss:     1.5588 Training Accuracy: 0.712549 Validation Accuracy: 0.665533\n",
      "Epoch  2, Batch 199 -Loss:     1.6186 Training Accuracy: 0.713555 Validation Accuracy: 0.664399\n",
      "Epoch  2, Batch 200 -Loss:     1.4913 Training Accuracy: 0.709676 Validation Accuracy: 0.659864\n",
      "Epoch  2, Batch 201 -Loss:     1.4947 Training Accuracy: 0.714647 Validation Accuracy: 0.658730\n",
      "Epoch  2, Batch 202 -Loss:     1.5360 Training Accuracy: 0.713842 Validation Accuracy: 0.649206\n",
      "Epoch  2, Batch 203 -Loss:     1.3159 Training Accuracy: 0.712348 Validation Accuracy: 0.645125\n",
      "Epoch  2, Batch 204 -Loss:     1.3862 Training Accuracy: 0.721256 Validation Accuracy: 0.658957\n",
      "Epoch  2, Batch 205 -Loss:     1.4007 Training Accuracy: 0.723900 Validation Accuracy: 0.662132\n",
      "Epoch  2, Batch 206 -Loss:     1.2799 Training Accuracy: 0.718728 Validation Accuracy: 0.658503\n",
      "Epoch  2, Batch 207 -Loss:     1.3832 Training Accuracy: 0.715998 Validation Accuracy: 0.650567\n",
      "Epoch  2, Batch 208 -Loss:     1.3917 Training Accuracy: 0.729849 Validation Accuracy: 0.662132\n",
      "Epoch  2, Batch 209 -Loss:     1.4867 Training Accuracy: 0.738728 Validation Accuracy: 0.674376\n",
      "Epoch  2, Batch 210 -Loss:     1.5129 Training Accuracy: 0.737952 Validation Accuracy: 0.678458\n",
      "Epoch  2, Batch 211 -Loss:     1.3570 Training Accuracy: 0.728009 Validation Accuracy: 0.670748\n",
      "Epoch  2, Batch 212 -Loss:     1.4622 Training Accuracy: 0.712204 Validation Accuracy: 0.652608\n",
      "Epoch  2, Batch 213 -Loss:     1.4424 Training Accuracy: 0.708497 Validation Accuracy: 0.653061\n",
      "Epoch  2, Batch 214 -Loss:     1.4701 Training Accuracy: 0.727463 Validation Accuracy: 0.671202\n",
      "Epoch  2, Batch 215 -Loss:     1.4287 Training Accuracy: 0.740567 Validation Accuracy: 0.684127\n",
      "Epoch  2, Batch 216 -Loss:     1.4753 Training Accuracy: 0.747953 Validation Accuracy: 0.697732\n",
      "Epoch  2, Batch 217 -Loss:     1.4955 Training Accuracy: 0.751085 Validation Accuracy: 0.692064\n",
      "Epoch  2, Batch 218 -Loss:     1.3697 Training Accuracy: 0.740941 Validation Accuracy: 0.675283\n",
      "Epoch  2, Batch 219 -Loss:     1.6579 Training Accuracy: 0.740855 Validation Accuracy: 0.665306\n",
      "Epoch  2, Batch 220 -Loss:     1.4270 Training Accuracy: 0.736458 Validation Accuracy: 0.661905\n",
      "Epoch  2, Batch 221 -Loss:     1.4035 Training Accuracy: 0.731257 Validation Accuracy: 0.661224\n",
      "Epoch  2, Batch 222 -Loss:     1.3063 Training Accuracy: 0.729877 Validation Accuracy: 0.663492\n",
      "Epoch  2, Batch 223 -Loss:     1.3315 Training Accuracy: 0.740309 Validation Accuracy: 0.674376\n",
      "Epoch  2, Batch 224 -Loss:     1.4183 Training Accuracy: 0.738699 Validation Accuracy: 0.676644\n",
      "Epoch  2, Batch 225 -Loss:     1.3532 Training Accuracy: 0.735740 Validation Accuracy: 0.679138\n",
      "Epoch  2, Batch 226 -Loss:     1.3329 Training Accuracy: 0.745424 Validation Accuracy: 0.682540\n",
      "Epoch  2, Batch 227 -Loss:     1.3600 Training Accuracy: 0.731400 Validation Accuracy: 0.674376\n",
      "Epoch  2, Batch 228 -Loss:     1.3827 Training Accuracy: 0.712406 Validation Accuracy: 0.644671\n",
      "Epoch  2, Batch 229 -Loss:     1.4275 Training Accuracy: 0.730941 Validation Accuracy: 0.673243\n",
      "Epoch  2, Batch 230 -Loss:     1.5995 Training Accuracy: 0.745194 Validation Accuracy: 0.706576\n",
      "Epoch  2, Batch 231 -Loss:     1.3544 Training Accuracy: 0.741085 Validation Accuracy: 0.708617\n",
      "Epoch  2, Batch 232 -Loss:     1.4661 Training Accuracy: 0.745912 Validation Accuracy: 0.708390\n",
      "Epoch  2, Batch 233 -Loss:     1.4517 Training Accuracy: 0.755194 Validation Accuracy: 0.709751\n",
      "Epoch  2, Batch 234 -Loss:     1.2061 Training Accuracy: 0.751631 Validation Accuracy: 0.690703\n",
      "Epoch  2, Batch 235 -Loss:     1.3758 Training Accuracy: 0.723239 Validation Accuracy: 0.661905\n",
      "Epoch  2, Batch 236 -Loss:     1.2840 Training Accuracy: 0.714417 Validation Accuracy: 0.650567\n",
      "Epoch  2, Batch 237 -Loss:     1.2179 Training Accuracy: 0.725165 Validation Accuracy: 0.664399\n",
      "Epoch  2, Batch 238 -Loss:     1.3802 Training Accuracy: 0.738125 Validation Accuracy: 0.674603\n",
      "Epoch  2, Batch 239 -Loss:     1.3387 Training Accuracy: 0.723756 Validation Accuracy: 0.674376\n",
      "Epoch  2, Batch 240 -Loss:     1.6536 Training Accuracy: 0.718929 Validation Accuracy: 0.666893\n",
      "Epoch  2, Batch 241 -Loss:     1.3940 Training Accuracy: 0.713009 Validation Accuracy: 0.658957\n",
      "Epoch  2, Batch 242 -Loss:     1.3894 Training Accuracy: 0.706198 Validation Accuracy: 0.649433\n",
      "Epoch  2, Batch 243 -Loss:     1.2607 Training Accuracy: 0.705106 Validation Accuracy: 0.641497\n",
      "Epoch  2, Batch 244 -Loss:     1.5819 Training Accuracy: 0.720136 Validation Accuracy: 0.668934\n",
      "Epoch  2, Batch 245 -Loss:     1.3486 Training Accuracy: 0.742349 Validation Accuracy: 0.700000\n",
      "Epoch  2, Batch 246 -Loss:     1.3261 Training Accuracy: 0.754936 Validation Accuracy: 0.715646\n",
      "Epoch  2, Batch 247 -Loss:     1.2739 Training Accuracy: 0.751602 Validation Accuracy: 0.707483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 248 -Loss:     1.4787 Training Accuracy: 0.743585 Validation Accuracy: 0.688889\n",
      "Epoch  2, Batch 249 -Loss:     1.4240 Training Accuracy: 0.735194 Validation Accuracy: 0.680272\n",
      "Epoch  2, Batch 250 -Loss:     1.3311 Training Accuracy: 0.738383 Validation Accuracy: 0.674376\n",
      "Epoch  2, Batch 251 -Loss:     1.2193 Training Accuracy: 0.739561 Validation Accuracy: 0.670295\n",
      "Epoch  2, Batch 252 -Loss:     1.3873 Training Accuracy: 0.739820 Validation Accuracy: 0.666893\n",
      "Epoch  2, Batch 253 -Loss:     1.3310 Training Accuracy: 0.742263 Validation Accuracy: 0.677778\n",
      "Epoch  2, Batch 254 -Loss:     1.3579 Training Accuracy: 0.744131 Validation Accuracy: 0.687755\n",
      "Epoch  2, Batch 255 -Loss:     1.5388 Training Accuracy: 0.741745 Validation Accuracy: 0.683900\n",
      "Epoch  2, Batch 256 -Loss:     1.3546 Training Accuracy: 0.746372 Validation Accuracy: 0.698639\n",
      "Epoch  2, Batch 257 -Loss:     1.3379 Training Accuracy: 0.753326 Validation Accuracy: 0.709524\n",
      "Epoch  2, Batch 258 -Loss:     1.3391 Training Accuracy: 0.760683 Validation Accuracy: 0.718367\n",
      "Epoch  2, Batch 259 -Loss:     1.4922 Training Accuracy: 0.768758 Validation Accuracy: 0.724717\n",
      "Epoch  2, Batch 260 -Loss:     1.4100 Training Accuracy: 0.764620 Validation Accuracy: 0.710658\n",
      "Epoch  2, Batch 261 -Loss:     1.2396 Training Accuracy: 0.736630 Validation Accuracy: 0.675057\n",
      "Epoch  2, Batch 262 -Loss:     1.3248 Training Accuracy: 0.711256 Validation Accuracy: 0.638322\n",
      "Epoch  2, Batch 263 -Loss:     1.2744 Training Accuracy: 0.718153 Validation Accuracy: 0.643764\n",
      "Epoch  2, Batch 264 -Loss:     1.2626 Training Accuracy: 0.750453 Validation Accuracy: 0.684807\n",
      "Epoch  2, Batch 265 -Loss:     1.3728 Training Accuracy: 0.751918 Validation Accuracy: 0.698186\n",
      "Epoch  2, Batch 266 -Loss:     1.3565 Training Accuracy: 0.733498 Validation Accuracy: 0.680952\n",
      "Epoch  2, Batch 267 -Loss:     1.4045 Training Accuracy: 0.731975 Validation Accuracy: 0.667574\n",
      "Epoch  2, Batch 268 -Loss:     1.3169 Training Accuracy: 0.718124 Validation Accuracy: 0.646259\n",
      "Epoch  2, Batch 269 -Loss:     1.4059 Training Accuracy: 0.703871 Validation Accuracy: 0.634467\n",
      "Epoch  2, Batch 270 -Loss:     1.3091 Training Accuracy: 0.728555 Validation Accuracy: 0.667574\n",
      "Epoch  2, Batch 271 -Loss:     1.3384 Training Accuracy: 0.734648 Validation Accuracy: 0.670975\n",
      "Epoch  2, Batch 272 -Loss:     1.4290 Training Accuracy: 0.719446 Validation Accuracy: 0.659410\n",
      "Epoch  3, Batch   1 -Loss:     1.3187 Training Accuracy: 0.728067 Validation Accuracy: 0.666440\n",
      "Epoch  3, Batch   2 -Loss:     1.1975 Training Accuracy: 0.754533 Validation Accuracy: 0.695011\n",
      "Epoch  3, Batch   3 -Loss:     1.3318 Training Accuracy: 0.746659 Validation Accuracy: 0.698866\n",
      "Epoch  3, Batch   4 -Loss:     1.2284 Training Accuracy: 0.721256 Validation Accuracy: 0.668254\n",
      "Epoch  3, Batch   5 -Loss:     1.4282 Training Accuracy: 0.715222 Validation Accuracy: 0.653515\n",
      "Epoch  3, Batch   6 -Loss:     1.3643 Training Accuracy: 0.738469 Validation Accuracy: 0.665533\n",
      "Epoch  3, Batch   7 -Loss:     1.4210 Training Accuracy: 0.753614 Validation Accuracy: 0.679365\n",
      "Epoch  3, Batch   8 -Loss:     1.2196 Training Accuracy: 0.757206 Validation Accuracy: 0.682766\n",
      "Epoch  3, Batch   9 -Loss:     1.3256 Training Accuracy: 0.753068 Validation Accuracy: 0.685941\n",
      "Epoch  3, Batch  10 -Loss:     1.3990 Training Accuracy: 0.750941 Validation Accuracy: 0.676644\n",
      "Epoch  3, Batch  11 -Loss:     1.2508 Training Accuracy: 0.738786 Validation Accuracy: 0.665760\n",
      "Epoch  3, Batch  12 -Loss:     1.0951 Training Accuracy: 0.726055 Validation Accuracy: 0.662812\n",
      "Epoch  3, Batch  13 -Loss:     1.2339 Training Accuracy: 0.727090 Validation Accuracy: 0.668254\n",
      "Epoch  3, Batch  14 -Loss:     1.2187 Training Accuracy: 0.719733 Validation Accuracy: 0.663492\n",
      "Epoch  3, Batch  15 -Loss:     1.4640 Training Accuracy: 0.740136 Validation Accuracy: 0.684354\n",
      "Epoch  3, Batch  16 -Loss:     1.2191 Training Accuracy: 0.760510 Validation Accuracy: 0.713152\n",
      "Epoch  3, Batch  17 -Loss:     1.2469 Training Accuracy: 0.756027 Validation Accuracy: 0.699546\n",
      "Epoch  3, Batch  18 -Loss:     1.3904 Training Accuracy: 0.750510 Validation Accuracy: 0.692517\n",
      "Epoch  3, Batch  19 -Loss:     1.3248 Training Accuracy: 0.747953 Validation Accuracy: 0.688662\n",
      "Epoch  3, Batch  20 -Loss:     1.2637 Training Accuracy: 0.758700 Validation Accuracy: 0.707937\n",
      "Epoch  3, Batch  21 -Loss:     1.1671 Training Accuracy: 0.760223 Validation Accuracy: 0.723356\n",
      "Epoch  3, Batch  22 -Loss:     1.4425 Training Accuracy: 0.754677 Validation Accuracy: 0.714966\n",
      "Epoch  3, Batch  23 -Loss:     1.3623 Training Accuracy: 0.749217 Validation Accuracy: 0.702041\n",
      "Epoch  3, Batch  24 -Loss:     1.5514 Training Accuracy: 0.753700 Validation Accuracy: 0.709751\n",
      "Epoch  3, Batch  25 -Loss:     1.2384 Training Accuracy: 0.757665 Validation Accuracy: 0.718594\n",
      "Epoch  3, Batch  26 -Loss:     1.3391 Training Accuracy: 0.739102 Validation Accuracy: 0.684127\n",
      "Epoch  3, Batch  27 -Loss:     1.2907 Training Accuracy: 0.736573 Validation Accuracy: 0.676190\n",
      "Epoch  3, Batch  28 -Loss:     1.2885 Training Accuracy: 0.761200 Validation Accuracy: 0.703401\n",
      "Epoch  3, Batch  29 -Loss:     1.2815 Training Accuracy: 0.772206 Validation Accuracy: 0.717460\n",
      "Epoch  3, Batch  30 -Loss:     1.1871 Training Accuracy: 0.768786 Validation Accuracy: 0.717234\n",
      "Epoch  3, Batch  31 -Loss:     1.3676 Training Accuracy: 0.759332 Validation Accuracy: 0.717687\n",
      "Epoch  3, Batch  32 -Loss:     1.3920 Training Accuracy: 0.761976 Validation Accuracy: 0.712245\n",
      "Epoch  3, Batch  33 -Loss:     1.3093 Training Accuracy: 0.757838 Validation Accuracy: 0.696599\n",
      "Epoch  3, Batch  34 -Loss:     1.4926 Training Accuracy: 0.734676 Validation Accuracy: 0.658730\n",
      "Epoch  3, Batch  35 -Loss:     1.4151 Training Accuracy: 0.744303 Validation Accuracy: 0.682993\n",
      "Epoch  3, Batch  36 -Loss:     1.2344 Training Accuracy: 0.759131 Validation Accuracy: 0.711791\n",
      "Epoch  3, Batch  37 -Loss:     1.3738 Training Accuracy: 0.758901 Validation Accuracy: 0.720408\n",
      "Epoch  3, Batch  38 -Loss:     1.2127 Training Accuracy: 0.774764 Validation Accuracy: 0.741723\n",
      "Epoch  3, Batch  39 -Loss:     1.3299 Training Accuracy: 0.765510 Validation Accuracy: 0.716327\n",
      "Epoch  3, Batch  40 -Loss:     1.2331 Training Accuracy: 0.745395 Validation Accuracy: 0.689342\n",
      "Epoch  3, Batch  41 -Loss:     1.2668 Training Accuracy: 0.741314 Validation Accuracy: 0.687075\n",
      "Epoch  3, Batch  42 -Loss:     1.4065 Training Accuracy: 0.755683 Validation Accuracy: 0.700227\n",
      "Epoch  3, Batch  43 -Loss:     1.3868 Training Accuracy: 0.761631 Validation Accuracy: 0.699320\n",
      "Epoch  3, Batch  44 -Loss:     1.3559 Training Accuracy: 0.761804 Validation Accuracy: 0.701134\n",
      "Epoch  3, Batch  45 -Loss:     1.2838 Training Accuracy: 0.758097 Validation Accuracy: 0.700000\n",
      "Epoch  3, Batch  46 -Loss:     1.2472 Training Accuracy: 0.758269 Validation Accuracy: 0.700454\n",
      "Epoch  3, Batch  47 -Loss:     1.3038 Training Accuracy: 0.769304 Validation Accuracy: 0.713379\n",
      "Epoch  3, Batch  48 -Loss:     1.5289 Training Accuracy: 0.770683 Validation Accuracy: 0.717234\n",
      "Epoch  3, Batch  49 -Loss:     1.4379 Training Accuracy: 0.763758 Validation Accuracy: 0.709977\n",
      "Epoch  3, Batch  50 -Loss:     1.4584 Training Accuracy: 0.750654 Validation Accuracy: 0.695011\n",
      "Epoch  3, Batch  51 -Loss:     1.4690 Training Accuracy: 0.746027 Validation Accuracy: 0.694785\n",
      "Epoch  3, Batch  52 -Loss:     1.1867 Training Accuracy: 0.750682 Validation Accuracy: 0.710658\n",
      "Epoch  3, Batch  53 -Loss:     1.2544 Training Accuracy: 0.762263 Validation Accuracy: 0.717234\n",
      "Epoch  3, Batch  54 -Loss:     1.3437 Training Accuracy: 0.773413 Validation Accuracy: 0.737188\n",
      "Epoch  3, Batch  55 -Loss:     1.1600 Training Accuracy: 0.767608 Validation Accuracy: 0.724036\n",
      "Epoch  3, Batch  56 -Loss:     1.2833 Training Accuracy: 0.757292 Validation Accuracy: 0.705215\n",
      "Epoch  3, Batch  57 -Loss:     1.2861 Training Accuracy: 0.751660 Validation Accuracy: 0.707710\n",
      "Epoch  3, Batch  58 -Loss:     1.3443 Training Accuracy: 0.751401 Validation Accuracy: 0.705669\n",
      "Epoch  3, Batch  59 -Loss:     1.2134 Training Accuracy: 0.756027 Validation Accuracy: 0.702948\n",
      "Epoch  3, Batch  60 -Loss:     1.2294 Training Accuracy: 0.749993 Validation Accuracy: 0.694785\n",
      "Epoch  3, Batch  61 -Loss:     1.2524 Training Accuracy: 0.747177 Validation Accuracy: 0.687302\n",
      "Epoch  3, Batch  62 -Loss:     1.3715 Training Accuracy: 0.756861 Validation Accuracy: 0.692290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3, Batch  63 -Loss:     1.0782 Training Accuracy: 0.764591 Validation Accuracy: 0.690703\n",
      "Epoch  3, Batch  64 -Loss:     1.2326 Training Accuracy: 0.761258 Validation Accuracy: 0.687755\n",
      "Epoch  3, Batch  65 -Loss:     1.1472 Training Accuracy: 0.748441 Validation Accuracy: 0.680952\n",
      "Epoch  3, Batch  66 -Loss:     1.3322 Training Accuracy: 0.757924 Validation Accuracy: 0.703175\n",
      "Epoch  3, Batch  67 -Loss:     1.1562 Training Accuracy: 0.761315 Validation Accuracy: 0.710204\n",
      "Epoch  3, Batch  68 -Loss:     1.4333 Training Accuracy: 0.775913 Validation Accuracy: 0.727664\n",
      "Epoch  3, Batch  69 -Loss:     1.3383 Training Accuracy: 0.787207 Validation Accuracy: 0.740363\n",
      "Epoch  3, Batch  70 -Loss:     1.1684 Training Accuracy: 0.786517 Validation Accuracy: 0.733787\n",
      "Epoch  3, Batch  71 -Loss:     1.4430 Training Accuracy: 0.783385 Validation Accuracy: 0.719955\n",
      "Epoch  3, Batch  72 -Loss:     1.4134 Training Accuracy: 0.777321 Validation Accuracy: 0.711565\n",
      "Epoch  3, Batch  73 -Loss:     1.1191 Training Accuracy: 0.779649 Validation Accuracy: 0.710884\n",
      "Epoch  3, Batch  74 -Loss:     1.2735 Training Accuracy: 0.781402 Validation Accuracy: 0.712925\n",
      "Epoch  3, Batch  75 -Loss:     1.2168 Training Accuracy: 0.779361 Validation Accuracy: 0.714966\n",
      "Epoch  3, Batch  76 -Loss:     1.1265 Training Accuracy: 0.774850 Validation Accuracy: 0.710204\n",
      "Epoch  3, Batch  77 -Loss:     1.4832 Training Accuracy: 0.765913 Validation Accuracy: 0.703175\n",
      "Epoch  3, Batch  78 -Loss:     1.3497 Training Accuracy: 0.761028 Validation Accuracy: 0.704762\n",
      "Epoch  3, Batch  79 -Loss:     1.4387 Training Accuracy: 0.771488 Validation Accuracy: 0.719728\n",
      "Epoch  3, Batch  80 -Loss:     1.2289 Training Accuracy: 0.777723 Validation Accuracy: 0.731973\n",
      "Epoch  3, Batch  81 -Loss:     1.1875 Training Accuracy: 0.773672 Validation Accuracy: 0.730839\n",
      "Epoch  3, Batch  82 -Loss:     1.3789 Training Accuracy: 0.771861 Validation Accuracy: 0.726077\n",
      "Epoch  3, Batch  83 -Loss:     1.3433 Training Accuracy: 0.774045 Validation Accuracy: 0.728118\n",
      "Epoch  3, Batch  84 -Loss:     1.3152 Training Accuracy: 0.783327 Validation Accuracy: 0.736281\n",
      "Epoch  3, Batch  85 -Loss:     1.2976 Training Accuracy: 0.789707 Validation Accuracy: 0.747392\n",
      "Epoch  3, Batch  86 -Loss:     1.2673 Training Accuracy: 0.788615 Validation Accuracy: 0.747392\n",
      "Epoch  3, Batch  87 -Loss:     1.1003 Training Accuracy: 0.782637 Validation Accuracy: 0.737188\n",
      "Epoch  3, Batch  88 -Loss:     1.2057 Training Accuracy: 0.775338 Validation Accuracy: 0.726304\n",
      "Epoch  3, Batch  89 -Loss:     1.3407 Training Accuracy: 0.778068 Validation Accuracy: 0.730839\n",
      "Epoch  3, Batch  90 -Loss:     1.3523 Training Accuracy: 0.776718 Validation Accuracy: 0.729705\n",
      "Epoch  3, Batch  91 -Loss:     1.2375 Training Accuracy: 0.782551 Validation Accuracy: 0.740136\n",
      "Epoch  3, Batch  92 -Loss:     1.3280 Training Accuracy: 0.789735 Validation Accuracy: 0.744671\n",
      "Epoch  3, Batch  93 -Loss:     1.2515 Training Accuracy: 0.782810 Validation Accuracy: 0.734467\n",
      "Epoch  3, Batch  94 -Loss:     1.2417 Training Accuracy: 0.775080 Validation Accuracy: 0.729252\n",
      "Epoch  3, Batch  95 -Loss:     1.1580 Training Accuracy: 0.781862 Validation Accuracy: 0.733787\n",
      "Epoch  3, Batch  96 -Loss:     1.2350 Training Accuracy: 0.782436 Validation Accuracy: 0.730839\n",
      "Epoch  3, Batch  97 -Loss:     1.2318 Training Accuracy: 0.781086 Validation Accuracy: 0.724717\n",
      "Epoch  3, Batch  98 -Loss:     1.1207 Training Accuracy: 0.778298 Validation Accuracy: 0.727664\n",
      "Epoch  3, Batch  99 -Loss:     1.1582 Training Accuracy: 0.754504 Validation Accuracy: 0.707937\n",
      "Epoch  3, Batch 100 -Loss:     1.2605 Training Accuracy: 0.738240 Validation Accuracy: 0.702041\n",
      "Epoch  3, Batch 101 -Loss:     1.2963 Training Accuracy: 0.767723 Validation Accuracy: 0.726077\n",
      "Epoch  3, Batch 102 -Loss:     1.1718 Training Accuracy: 0.784477 Validation Accuracy: 0.742857\n",
      "Epoch  3, Batch 103 -Loss:     1.1304 Training Accuracy: 0.769993 Validation Accuracy: 0.726984\n",
      "Epoch  3, Batch 104 -Loss:     1.3849 Training Accuracy: 0.765309 Validation Accuracy: 0.724943\n",
      "Epoch  3, Batch 105 -Loss:     1.3542 Training Accuracy: 0.778614 Validation Accuracy: 0.734921\n",
      "Epoch  3, Batch 106 -Loss:     1.3201 Training Accuracy: 0.789333 Validation Accuracy: 0.733787\n",
      "Epoch  3, Batch 107 -Loss:     1.3198 Training Accuracy: 0.771545 Validation Accuracy: 0.703401\n",
      "Epoch  3, Batch 108 -Loss:     1.2259 Training Accuracy: 0.753786 Validation Accuracy: 0.686848\n",
      "Epoch  3, Batch 109 -Loss:     1.2630 Training Accuracy: 0.760424 Validation Accuracy: 0.692517\n",
      "Epoch  3, Batch 110 -Loss:     1.2306 Training Accuracy: 0.776718 Validation Accuracy: 0.724036\n",
      "Epoch  3, Batch 111 -Loss:     1.2356 Training Accuracy: 0.786517 Validation Accuracy: 0.751701\n",
      "Epoch  3, Batch 112 -Loss:     1.2149 Training Accuracy: 0.787005 Validation Accuracy: 0.750567\n",
      "Epoch  3, Batch 113 -Loss:     1.1485 Training Accuracy: 0.784764 Validation Accuracy: 0.748526\n",
      "Epoch  3, Batch 114 -Loss:     1.0152 Training Accuracy: 0.777609 Validation Accuracy: 0.742177\n",
      "Epoch  3, Batch 115 -Loss:     1.1544 Training Accuracy: 0.776028 Validation Accuracy: 0.736961\n",
      "Epoch  3, Batch 116 -Loss:     1.3146 Training Accuracy: 0.780195 Validation Accuracy: 0.740590\n",
      "Epoch  3, Batch 117 -Loss:     1.0761 Training Accuracy: 0.775971 Validation Accuracy: 0.739456\n",
      "Epoch  3, Batch 118 -Loss:     1.2539 Training Accuracy: 0.776660 Validation Accuracy: 0.744218\n",
      "Epoch  3, Batch 119 -Loss:     1.2700 Training Accuracy: 0.769160 Validation Accuracy: 0.725624\n",
      "Epoch  3, Batch 120 -Loss:     1.1392 Training Accuracy: 0.765884 Validation Accuracy: 0.716780\n",
      "Epoch  3, Batch 121 -Loss:     1.0718 Training Accuracy: 0.757953 Validation Accuracy: 0.712245\n",
      "Epoch  3, Batch 122 -Loss:     1.2530 Training Accuracy: 0.761804 Validation Accuracy: 0.717007\n",
      "Epoch  3, Batch 123 -Loss:     1.4949 Training Accuracy: 0.767091 Validation Accuracy: 0.715193\n",
      "Epoch  3, Batch 124 -Loss:     1.2969 Training Accuracy: 0.765108 Validation Accuracy: 0.723129\n",
      "Epoch  3, Batch 125 -Loss:     1.1678 Training Accuracy: 0.777925 Validation Accuracy: 0.736508\n",
      "Epoch  3, Batch 126 -Loss:     1.2954 Training Accuracy: 0.782350 Validation Accuracy: 0.726984\n",
      "Epoch  3, Batch 127 -Loss:     1.4209 Training Accuracy: 0.756947 Validation Accuracy: 0.706803\n",
      "Epoch  3, Batch 128 -Loss:     1.3873 Training Accuracy: 0.764821 Validation Accuracy: 0.715646\n",
      "Epoch  3, Batch 129 -Loss:     1.4393 Training Accuracy: 0.767924 Validation Accuracy: 0.726077\n",
      "Epoch  3, Batch 130 -Loss:     1.2806 Training Accuracy: 0.774850 Validation Accuracy: 0.734240\n",
      "Epoch  3, Batch 131 -Loss:     1.1841 Training Accuracy: 0.800138 Validation Accuracy: 0.752834\n",
      "Epoch  3, Batch 132 -Loss:     1.0871 Training Accuracy: 0.807667 Validation Accuracy: 0.758730\n",
      "Epoch  3, Batch 133 -Loss:     1.2668 Training Accuracy: 0.786919 Validation Accuracy: 0.725850\n",
      "Epoch  3, Batch 134 -Loss:     1.2007 Training Accuracy: 0.769649 Validation Accuracy: 0.702721\n",
      "Epoch  3, Batch 135 -Loss:     1.2474 Training Accuracy: 0.763901 Validation Accuracy: 0.694558\n",
      "Epoch  3, Batch 136 -Loss:     1.2722 Training Accuracy: 0.760223 Validation Accuracy: 0.685488\n",
      "Epoch  3, Batch 137 -Loss:     1.2899 Training Accuracy: 0.765654 Validation Accuracy: 0.690476\n",
      "Epoch  3, Batch 138 -Loss:     1.2856 Training Accuracy: 0.762177 Validation Accuracy: 0.699773\n",
      "Epoch  3, Batch 139 -Loss:     1.3265 Training Accuracy: 0.782896 Validation Accuracy: 0.723129\n",
      "Epoch  3, Batch 140 -Loss:     1.3965 Training Accuracy: 0.801172 Validation Accuracy: 0.746258\n",
      "Epoch  3, Batch 141 -Loss:     1.1424 Training Accuracy: 0.785655 Validation Accuracy: 0.740590\n",
      "Epoch  3, Batch 142 -Loss:     1.2337 Training Accuracy: 0.760913 Validation Accuracy: 0.717234\n",
      "Epoch  3, Batch 143 -Loss:     1.3535 Training Accuracy: 0.758326 Validation Accuracy: 0.718821\n",
      "Epoch  3, Batch 144 -Loss:     1.1699 Training Accuracy: 0.772005 Validation Accuracy: 0.730385\n",
      "Epoch  3, Batch 145 -Loss:     1.0822 Training Accuracy: 0.786804 Validation Accuracy: 0.739002\n",
      "Epoch  3, Batch 146 -Loss:     1.2763 Training Accuracy: 0.781229 Validation Accuracy: 0.729478\n",
      "Epoch  3, Batch 147 -Loss:     1.2008 Training Accuracy: 0.779074 Validation Accuracy: 0.719955\n",
      "Epoch  3, Batch 148 -Loss:     1.2731 Training Accuracy: 0.781114 Validation Accuracy: 0.722902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3, Batch 149 -Loss:     1.1707 Training Accuracy: 0.787609 Validation Accuracy: 0.726077\n",
      "Epoch  3, Batch 150 -Loss:     1.1005 Training Accuracy: 0.800368 Validation Accuracy: 0.742404\n",
      "Epoch  3, Batch 151 -Loss:     1.3187 Training Accuracy: 0.804104 Validation Accuracy: 0.753061\n",
      "Epoch  3, Batch 152 -Loss:     1.0678 Training Accuracy: 0.800684 Validation Accuracy: 0.745578\n",
      "Epoch  3, Batch 153 -Loss:     1.2431 Training Accuracy: 0.798356 Validation Accuracy: 0.739002\n",
      "Epoch  3, Batch 154 -Loss:     1.2003 Training Accuracy: 0.796948 Validation Accuracy: 0.737415\n",
      "Epoch  3, Batch 155 -Loss:     1.2186 Training Accuracy: 0.781689 Validation Accuracy: 0.717460\n",
      "Epoch  3, Batch 156 -Loss:     1.4777 Training Accuracy: 0.773557 Validation Accuracy: 0.707483\n",
      "Epoch  3, Batch 157 -Loss:     1.1237 Training Accuracy: 0.790166 Validation Accuracy: 0.722902\n",
      "Epoch  3, Batch 158 -Loss:     1.3525 Training Accuracy: 0.800885 Validation Accuracy: 0.736961\n",
      "Epoch  3, Batch 159 -Loss:     1.2104 Training Accuracy: 0.793615 Validation Accuracy: 0.728345\n",
      "Epoch  3, Batch 160 -Loss:     1.2964 Training Accuracy: 0.783068 Validation Accuracy: 0.723583\n",
      "Epoch  3, Batch 161 -Loss:     1.3963 Training Accuracy: 0.781028 Validation Accuracy: 0.715193\n",
      "Epoch  3, Batch 162 -Loss:     1.2854 Training Accuracy: 0.772752 Validation Accuracy: 0.705896\n",
      "Epoch  3, Batch 163 -Loss:     1.1252 Training Accuracy: 0.745884 Validation Accuracy: 0.686168\n",
      "Epoch  3, Batch 164 -Loss:     1.2491 Training Accuracy: 0.761660 Validation Accuracy: 0.704989\n",
      "Epoch  3, Batch 165 -Loss:     1.2042 Training Accuracy: 0.781574 Validation Accuracy: 0.723583\n",
      "Epoch  3, Batch 166 -Loss:     1.1880 Training Accuracy: 0.779793 Validation Accuracy: 0.731066\n",
      "Epoch  3, Batch 167 -Loss:     1.1517 Training Accuracy: 0.781229 Validation Accuracy: 0.733560\n",
      "Epoch  3, Batch 168 -Loss:     1.1341 Training Accuracy: 0.785827 Validation Accuracy: 0.732880\n",
      "Epoch  3, Batch 169 -Loss:     1.2075 Training Accuracy: 0.792034 Validation Accuracy: 0.735147\n",
      "Epoch  3, Batch 170 -Loss:     1.2533 Training Accuracy: 0.777494 Validation Accuracy: 0.728571\n",
      "Epoch  3, Batch 171 -Loss:     1.2030 Training Accuracy: 0.770913 Validation Accuracy: 0.720408\n",
      "Epoch  3, Batch 172 -Loss:     1.1448 Training Accuracy: 0.772177 Validation Accuracy: 0.720181\n",
      "Epoch  3, Batch 173 -Loss:     0.9893 Training Accuracy: 0.777206 Validation Accuracy: 0.721088\n",
      "Epoch  3, Batch 174 -Loss:     1.2427 Training Accuracy: 0.782063 Validation Accuracy: 0.723810\n",
      "Epoch  3, Batch 175 -Loss:     1.0948 Training Accuracy: 0.786201 Validation Accuracy: 0.726077\n",
      "Epoch  3, Batch 176 -Loss:     1.1655 Training Accuracy: 0.793241 Validation Accuracy: 0.731973\n",
      "Epoch  3, Batch 177 -Loss:     1.1937 Training Accuracy: 0.799247 Validation Accuracy: 0.727211\n",
      "Epoch  3, Batch 178 -Loss:     1.2398 Training Accuracy: 0.796804 Validation Accuracy: 0.720408\n",
      "Epoch  3, Batch 179 -Loss:     1.2600 Training Accuracy: 0.792925 Validation Accuracy: 0.721769\n",
      "Epoch  3, Batch 180 -Loss:     1.2437 Training Accuracy: 0.795827 Validation Accuracy: 0.722902\n",
      "Epoch  3, Batch 181 -Loss:     1.1171 Training Accuracy: 0.786028 Validation Accuracy: 0.732653\n",
      "Epoch  3, Batch 182 -Loss:     1.2175 Training Accuracy: 0.778959 Validation Accuracy: 0.731973\n",
      "Epoch  3, Batch 183 -Loss:     1.1690 Training Accuracy: 0.778988 Validation Accuracy: 0.733560\n",
      "Epoch  3, Batch 184 -Loss:     1.1220 Training Accuracy: 0.790942 Validation Accuracy: 0.742857\n",
      "Epoch  3, Batch 185 -Loss:     0.9857 Training Accuracy: 0.796488 Validation Accuracy: 0.744898\n",
      "Epoch  3, Batch 186 -Loss:     1.1519 Training Accuracy: 0.793902 Validation Accuracy: 0.743311\n",
      "Epoch  3, Batch 187 -Loss:     1.2426 Training Accuracy: 0.789448 Validation Accuracy: 0.735601\n",
      "Epoch  3, Batch 188 -Loss:     1.2102 Training Accuracy: 0.797753 Validation Accuracy: 0.739683\n",
      "Epoch  3, Batch 189 -Loss:     1.1613 Training Accuracy: 0.798672 Validation Accuracy: 0.737415\n",
      "Epoch  3, Batch 190 -Loss:     1.2092 Training Accuracy: 0.798586 Validation Accuracy: 0.731293\n",
      "Epoch  3, Batch 191 -Loss:     1.1649 Training Accuracy: 0.798098 Validation Accuracy: 0.735601\n",
      "Epoch  3, Batch 192 -Loss:     1.3078 Training Accuracy: 0.795425 Validation Accuracy: 0.730612\n",
      "Epoch  3, Batch 193 -Loss:     1.2768 Training Accuracy: 0.799678 Validation Accuracy: 0.733787\n",
      "Epoch  3, Batch 194 -Loss:     1.0884 Training Accuracy: 0.806403 Validation Accuracy: 0.735147\n",
      "Epoch  3, Batch 195 -Loss:     0.9951 Training Accuracy: 0.811776 Validation Accuracy: 0.736508\n",
      "Epoch  3, Batch 196 -Loss:     1.1266 Training Accuracy: 0.810081 Validation Accuracy: 0.730159\n",
      "Epoch  3, Batch 197 -Loss:     0.9373 Training Accuracy: 0.796172 Validation Accuracy: 0.724490\n",
      "Epoch  3, Batch 198 -Loss:     1.3972 Training Accuracy: 0.800598 Validation Accuracy: 0.721995\n",
      "Epoch  3, Batch 199 -Loss:     1.1826 Training Accuracy: 0.801086 Validation Accuracy: 0.723129\n",
      "Epoch  3, Batch 200 -Loss:     1.1135 Training Accuracy: 0.792322 Validation Accuracy: 0.706803\n",
      "Epoch  3, Batch 201 -Loss:     1.1514 Training Accuracy: 0.782005 Validation Accuracy: 0.710431\n",
      "Epoch  3, Batch 202 -Loss:     1.1597 Training Accuracy: 0.781373 Validation Accuracy: 0.720635\n",
      "Epoch  3, Batch 203 -Loss:     1.0585 Training Accuracy: 0.790310 Validation Accuracy: 0.742177\n",
      "Epoch  3, Batch 204 -Loss:     1.0708 Training Accuracy: 0.792149 Validation Accuracy: 0.753968\n",
      "Epoch  3, Batch 205 -Loss:     1.1918 Training Accuracy: 0.810828 Validation Accuracy: 0.769615\n",
      "Epoch  3, Batch 206 -Loss:     1.1340 Training Accuracy: 0.813414 Validation Accuracy: 0.751927\n",
      "Epoch  3, Batch 207 -Loss:     1.1840 Training Accuracy: 0.808931 Validation Accuracy: 0.736735\n",
      "Epoch  3, Batch 208 -Loss:     1.2835 Training Accuracy: 0.798759 Validation Accuracy: 0.727438\n",
      "Epoch  3, Batch 209 -Loss:     1.3184 Training Accuracy: 0.789218 Validation Accuracy: 0.722449\n",
      "Epoch  3, Batch 210 -Loss:     1.1330 Training Accuracy: 0.794506 Validation Accuracy: 0.735828\n",
      "Epoch  3, Batch 211 -Loss:     1.1608 Training Accuracy: 0.790626 Validation Accuracy: 0.733107\n",
      "Epoch  3, Batch 212 -Loss:     1.2107 Training Accuracy: 0.788787 Validation Accuracy: 0.722902\n",
      "Epoch  3, Batch 213 -Loss:     1.2171 Training Accuracy: 0.799420 Validation Accuracy: 0.733107\n",
      "Epoch  3, Batch 214 -Loss:     1.0567 Training Accuracy: 0.807207 Validation Accuracy: 0.741497\n",
      "Epoch  3, Batch 215 -Loss:     1.2003 Training Accuracy: 0.804592 Validation Accuracy: 0.738775\n",
      "Epoch  3, Batch 216 -Loss:     1.1346 Training Accuracy: 0.801920 Validation Accuracy: 0.736961\n",
      "Epoch  3, Batch 217 -Loss:     1.1117 Training Accuracy: 0.807494 Validation Accuracy: 0.743084\n",
      "Epoch  3, Batch 218 -Loss:     1.0853 Training Accuracy: 0.800253 Validation Accuracy: 0.728118\n",
      "Epoch  3, Batch 219 -Loss:     1.2649 Training Accuracy: 0.787321 Validation Accuracy: 0.714512\n",
      "Epoch  3, Batch 220 -Loss:     1.1273 Training Accuracy: 0.792034 Validation Accuracy: 0.724943\n",
      "Epoch  3, Batch 221 -Loss:     1.1583 Training Accuracy: 0.805885 Validation Accuracy: 0.736961\n",
      "Epoch  3, Batch 222 -Loss:     1.0765 Training Accuracy: 0.810052 Validation Accuracy: 0.746939\n",
      "Epoch  3, Batch 223 -Loss:     1.1025 Training Accuracy: 0.814707 Validation Accuracy: 0.760317\n",
      "Epoch  3, Batch 224 -Loss:     1.1947 Training Accuracy: 0.818903 Validation Accuracy: 0.761225\n",
      "Epoch  3, Batch 225 -Loss:     1.1808 Training Accuracy: 0.814679 Validation Accuracy: 0.755102\n",
      "Epoch  3, Batch 226 -Loss:     1.1670 Training Accuracy: 0.808299 Validation Accuracy: 0.750567\n",
      "Epoch  3, Batch 227 -Loss:     1.2104 Training Accuracy: 0.804075 Validation Accuracy: 0.742404\n",
      "Epoch  3, Batch 228 -Loss:     1.1452 Training Accuracy: 0.808184 Validation Accuracy: 0.741497\n",
      "Epoch  3, Batch 229 -Loss:     1.3033 Training Accuracy: 0.803960 Validation Accuracy: 0.733560\n",
      "Epoch  3, Batch 230 -Loss:     1.3280 Training Accuracy: 0.811288 Validation Accuracy: 0.739229\n",
      "Epoch  3, Batch 231 -Loss:     1.1516 Training Accuracy: 0.812178 Validation Accuracy: 0.746258\n",
      "Epoch  3, Batch 232 -Loss:     1.0682 Training Accuracy: 0.808155 Validation Accuracy: 0.746485\n",
      "Epoch  3, Batch 233 -Loss:     1.0601 Training Accuracy: 0.817466 Validation Accuracy: 0.755782\n",
      "Epoch  3, Batch 234 -Loss:     1.1141 Training Accuracy: 0.816748 Validation Accuracy: 0.757596\n",
      "Epoch  3, Batch 235 -Loss:     1.2157 Training Accuracy: 0.812006 Validation Accuracy: 0.756689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3, Batch 236 -Loss:     1.0856 Training Accuracy: 0.803414 Validation Accuracy: 0.741497\n",
      "Epoch  3, Batch 237 -Loss:     1.2033 Training Accuracy: 0.793902 Validation Accuracy: 0.734694\n",
      "Epoch  3, Batch 238 -Loss:     1.1664 Training Accuracy: 0.807609 Validation Accuracy: 0.746485\n",
      "Epoch  3, Batch 239 -Loss:     1.0463 Training Accuracy: 0.819305 Validation Accuracy: 0.762358\n",
      "Epoch  3, Batch 240 -Loss:     1.1699 Training Accuracy: 0.810655 Validation Accuracy: 0.756689\n",
      "Epoch  3, Batch 241 -Loss:     1.3461 Training Accuracy: 0.808644 Validation Accuracy: 0.751020\n",
      "Epoch  3, Batch 242 -Loss:     0.9811 Training Accuracy: 0.813069 Validation Accuracy: 0.747166\n",
      "Epoch  3, Batch 243 -Loss:     1.1052 Training Accuracy: 0.813414 Validation Accuracy: 0.742404\n",
      "Epoch  3, Batch 244 -Loss:     1.0521 Training Accuracy: 0.801805 Validation Accuracy: 0.735374\n",
      "Epoch  3, Batch 245 -Loss:     1.1084 Training Accuracy: 0.794304 Validation Accuracy: 0.731293\n",
      "Epoch  3, Batch 246 -Loss:     1.1326 Training Accuracy: 0.797954 Validation Accuracy: 0.736281\n",
      "Epoch  3, Batch 247 -Loss:     1.2736 Training Accuracy: 0.808931 Validation Accuracy: 0.752608\n",
      "Epoch  3, Batch 248 -Loss:     1.1274 Training Accuracy: 0.811029 Validation Accuracy: 0.759410\n",
      "Epoch  3, Batch 249 -Loss:     1.1227 Training Accuracy: 0.814477 Validation Accuracy: 0.763039\n",
      "Epoch  3, Batch 250 -Loss:     1.0675 Training Accuracy: 0.820684 Validation Accuracy: 0.770068\n",
      "Epoch  3, Batch 251 -Loss:     1.1672 Training Accuracy: 0.814592 Validation Accuracy: 0.758277\n",
      "Epoch  3, Batch 252 -Loss:     1.1549 Training Accuracy: 0.808357 Validation Accuracy: 0.750340\n",
      "Epoch  3, Batch 253 -Loss:     1.0795 Training Accuracy: 0.811546 Validation Accuracy: 0.760771\n",
      "Epoch  3, Batch 254 -Loss:     1.0079 Training Accuracy: 0.816949 Validation Accuracy: 0.772336\n",
      "Epoch  3, Batch 255 -Loss:     1.1209 Training Accuracy: 0.813500 Validation Accuracy: 0.768254\n",
      "Epoch  3, Batch 256 -Loss:     1.1241 Training Accuracy: 0.817006 Validation Accuracy: 0.765760\n",
      "Epoch  3, Batch 257 -Loss:     1.1134 Training Accuracy: 0.832064 Validation Accuracy: 0.775737\n",
      "Epoch  3, Batch 258 -Loss:     1.2142 Training Accuracy: 0.828587 Validation Accuracy: 0.767347\n",
      "Epoch  3, Batch 259 -Loss:     1.2000 Training Accuracy: 0.810483 Validation Accuracy: 0.746939\n",
      "Epoch  3, Batch 260 -Loss:     1.0832 Training Accuracy: 0.796230 Validation Accuracy: 0.730839\n",
      "Epoch  3, Batch 261 -Loss:     1.0327 Training Accuracy: 0.799218 Validation Accuracy: 0.728571\n",
      "Epoch  3, Batch 262 -Loss:     1.0290 Training Accuracy: 0.804448 Validation Accuracy: 0.727211\n",
      "Epoch  3, Batch 263 -Loss:     1.0526 Training Accuracy: 0.808903 Validation Accuracy: 0.728345\n",
      "Epoch  3, Batch 264 -Loss:     0.9692 Training Accuracy: 0.815081 Validation Accuracy: 0.737188\n",
      "Epoch  3, Batch 265 -Loss:     1.0259 Training Accuracy: 0.818730 Validation Accuracy: 0.738775\n",
      "Epoch  3, Batch 266 -Loss:     1.0133 Training Accuracy: 0.814133 Validation Accuracy: 0.741723\n",
      "Epoch  3, Batch 267 -Loss:     1.1803 Training Accuracy: 0.810397 Validation Accuracy: 0.740363\n",
      "Epoch  3, Batch 268 -Loss:     1.1981 Training Accuracy: 0.808558 Validation Accuracy: 0.745578\n",
      "Epoch  3, Batch 269 -Loss:     1.1393 Training Accuracy: 0.812293 Validation Accuracy: 0.749887\n",
      "Epoch  3, Batch 270 -Loss:     1.1981 Training Accuracy: 0.808644 Validation Accuracy: 0.745125\n",
      "Epoch  3, Batch 271 -Loss:     1.1832 Training Accuracy: 0.808874 Validation Accuracy: 0.741950\n",
      "Epoch  3, Batch 272 -Loss:     1.2255 Training Accuracy: 0.817638 Validation Accuracy: 0.754195\n",
      "Epoch  4, Batch   1 -Loss:     1.1659 Training Accuracy: 0.829679 Validation Accuracy: 0.764626\n",
      "Epoch  4, Batch   2 -Loss:     1.0325 Training Accuracy: 0.831145 Validation Accuracy: 0.762132\n",
      "Epoch  4, Batch   3 -Loss:     0.9793 Training Accuracy: 0.817897 Validation Accuracy: 0.744898\n",
      "Epoch  4, Batch   4 -Loss:     1.0930 Training Accuracy: 0.807035 Validation Accuracy: 0.729932\n",
      "Epoch  4, Batch   5 -Loss:     1.0253 Training Accuracy: 0.801086 Validation Accuracy: 0.723129\n",
      "Epoch  4, Batch   6 -Loss:     1.0395 Training Accuracy: 0.802782 Validation Accuracy: 0.724490\n",
      "Epoch  4, Batch   7 -Loss:     1.0772 Training Accuracy: 0.804650 Validation Accuracy: 0.730385\n",
      "Epoch  4, Batch   8 -Loss:     1.2191 Training Accuracy: 0.807437 Validation Accuracy: 0.736735\n",
      "Epoch  4, Batch   9 -Loss:     1.3359 Training Accuracy: 0.817638 Validation Accuracy: 0.752608\n",
      "Epoch  4, Batch  10 -Loss:     1.0608 Training Accuracy: 0.816345 Validation Accuracy: 0.763946\n",
      "Epoch  4, Batch  11 -Loss:     1.2220 Training Accuracy: 0.824823 Validation Accuracy: 0.773469\n",
      "Epoch  4, Batch  12 -Loss:     1.0819 Training Accuracy: 0.819707 Validation Accuracy: 0.768707\n",
      "Epoch  4, Batch  13 -Loss:     1.1341 Training Accuracy: 0.810454 Validation Accuracy: 0.760998\n",
      "Epoch  4, Batch  14 -Loss:     1.0494 Training Accuracy: 0.818587 Validation Accuracy: 0.765079\n",
      "Epoch  4, Batch  15 -Loss:     1.1528 Training Accuracy: 0.818414 Validation Accuracy: 0.764399\n",
      "Epoch  4, Batch  16 -Loss:     1.1639 Training Accuracy: 0.820052 Validation Accuracy: 0.763946\n",
      "Epoch  4, Batch  17 -Loss:     1.0596 Training Accuracy: 0.826144 Validation Accuracy: 0.766667\n",
      "Epoch  4, Batch  18 -Loss:     1.0356 Training Accuracy: 0.829535 Validation Accuracy: 0.764853\n",
      "Epoch  4, Batch  19 -Loss:     1.0947 Training Accuracy: 0.812581 Validation Accuracy: 0.744898\n",
      "Epoch  4, Batch  20 -Loss:     1.1290 Training Accuracy: 0.805914 Validation Accuracy: 0.735828\n",
      "Epoch  4, Batch  21 -Loss:     1.1205 Training Accuracy: 0.819937 Validation Accuracy: 0.748980\n",
      "Epoch  4, Batch  22 -Loss:     1.1426 Training Accuracy: 0.803299 Validation Accuracy: 0.732880\n",
      "Epoch  4, Batch  23 -Loss:     1.1527 Training Accuracy: 0.794822 Validation Accuracy: 0.728118\n",
      "Epoch  4, Batch  24 -Loss:     1.0816 Training Accuracy: 0.800885 Validation Accuracy: 0.737415\n",
      "Epoch  4, Batch  25 -Loss:     1.1415 Training Accuracy: 0.814276 Validation Accuracy: 0.745351\n",
      "Epoch  4, Batch  26 -Loss:     1.0803 Training Accuracy: 0.821547 Validation Accuracy: 0.747392\n",
      "Epoch  4, Batch  27 -Loss:     1.2006 Training Accuracy: 0.828817 Validation Accuracy: 0.754195\n",
      "Epoch  4, Batch  28 -Loss:     1.1094 Training Accuracy: 0.824277 Validation Accuracy: 0.759184\n",
      "Epoch  4, Batch  29 -Loss:     1.1054 Training Accuracy: 0.817265 Validation Accuracy: 0.755556\n",
      "Epoch  4, Batch  30 -Loss:     1.1032 Training Accuracy: 0.818759 Validation Accuracy: 0.756236\n",
      "Epoch  4, Batch  31 -Loss:     1.0903 Training Accuracy: 0.813529 Validation Accuracy: 0.755556\n",
      "Epoch  4, Batch  32 -Loss:     1.0782 Training Accuracy: 0.822725 Validation Accuracy: 0.761225\n",
      "Epoch  4, Batch  33 -Loss:     1.1463 Training Accuracy: 0.826604 Validation Accuracy: 0.768254\n",
      "Epoch  4, Batch  34 -Loss:     1.0698 Training Accuracy: 0.821116 Validation Accuracy: 0.765760\n",
      "Epoch  4, Batch  35 -Loss:     1.1749 Training Accuracy: 0.807523 Validation Accuracy: 0.754649\n",
      "Epoch  4, Batch  36 -Loss:     1.2573 Training Accuracy: 0.806776 Validation Accuracy: 0.757370\n",
      "Epoch  4, Batch  37 -Loss:     1.0161 Training Accuracy: 0.804707 Validation Accuracy: 0.750794\n",
      "Epoch  4, Batch  38 -Loss:     1.0684 Training Accuracy: 0.813414 Validation Accuracy: 0.761451\n",
      "Epoch  4, Batch  39 -Loss:     1.0193 Training Accuracy: 0.818615 Validation Accuracy: 0.763039\n",
      "Epoch  4, Batch  40 -Loss:     1.1653 Training Accuracy: 0.820570 Validation Accuracy: 0.765079\n",
      "Epoch  4, Batch  41 -Loss:     1.1580 Training Accuracy: 0.826432 Validation Accuracy: 0.776644\n",
      "Epoch  4, Batch  42 -Loss:     1.0548 Training Accuracy: 0.819161 Validation Accuracy: 0.771202\n",
      "Epoch  4, Batch  43 -Loss:     1.1086 Training Accuracy: 0.827466 Validation Accuracy: 0.773923\n",
      "Epoch  4, Batch  44 -Loss:     0.9905 Training Accuracy: 0.834449 Validation Accuracy: 0.786848\n",
      "Epoch  4, Batch  45 -Loss:     1.0887 Training Accuracy: 0.840656 Validation Accuracy: 0.783900\n",
      "Epoch  4, Batch  46 -Loss:     0.9691 Training Accuracy: 0.827696 Validation Accuracy: 0.763719\n",
      "Epoch  4, Batch  47 -Loss:     1.1828 Training Accuracy: 0.816115 Validation Accuracy: 0.749206\n",
      "Epoch  4, Batch  48 -Loss:     1.2885 Training Accuracy: 0.816978 Validation Accuracy: 0.749433\n",
      "Epoch  4, Batch  49 -Loss:     1.0080 Training Accuracy: 0.814018 Validation Accuracy: 0.747392\n",
      "Epoch  4, Batch  50 -Loss:     1.1654 Training Accuracy: 0.808558 Validation Accuracy: 0.752834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4, Batch  51 -Loss:     1.0613 Training Accuracy: 0.787580 Validation Accuracy: 0.735147\n",
      "Epoch  4, Batch  52 -Loss:     1.0108 Training Accuracy: 0.779218 Validation Accuracy: 0.732426\n",
      "Epoch  4, Batch  53 -Loss:     1.1475 Training Accuracy: 0.791603 Validation Accuracy: 0.747846\n",
      "Epoch  4, Batch  54 -Loss:     1.0724 Training Accuracy: 0.827179 Validation Accuracy: 0.776871\n",
      "Epoch  4, Batch  55 -Loss:     0.9587 Training Accuracy: 0.823185 Validation Accuracy: 0.757143\n",
      "Epoch  4, Batch  56 -Loss:     1.0949 Training Accuracy: 0.810311 Validation Accuracy: 0.723129\n",
      "Epoch  4, Batch  57 -Loss:     1.2332 Training Accuracy: 0.788902 Validation Accuracy: 0.722449\n",
      "Epoch  4, Batch  58 -Loss:     1.1006 Training Accuracy: 0.787350 Validation Accuracy: 0.730839\n",
      "Epoch  4, Batch  59 -Loss:     1.0931 Training Accuracy: 0.820598 Validation Accuracy: 0.772109\n",
      "Epoch  4, Batch  60 -Loss:     1.0682 Training Accuracy: 0.835168 Validation Accuracy: 0.785034\n",
      "Epoch  4, Batch  61 -Loss:     1.0559 Training Accuracy: 0.823242 Validation Accuracy: 0.769841\n",
      "Epoch  4, Batch  62 -Loss:     1.1291 Training Accuracy: 0.812696 Validation Accuracy: 0.769388\n",
      "Epoch  4, Batch  63 -Loss:     1.1551 Training Accuracy: 0.814736 Validation Accuracy: 0.767347\n",
      "Epoch  4, Batch  64 -Loss:     1.1129 Training Accuracy: 0.805310 Validation Accuracy: 0.745125\n",
      "Epoch  4, Batch  65 -Loss:     1.2887 Training Accuracy: 0.796316 Validation Accuracy: 0.742177\n",
      "Epoch  4, Batch  66 -Loss:     1.0597 Training Accuracy: 0.805598 Validation Accuracy: 0.748299\n",
      "Epoch  4, Batch  67 -Loss:     1.1693 Training Accuracy: 0.818615 Validation Accuracy: 0.760544\n",
      "Epoch  4, Batch  68 -Loss:     1.0531 Training Accuracy: 0.809707 Validation Accuracy: 0.750567\n",
      "Epoch  4, Batch  69 -Loss:     1.0926 Training Accuracy: 0.811747 Validation Accuracy: 0.748980\n",
      "Epoch  4, Batch  70 -Loss:     1.2605 Training Accuracy: 0.821029 Validation Accuracy: 0.766213\n",
      "Epoch  4, Batch  71 -Loss:     0.9903 Training Accuracy: 0.816633 Validation Accuracy: 0.764399\n",
      "Epoch  4, Batch  72 -Loss:     1.0408 Training Accuracy: 0.810742 Validation Accuracy: 0.749433\n",
      "Epoch  4, Batch  73 -Loss:     1.1244 Training Accuracy: 0.817753 Validation Accuracy: 0.753288\n",
      "Epoch  4, Batch  74 -Loss:     1.0510 Training Accuracy: 0.827265 Validation Accuracy: 0.773016\n",
      "Epoch  4, Batch  75 -Loss:     1.2058 Training Accuracy: 0.824104 Validation Accuracy: 0.765986\n",
      "Epoch  4, Batch  76 -Loss:     1.0722 Training Accuracy: 0.816604 Validation Accuracy: 0.745351\n",
      "Epoch  4, Batch  77 -Loss:     0.9521 Training Accuracy: 0.826834 Validation Accuracy: 0.751247\n",
      "Epoch  4, Batch  78 -Loss:     1.1293 Training Accuracy: 0.835771 Validation Accuracy: 0.761905\n",
      "Epoch  4, Batch  79 -Loss:     1.0241 Training Accuracy: 0.828587 Validation Accuracy: 0.757823\n",
      "Epoch  4, Batch  80 -Loss:     1.0775 Training Accuracy: 0.823501 Validation Accuracy: 0.751247\n",
      "Epoch  4, Batch  81 -Loss:     1.0550 Training Accuracy: 0.826116 Validation Accuracy: 0.756009\n",
      "Epoch  4, Batch  82 -Loss:     1.1501 Training Accuracy: 0.832294 Validation Accuracy: 0.764172\n",
      "Epoch  4, Batch  83 -Loss:     1.1101 Training Accuracy: 0.826231 Validation Accuracy: 0.766667\n",
      "Epoch  4, Batch  84 -Loss:     1.0732 Training Accuracy: 0.822294 Validation Accuracy: 0.765079\n",
      "Epoch  4, Batch  85 -Loss:     1.0333 Training Accuracy: 0.823127 Validation Accuracy: 0.758957\n",
      "Epoch  4, Batch  86 -Loss:     1.2232 Training Accuracy: 0.827007 Validation Accuracy: 0.765306\n",
      "Epoch  4, Batch  87 -Loss:     0.9935 Training Accuracy: 0.822265 Validation Accuracy: 0.756463\n",
      "Epoch  4, Batch  88 -Loss:     1.1530 Training Accuracy: 0.825426 Validation Accuracy: 0.753515\n",
      "Epoch  4, Batch  89 -Loss:     1.0981 Training Accuracy: 0.831834 Validation Accuracy: 0.763265\n",
      "Epoch  4, Batch  90 -Loss:     1.1697 Training Accuracy: 0.825943 Validation Accuracy: 0.766440\n",
      "Epoch  4, Batch  91 -Loss:     1.0164 Training Accuracy: 0.818386 Validation Accuracy: 0.763946\n",
      "Epoch  4, Batch  92 -Loss:     1.0261 Training Accuracy: 0.818328 Validation Accuracy: 0.770748\n",
      "Epoch  4, Batch  93 -Loss:     1.0896 Training Accuracy: 0.827093 Validation Accuracy: 0.774830\n",
      "Epoch  4, Batch  94 -Loss:     1.0493 Training Accuracy: 0.825800 Validation Accuracy: 0.765986\n",
      "Epoch  4, Batch  95 -Loss:     1.1758 Training Accuracy: 0.816259 Validation Accuracy: 0.750340\n",
      "Epoch  4, Batch  96 -Loss:     1.2518 Training Accuracy: 0.813644 Validation Accuracy: 0.748526\n",
      "Epoch  4, Batch  97 -Loss:     1.1482 Training Accuracy: 0.815684 Validation Accuracy: 0.757370\n",
      "Epoch  4, Batch  98 -Loss:     1.0280 Training Accuracy: 0.826805 Validation Accuracy: 0.771882\n",
      "Epoch  4, Batch  99 -Loss:     0.9931 Training Accuracy: 0.829334 Validation Accuracy: 0.781633\n",
      "Epoch  4, Batch 100 -Loss:     1.1081 Training Accuracy: 0.823242 Validation Accuracy: 0.786621\n",
      "Epoch  4, Batch 101 -Loss:     1.0639 Training Accuracy: 0.828386 Validation Accuracy: 0.789342\n",
      "Epoch  4, Batch 102 -Loss:     0.9831 Training Accuracy: 0.833990 Validation Accuracy: 0.794558\n",
      "Epoch  4, Batch 103 -Loss:     1.1242 Training Accuracy: 0.835685 Validation Accuracy: 0.797506\n",
      "Epoch  4, Batch 104 -Loss:     1.1077 Training Accuracy: 0.837438 Validation Accuracy: 0.784807\n",
      "Epoch  4, Batch 105 -Loss:     0.9681 Training Accuracy: 0.835484 Validation Accuracy: 0.778231\n",
      "Epoch  4, Batch 106 -Loss:     1.1464 Training Accuracy: 0.839593 Validation Accuracy: 0.781406\n",
      "Epoch  4, Batch 107 -Loss:     1.1551 Training Accuracy: 0.846634 Validation Accuracy: 0.791383\n",
      "Epoch  4, Batch 108 -Loss:     0.9521 Training Accuracy: 0.839191 Validation Accuracy: 0.792063\n",
      "Epoch  4, Batch 109 -Loss:     0.9699 Training Accuracy: 0.814362 Validation Accuracy: 0.772109\n",
      "Epoch  4, Batch 110 -Loss:     0.9709 Training Accuracy: 0.820972 Validation Accuracy: 0.770068\n",
      "Epoch  4, Batch 111 -Loss:     1.1798 Training Accuracy: 0.841835 Validation Accuracy: 0.777324\n",
      "Epoch  4, Batch 112 -Loss:     1.1242 Training Accuracy: 0.844392 Validation Accuracy: 0.770975\n",
      "Epoch  4, Batch 113 -Loss:     1.1076 Training Accuracy: 0.828070 Validation Accuracy: 0.755102\n",
      "Epoch  4, Batch 114 -Loss:     0.9975 Training Accuracy: 0.804104 Validation Accuracy: 0.735374\n",
      "Epoch  4, Batch 115 -Loss:     1.0522 Training Accuracy: 0.806403 Validation Accuracy: 0.736961\n",
      "Epoch  4, Batch 116 -Loss:     1.1428 Training Accuracy: 0.825081 Validation Accuracy: 0.746712\n",
      "Epoch  4, Batch 117 -Loss:     1.0911 Training Accuracy: 0.823960 Validation Accuracy: 0.754649\n",
      "Epoch  4, Batch 118 -Loss:     0.9773 Training Accuracy: 0.803759 Validation Accuracy: 0.740363\n",
      "Epoch  4, Batch 119 -Loss:     1.2189 Training Accuracy: 0.806201 Validation Accuracy: 0.752381\n",
      "Epoch  4, Batch 120 -Loss:     1.1117 Training Accuracy: 0.838185 Validation Accuracy: 0.782766\n",
      "Epoch  4, Batch 121 -Loss:     1.2515 Training Accuracy: 0.842208 Validation Accuracy: 0.776417\n",
      "Epoch  4, Batch 122 -Loss:     1.1057 Training Accuracy: 0.822064 Validation Accuracy: 0.754422\n",
      "Epoch  4, Batch 123 -Loss:     1.0074 Training Accuracy: 0.833443 Validation Accuracy: 0.765079\n",
      "Epoch  4, Batch 124 -Loss:     1.0160 Training Accuracy: 0.822524 Validation Accuracy: 0.758503\n",
      "Epoch  4, Batch 125 -Loss:     1.0428 Training Accuracy: 0.790597 Validation Accuracy: 0.726757\n",
      "Epoch  4, Batch 126 -Loss:     1.1321 Training Accuracy: 0.795281 Validation Accuracy: 0.729252\n",
      "Epoch  4, Batch 127 -Loss:     1.0832 Training Accuracy: 0.820081 Validation Accuracy: 0.756236\n",
      "Epoch  4, Batch 128 -Loss:     1.0186 Training Accuracy: 0.833501 Validation Accuracy: 0.764853\n",
      "Epoch  4, Batch 129 -Loss:     1.1206 Training Accuracy: 0.836260 Validation Accuracy: 0.770068\n",
      "Epoch  4, Batch 130 -Loss:     1.0173 Training Accuracy: 0.842151 Validation Accuracy: 0.780952\n",
      "Epoch  4, Batch 131 -Loss:     1.0908 Training Accuracy: 0.840225 Validation Accuracy: 0.782086\n",
      "Epoch  4, Batch 132 -Loss:     0.9500 Training Accuracy: 0.833645 Validation Accuracy: 0.768707\n",
      "Epoch  4, Batch 133 -Loss:     1.0281 Training Accuracy: 0.820282 Validation Accuracy: 0.751020\n",
      "Epoch  4, Batch 134 -Loss:     1.0153 Training Accuracy: 0.825254 Validation Accuracy: 0.758277\n",
      "Epoch  4, Batch 135 -Loss:     1.0877 Training Accuracy: 0.828645 Validation Accuracy: 0.763265\n",
      "Epoch  4, Batch 136 -Loss:     0.9324 Training Accuracy: 0.836834 Validation Accuracy: 0.775283\n",
      "Epoch  4, Batch 137 -Loss:     0.9300 Training Accuracy: 0.843013 Validation Accuracy: 0.774830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4, Batch 138 -Loss:     1.2687 Training Accuracy: 0.843415 Validation Accuracy: 0.774376\n",
      "Epoch  4, Batch 139 -Loss:     1.0485 Training Accuracy: 0.839047 Validation Accuracy: 0.772562\n",
      "Epoch  4, Batch 140 -Loss:     1.1002 Training Accuracy: 0.842122 Validation Accuracy: 0.777098\n",
      "Epoch  4, Batch 141 -Loss:     1.1665 Training Accuracy: 0.842467 Validation Accuracy: 0.778685\n",
      "Epoch  4, Batch 142 -Loss:     1.3173 Training Accuracy: 0.831260 Validation Accuracy: 0.780272\n",
      "Epoch  4, Batch 143 -Loss:     1.0515 Training Accuracy: 0.826432 Validation Accuracy: 0.780045\n",
      "Epoch  4, Batch 144 -Loss:     1.1221 Training Accuracy: 0.827121 Validation Accuracy: 0.771655\n",
      "Epoch  4, Batch 145 -Loss:     1.0211 Training Accuracy: 0.835800 Validation Accuracy: 0.774830\n",
      "Epoch  4, Batch 146 -Loss:     1.1596 Training Accuracy: 0.847294 Validation Accuracy: 0.770295\n",
      "Epoch  4, Batch 147 -Loss:     1.0998 Training Accuracy: 0.840599 Validation Accuracy: 0.759637\n",
      "Epoch  4, Batch 148 -Loss:     0.9850 Training Accuracy: 0.830915 Validation Accuracy: 0.752381\n",
      "Epoch  4, Batch 149 -Loss:     1.0447 Training Accuracy: 0.841806 Validation Accuracy: 0.762585\n",
      "Epoch  4, Batch 150 -Loss:     1.0103 Training Accuracy: 0.852697 Validation Accuracy: 0.780499\n",
      "Epoch  4, Batch 151 -Loss:     1.0784 Training Accuracy: 0.822265 Validation Accuracy: 0.761451\n",
      "Epoch  4, Batch 152 -Loss:     0.9964 Training Accuracy: 0.795052 Validation Accuracy: 0.731746\n",
      "Epoch  4, Batch 153 -Loss:     0.9306 Training Accuracy: 0.799621 Validation Accuracy: 0.734014\n",
      "Epoch  4, Batch 154 -Loss:     1.0600 Training Accuracy: 0.812926 Validation Accuracy: 0.747166\n",
      "Epoch  4, Batch 155 -Loss:     1.0306 Training Accuracy: 0.837323 Validation Accuracy: 0.768481\n",
      "Epoch  4, Batch 156 -Loss:     1.0607 Training Accuracy: 0.845542 Validation Accuracy: 0.773923\n",
      "Epoch  4, Batch 157 -Loss:     1.1058 Training Accuracy: 0.832265 Validation Accuracy: 0.758277\n",
      "Epoch  4, Batch 158 -Loss:     1.0168 Training Accuracy: 0.819707 Validation Accuracy: 0.751701\n",
      "Epoch  4, Batch 159 -Loss:     1.0330 Training Accuracy: 0.820972 Validation Accuracy: 0.749206\n",
      "Epoch  4, Batch 160 -Loss:     1.0759 Training Accuracy: 0.823587 Validation Accuracy: 0.765306\n",
      "Epoch  4, Batch 161 -Loss:     1.1082 Training Accuracy: 0.820167 Validation Accuracy: 0.763719\n",
      "Epoch  4, Batch 162 -Loss:     1.0201 Training Accuracy: 0.833530 Validation Accuracy: 0.782540\n",
      "Epoch  4, Batch 163 -Loss:     1.0428 Training Accuracy: 0.859421 Validation Accuracy: 0.793651\n",
      "Epoch  4, Batch 164 -Loss:     0.9366 Training Accuracy: 0.843875 Validation Accuracy: 0.773016\n",
      "Epoch  4, Batch 165 -Loss:     1.1290 Training Accuracy: 0.815138 Validation Accuracy: 0.744898\n",
      "Epoch  4, Batch 166 -Loss:     1.1122 Training Accuracy: 0.805512 Validation Accuracy: 0.737642\n",
      "Epoch  4, Batch 167 -Loss:     1.0984 Training Accuracy: 0.843702 Validation Accuracy: 0.779592\n",
      "Epoch  4, Batch 168 -Loss:     1.1755 Training Accuracy: 0.851145 Validation Accuracy: 0.792063\n",
      "Epoch  4, Batch 169 -Loss:     0.9332 Training Accuracy: 0.832007 Validation Accuracy: 0.780499\n",
      "Epoch  4, Batch 170 -Loss:     1.1297 Training Accuracy: 0.828673 Validation Accuracy: 0.780272\n",
      "Epoch  4, Batch 171 -Loss:     1.0522 Training Accuracy: 0.842467 Validation Accuracy: 0.791610\n",
      "Epoch  4, Batch 172 -Loss:     0.8975 Training Accuracy: 0.851001 Validation Accuracy: 0.792517\n",
      "Epoch  4, Batch 173 -Loss:     0.9869 Training Accuracy: 0.843932 Validation Accuracy: 0.778005\n",
      "Epoch  4, Batch 174 -Loss:     1.1452 Training Accuracy: 0.837294 Validation Accuracy: 0.767347\n",
      "Epoch  4, Batch 175 -Loss:     0.9856 Training Accuracy: 0.840972 Validation Accuracy: 0.769841\n",
      "Epoch  4, Batch 176 -Loss:     0.8301 Training Accuracy: 0.845484 Validation Accuracy: 0.777098\n",
      "Epoch  4, Batch 177 -Loss:     1.0340 Training Accuracy: 0.852898 Validation Accuracy: 0.783900\n",
      "Epoch  4, Batch 178 -Loss:     0.8507 Training Accuracy: 0.851978 Validation Accuracy: 0.785488\n",
      "Epoch  4, Batch 179 -Loss:     0.9564 Training Accuracy: 0.852180 Validation Accuracy: 0.783900\n",
      "Epoch  4, Batch 180 -Loss:     0.9733 Training Accuracy: 0.851662 Validation Accuracy: 0.790703\n",
      "Epoch  4, Batch 181 -Loss:     0.9456 Training Accuracy: 0.848588 Validation Accuracy: 0.784127\n",
      "Epoch  4, Batch 182 -Loss:     1.0317 Training Accuracy: 0.843099 Validation Accuracy: 0.776417\n",
      "Epoch  4, Batch 183 -Loss:     0.8964 Training Accuracy: 0.835139 Validation Accuracy: 0.766213\n",
      "Epoch  4, Batch 184 -Loss:     1.0452 Training Accuracy: 0.846519 Validation Accuracy: 0.775283\n",
      "Epoch  4, Batch 185 -Loss:     0.9693 Training Accuracy: 0.853760 Validation Accuracy: 0.784127\n",
      "Epoch  4, Batch 186 -Loss:     1.0188 Training Accuracy: 0.844622 Validation Accuracy: 0.780952\n",
      "Epoch  4, Batch 187 -Loss:     1.0326 Training Accuracy: 0.832323 Validation Accuracy: 0.762358\n",
      "Epoch  4, Batch 188 -Loss:     1.1532 Training Accuracy: 0.834306 Validation Accuracy: 0.767347\n",
      "Epoch  4, Batch 189 -Loss:     1.1334 Training Accuracy: 0.829966 Validation Accuracy: 0.760317\n",
      "Epoch  4, Batch 190 -Loss:     1.0148 Training Accuracy: 0.815598 Validation Accuracy: 0.750567\n",
      "Epoch  4, Batch 191 -Loss:     1.1936 Training Accuracy: 0.837840 Validation Accuracy: 0.767800\n",
      "Epoch  4, Batch 192 -Loss:     0.9380 Training Accuracy: 0.847726 Validation Accuracy: 0.784807\n",
      "Epoch  4, Batch 193 -Loss:     1.1857 Training Accuracy: 0.837926 Validation Accuracy: 0.776417\n",
      "Epoch  4, Batch 194 -Loss:     1.0778 Training Accuracy: 0.848760 Validation Accuracy: 0.779138\n",
      "Epoch  4, Batch 195 -Loss:     1.1148 Training Accuracy: 0.857266 Validation Accuracy: 0.789569\n",
      "Epoch  4, Batch 196 -Loss:     1.0736 Training Accuracy: 0.839018 Validation Accuracy: 0.782086\n",
      "Epoch  4, Batch 197 -Loss:     1.0252 Training Accuracy: 0.820052 Validation Accuracy: 0.775283\n",
      "Epoch  4, Batch 198 -Loss:     1.0625 Training Accuracy: 0.817351 Validation Accuracy: 0.771429\n",
      "Epoch  4, Batch 199 -Loss:     0.9756 Training Accuracy: 0.818213 Validation Accuracy: 0.768707\n",
      "Epoch  4, Batch 200 -Loss:     0.8886 Training Accuracy: 0.829420 Validation Accuracy: 0.768027\n",
      "Epoch  4, Batch 201 -Loss:     1.0186 Training Accuracy: 0.840628 Validation Accuracy: 0.769841\n",
      "Epoch  4, Batch 202 -Loss:     0.9447 Training Accuracy: 0.839306 Validation Accuracy: 0.770522\n",
      "Epoch  4, Batch 203 -Loss:     1.0182 Training Accuracy: 0.844421 Validation Accuracy: 0.782313\n",
      "Epoch  4, Batch 204 -Loss:     0.9613 Training Accuracy: 0.844507 Validation Accuracy: 0.781859\n",
      "Epoch  4, Batch 205 -Loss:     1.0918 Training Accuracy: 0.843702 Validation Accuracy: 0.785714\n",
      "Epoch  4, Batch 206 -Loss:     0.9819 Training Accuracy: 0.840915 Validation Accuracy: 0.787755\n",
      "Epoch  4, Batch 207 -Loss:     1.1142 Training Accuracy: 0.833645 Validation Accuracy: 0.776871\n",
      "Epoch  4, Batch 208 -Loss:     1.0967 Training Accuracy: 0.825225 Validation Accuracy: 0.761905\n",
      "Epoch  4, Batch 209 -Loss:     0.9694 Training Accuracy: 0.830915 Validation Accuracy: 0.767347\n",
      "Epoch  4, Batch 210 -Loss:     0.9038 Training Accuracy: 0.842007 Validation Accuracy: 0.772562\n",
      "Epoch  4, Batch 211 -Loss:     0.9867 Training Accuracy: 0.850714 Validation Accuracy: 0.776417\n",
      "Epoch  4, Batch 212 -Loss:     1.2101 Training Accuracy: 0.853760 Validation Accuracy: 0.773696\n",
      "Epoch  4, Batch 213 -Loss:     1.1356 Training Accuracy: 0.857295 Validation Accuracy: 0.784127\n",
      "Epoch  4, Batch 214 -Loss:     1.1681 Training Accuracy: 0.859450 Validation Accuracy: 0.791156\n",
      "Epoch  4, Batch 215 -Loss:     1.0586 Training Accuracy: 0.854335 Validation Accuracy: 0.788209\n",
      "Epoch  4, Batch 216 -Loss:     1.0572 Training Accuracy: 0.855657 Validation Accuracy: 0.790930\n",
      "Epoch  4, Batch 217 -Loss:     0.9265 Training Accuracy: 0.859364 Validation Accuracy: 0.787075\n",
      "Epoch  4, Batch 218 -Loss:     0.9958 Training Accuracy: 0.855168 Validation Accuracy: 0.781179\n",
      "Epoch  4, Batch 219 -Loss:     1.0728 Training Accuracy: 0.855714 Validation Accuracy: 0.781633\n",
      "Epoch  4, Batch 220 -Loss:     0.9398 Training Accuracy: 0.853099 Validation Accuracy: 0.781633\n",
      "Epoch  4, Batch 221 -Loss:     1.0442 Training Accuracy: 0.854651 Validation Accuracy: 0.785034\n",
      "Epoch  4, Batch 222 -Loss:     0.9224 Training Accuracy: 0.856289 Validation Accuracy: 0.787982\n",
      "Epoch  4, Batch 223 -Loss:     1.0129 Training Accuracy: 0.854421 Validation Accuracy: 0.790476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4, Batch 224 -Loss:     1.0008 Training Accuracy: 0.833731 Validation Accuracy: 0.769841\n",
      "Epoch  4, Batch 225 -Loss:     0.9162 Training Accuracy: 0.821489 Validation Accuracy: 0.761225\n",
      "Epoch  4, Batch 226 -Loss:     1.0330 Training Accuracy: 0.828817 Validation Accuracy: 0.770068\n",
      "Epoch  4, Batch 227 -Loss:     0.9514 Training Accuracy: 0.845283 Validation Accuracy: 0.778685\n",
      "Epoch  4, Batch 228 -Loss:     1.0153 Training Accuracy: 0.859766 Validation Accuracy: 0.791383\n",
      "Epoch  4, Batch 229 -Loss:     1.0562 Training Accuracy: 0.854910 Validation Accuracy: 0.787075\n",
      "Epoch  4, Batch 230 -Loss:     1.0834 Training Accuracy: 0.835599 Validation Accuracy: 0.769615\n",
      "Epoch  4, Batch 231 -Loss:     0.9918 Training Accuracy: 0.829018 Validation Accuracy: 0.765986\n",
      "Epoch  4, Batch 232 -Loss:     1.0153 Training Accuracy: 0.847553 Validation Accuracy: 0.780499\n",
      "Epoch  4, Batch 233 -Loss:     1.0474 Training Accuracy: 0.858559 Validation Accuracy: 0.777324\n",
      "Epoch  4, Batch 234 -Loss:     0.9073 Training Accuracy: 0.829535 Validation Accuracy: 0.758050\n",
      "Epoch  4, Batch 235 -Loss:     1.0325 Training Accuracy: 0.808385 Validation Accuracy: 0.742404\n",
      "Epoch  4, Batch 236 -Loss:     1.0200 Training Accuracy: 0.806201 Validation Accuracy: 0.743311\n",
      "Epoch  4, Batch 237 -Loss:     0.9981 Training Accuracy: 0.834909 Validation Accuracy: 0.771882\n",
      "Epoch  4, Batch 238 -Loss:     0.9526 Training Accuracy: 0.861088 Validation Accuracy: 0.774603\n",
      "Epoch  4, Batch 239 -Loss:     0.8572 Training Accuracy: 0.846748 Validation Accuracy: 0.759410\n",
      "Epoch  4, Batch 240 -Loss:     1.0783 Training Accuracy: 0.828759 Validation Accuracy: 0.750113\n",
      "Epoch  4, Batch 241 -Loss:     1.0617 Training Accuracy: 0.851404 Validation Accuracy: 0.772789\n",
      "Epoch  4, Batch 242 -Loss:     1.1003 Training Accuracy: 0.852151 Validation Accuracy: 0.769615\n",
      "Epoch  4, Batch 243 -Loss:     0.9864 Training Accuracy: 0.833616 Validation Accuracy: 0.759637\n",
      "Epoch  4, Batch 244 -Loss:     0.9837 Training Accuracy: 0.817409 Validation Accuracy: 0.740136\n",
      "Epoch  4, Batch 245 -Loss:     0.9354 Training Accuracy: 0.815598 Validation Accuracy: 0.738549\n",
      "Epoch  4, Batch 246 -Loss:     1.2056 Training Accuracy: 0.833673 Validation Accuracy: 0.758277\n",
      "Epoch  4, Batch 247 -Loss:     0.9862 Training Accuracy: 0.839220 Validation Accuracy: 0.763719\n",
      "Epoch  4, Batch 248 -Loss:     1.0259 Training Accuracy: 0.839248 Validation Accuracy: 0.767120\n",
      "Epoch  4, Batch 249 -Loss:     1.0563 Training Accuracy: 0.840139 Validation Accuracy: 0.766893\n",
      "Epoch  4, Batch 250 -Loss:     0.9001 Training Accuracy: 0.838472 Validation Accuracy: 0.770748\n",
      "Epoch  4, Batch 251 -Loss:     0.9577 Training Accuracy: 0.848157 Validation Accuracy: 0.780045\n",
      "Epoch  4, Batch 252 -Loss:     0.9720 Training Accuracy: 0.863674 Validation Accuracy: 0.793424\n",
      "Epoch  4, Batch 253 -Loss:     1.0096 Training Accuracy: 0.869910 Validation Accuracy: 0.799093\n",
      "Epoch  4, Batch 254 -Loss:     1.0839 Training Accuracy: 0.864019 Validation Accuracy: 0.794785\n",
      "Epoch  4, Batch 255 -Loss:     0.9333 Training Accuracy: 0.861634 Validation Accuracy: 0.794558\n",
      "Epoch  4, Batch 256 -Loss:     1.0087 Training Accuracy: 0.862237 Validation Accuracy: 0.785488\n",
      "Epoch  4, Batch 257 -Loss:     1.1194 Training Accuracy: 0.864278 Validation Accuracy: 0.785261\n",
      "Epoch  4, Batch 258 -Loss:     0.8729 Training Accuracy: 0.853300 Validation Accuracy: 0.773469\n",
      "Epoch  4, Batch 259 -Loss:     1.0820 Training Accuracy: 0.842036 Validation Accuracy: 0.761905\n",
      "Epoch  4, Batch 260 -Loss:     0.9679 Training Accuracy: 0.830455 Validation Accuracy: 0.753288\n",
      "Epoch  4, Batch 261 -Loss:     1.0652 Training Accuracy: 0.839421 Validation Accuracy: 0.765986\n",
      "Epoch  4, Batch 262 -Loss:     0.9191 Training Accuracy: 0.850369 Validation Accuracy: 0.776190\n",
      "Epoch  4, Batch 263 -Loss:     0.9960 Training Accuracy: 0.855858 Validation Accuracy: 0.779819\n",
      "Epoch  4, Batch 264 -Loss:     0.9376 Training Accuracy: 0.861634 Validation Accuracy: 0.789796\n",
      "Epoch  4, Batch 265 -Loss:     0.9959 Training Accuracy: 0.852036 Validation Accuracy: 0.787528\n",
      "Epoch  4, Batch 266 -Loss:     1.0328 Training Accuracy: 0.832754 Validation Accuracy: 0.763946\n",
      "Epoch  4, Batch 267 -Loss:     1.0912 Training Accuracy: 0.831691 Validation Accuracy: 0.764399\n",
      "Epoch  4, Batch 268 -Loss:     0.8922 Training Accuracy: 0.845599 Validation Accuracy: 0.782086\n",
      "Epoch  4, Batch 269 -Loss:     1.1522 Training Accuracy: 0.853933 Validation Accuracy: 0.790930\n",
      "Epoch  4, Batch 270 -Loss:     0.9962 Training Accuracy: 0.865485 Validation Accuracy: 0.800680\n",
      "Epoch  4, Batch 271 -Loss:     0.8940 Training Accuracy: 0.869680 Validation Accuracy: 0.803401\n",
      "Epoch  4, Batch 272 -Loss:     0.9248 Training Accuracy: 0.864105 Validation Accuracy: 0.798413\n",
      "Epoch  5, Batch   1 -Loss:     0.9795 Training Accuracy: 0.853387 Validation Accuracy: 0.784354\n",
      "Epoch  5, Batch   2 -Loss:     1.0068 Training Accuracy: 0.846145 Validation Accuracy: 0.776871\n",
      "Epoch  5, Batch   3 -Loss:     0.9452 Training Accuracy: 0.854306 Validation Accuracy: 0.790930\n",
      "Epoch  5, Batch   4 -Loss:     1.0474 Training Accuracy: 0.855887 Validation Accuracy: 0.794331\n",
      "Epoch  5, Batch   5 -Loss:     0.9989 Training Accuracy: 0.848990 Validation Accuracy: 0.788209\n",
      "Epoch  5, Batch   6 -Loss:     0.8978 Training Accuracy: 0.848616 Validation Accuracy: 0.792063\n",
      "Epoch  5, Batch   7 -Loss:     1.0225 Training Accuracy: 0.862870 Validation Accuracy: 0.804989\n",
      "Epoch  5, Batch   8 -Loss:     0.9446 Training Accuracy: 0.862237 Validation Accuracy: 0.802041\n",
      "Epoch  5, Batch   9 -Loss:     1.0556 Training Accuracy: 0.845858 Validation Accuracy: 0.780272\n",
      "Epoch  5, Batch  10 -Loss:     1.0546 Training Accuracy: 0.840484 Validation Accuracy: 0.768934\n",
      "Epoch  5, Batch  11 -Loss:     1.0763 Training Accuracy: 0.856030 Validation Accuracy: 0.777778\n",
      "Epoch  5, Batch  12 -Loss:     0.9399 Training Accuracy: 0.867036 Validation Accuracy: 0.789116\n",
      "Epoch  5, Batch  13 -Loss:     0.8584 Training Accuracy: 0.857094 Validation Accuracy: 0.783673\n",
      "Epoch  5, Batch  14 -Loss:     0.9664 Training Accuracy: 0.851059 Validation Accuracy: 0.777778\n",
      "Epoch  5, Batch  15 -Loss:     0.9140 Training Accuracy: 0.848157 Validation Accuracy: 0.777098\n",
      "Epoch  5, Batch  16 -Loss:     0.9974 Training Accuracy: 0.854651 Validation Accuracy: 0.784580\n",
      "Epoch  5, Batch  17 -Loss:     1.0801 Training Accuracy: 0.866031 Validation Accuracy: 0.789569\n",
      "Epoch  5, Batch  18 -Loss:     0.9955 Training Accuracy: 0.867094 Validation Accuracy: 0.793424\n",
      "Epoch  5, Batch  19 -Loss:     0.7603 Training Accuracy: 0.868445 Validation Accuracy: 0.797052\n",
      "Epoch  5, Batch  20 -Loss:     1.0278 Training Accuracy: 0.869910 Validation Accuracy: 0.797732\n",
      "Epoch  5, Batch  21 -Loss:     0.8931 Training Accuracy: 0.861347 Validation Accuracy: 0.789796\n",
      "Epoch  5, Batch  22 -Loss:     0.9863 Training Accuracy: 0.848616 Validation Accuracy: 0.781633\n",
      "Epoch  5, Batch  23 -Loss:     0.9443 Training Accuracy: 0.855657 Validation Accuracy: 0.783673\n",
      "Epoch  5, Batch  24 -Loss:     0.9688 Training Accuracy: 0.856203 Validation Accuracy: 0.780272\n",
      "Epoch  5, Batch  25 -Loss:     1.0409 Training Accuracy: 0.859910 Validation Accuracy: 0.784127\n",
      "Epoch  5, Batch  26 -Loss:     0.8985 Training Accuracy: 0.868042 Validation Accuracy: 0.793651\n",
      "Epoch  5, Batch  27 -Loss:     0.8904 Training Accuracy: 0.873703 Validation Accuracy: 0.793878\n",
      "Epoch  5, Batch  28 -Loss:     0.8795 Training Accuracy: 0.871347 Validation Accuracy: 0.784127\n",
      "Epoch  5, Batch  29 -Loss:     1.0140 Training Accuracy: 0.864709 Validation Accuracy: 0.777098\n",
      "Epoch  5, Batch  30 -Loss:     1.0005 Training Accuracy: 0.866663 Validation Accuracy: 0.778458\n",
      "Epoch  5, Batch  31 -Loss:     0.9512 Training Accuracy: 0.874393 Validation Accuracy: 0.790703\n",
      "Epoch  5, Batch  32 -Loss:     0.9840 Training Accuracy: 0.865600 Validation Accuracy: 0.785941\n",
      "Epoch  5, Batch  33 -Loss:     0.9027 Training Accuracy: 0.840484 Validation Accuracy: 0.772562\n",
      "Epoch  5, Batch  34 -Loss:     0.8498 Training Accuracy: 0.816978 Validation Accuracy: 0.753968\n",
      "Epoch  5, Batch  35 -Loss:     1.1076 Training Accuracy: 0.818529 Validation Accuracy: 0.756916\n",
      "Epoch  5, Batch  36 -Loss:     0.9767 Training Accuracy: 0.849134 Validation Accuracy: 0.772109\n",
      "Epoch  5, Batch  37 -Loss:     1.0905 Training Accuracy: 0.866749 Validation Accuracy: 0.782086\n",
      "Epoch  5, Batch  38 -Loss:     1.0658 Training Accuracy: 0.851116 Validation Accuracy: 0.776644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5, Batch  39 -Loss:     1.1137 Training Accuracy: 0.832122 Validation Accuracy: 0.762585\n",
      "Epoch  5, Batch  40 -Loss:     0.9619 Training Accuracy: 0.844967 Validation Accuracy: 0.775510\n",
      "Epoch  5, Batch  41 -Loss:     1.1216 Training Accuracy: 0.874077 Validation Accuracy: 0.800227\n",
      "Epoch  5, Batch  42 -Loss:     0.9253 Training Accuracy: 0.856806 Validation Accuracy: 0.793424\n",
      "Epoch  5, Batch  43 -Loss:     0.9970 Training Accuracy: 0.836949 Validation Accuracy: 0.782540\n",
      "Epoch  5, Batch  44 -Loss:     0.9659 Training Accuracy: 0.832179 Validation Accuracy: 0.774376\n",
      "Epoch  5, Batch  45 -Loss:     0.9922 Training Accuracy: 0.844047 Validation Accuracy: 0.787755\n",
      "Epoch  5, Batch  46 -Loss:     0.9686 Training Accuracy: 0.858329 Validation Accuracy: 0.796372\n",
      "Epoch  5, Batch  47 -Loss:     1.0223 Training Accuracy: 0.864709 Validation Accuracy: 0.795465\n",
      "Epoch  5, Batch  48 -Loss:     0.8445 Training Accuracy: 0.864163 Validation Accuracy: 0.793197\n",
      "Epoch  5, Batch  49 -Loss:     1.0637 Training Accuracy: 0.866031 Validation Accuracy: 0.793424\n",
      "Epoch  5, Batch  50 -Loss:     0.9941 Training Accuracy: 0.866720 Validation Accuracy: 0.791837\n",
      "Epoch  5, Batch  51 -Loss:     0.9369 Training Accuracy: 0.876433 Validation Accuracy: 0.797506\n",
      "Epoch  5, Batch  52 -Loss:     0.9487 Training Accuracy: 0.880859 Validation Accuracy: 0.802948\n",
      "Epoch  5, Batch  53 -Loss:     1.1155 Training Accuracy: 0.872841 Validation Accuracy: 0.802494\n",
      "Epoch  5, Batch  54 -Loss:     0.9653 Training Accuracy: 0.849392 Validation Accuracy: 0.785714\n",
      "Epoch  5, Batch  55 -Loss:     1.0122 Training Accuracy: 0.840455 Validation Accuracy: 0.773243\n",
      "Epoch  5, Batch  56 -Loss:     0.9907 Training Accuracy: 0.848990 Validation Accuracy: 0.783900\n",
      "Epoch  5, Batch  57 -Loss:     0.8641 Training Accuracy: 0.864306 Validation Accuracy: 0.795011\n",
      "Epoch  5, Batch  58 -Loss:     0.9843 Training Accuracy: 0.866663 Validation Accuracy: 0.789342\n",
      "Epoch  5, Batch  59 -Loss:     0.9843 Training Accuracy: 0.856232 Validation Accuracy: 0.781179\n",
      "Epoch  5, Batch  60 -Loss:     1.0274 Training Accuracy: 0.863789 Validation Accuracy: 0.790703\n",
      "Epoch  5, Batch  61 -Loss:     0.9316 Training Accuracy: 0.867870 Validation Accuracy: 0.801587\n",
      "Epoch  5, Batch  62 -Loss:     0.9465 Training Accuracy: 0.861778 Validation Accuracy: 0.804308\n",
      "Epoch  5, Batch  63 -Loss:     0.9452 Training Accuracy: 0.857180 Validation Accuracy: 0.802268\n",
      "Epoch  5, Batch  64 -Loss:     0.8326 Training Accuracy: 0.856145 Validation Accuracy: 0.795465\n",
      "Epoch  5, Batch  65 -Loss:     0.9111 Training Accuracy: 0.858904 Validation Accuracy: 0.787982\n",
      "Epoch  5, Batch  66 -Loss:     1.0266 Training Accuracy: 0.862352 Validation Accuracy: 0.779819\n",
      "Epoch  5, Batch  67 -Loss:     0.9968 Training Accuracy: 0.860542 Validation Accuracy: 0.769841\n",
      "Epoch  5, Batch  68 -Loss:     0.8653 Training Accuracy: 0.859709 Validation Accuracy: 0.772109\n",
      "Epoch  5, Batch  69 -Loss:     1.0387 Training Accuracy: 0.861806 Validation Accuracy: 0.777551\n",
      "Epoch  5, Batch  70 -Loss:     0.9121 Training Accuracy: 0.864163 Validation Accuracy: 0.788435\n",
      "Epoch  5, Batch  71 -Loss:     0.8877 Training Accuracy: 0.863531 Validation Accuracy: 0.785714\n",
      "Epoch  5, Batch  72 -Loss:     0.9090 Training Accuracy: 0.869508 Validation Accuracy: 0.795465\n",
      "Epoch  5, Batch  73 -Loss:     0.9098 Training Accuracy: 0.871634 Validation Accuracy: 0.797959\n",
      "Epoch  5, Batch  74 -Loss:     0.8634 Training Accuracy: 0.869651 Validation Accuracy: 0.795011\n",
      "Epoch  5, Batch  75 -Loss:     0.9173 Training Accuracy: 0.865571 Validation Accuracy: 0.793197\n",
      "Epoch  5, Batch  76 -Loss:     0.9939 Training Accuracy: 0.861174 Validation Accuracy: 0.789342\n",
      "Epoch  5, Batch  77 -Loss:     1.0434 Training Accuracy: 0.859622 Validation Accuracy: 0.788435\n",
      "Epoch  5, Batch  78 -Loss:     0.9325 Training Accuracy: 0.857438 Validation Accuracy: 0.789569\n",
      "Epoch  5, Batch  79 -Loss:     0.9546 Training Accuracy: 0.862209 Validation Accuracy: 0.795011\n",
      "Epoch  5, Batch  80 -Loss:     0.9804 Training Accuracy: 0.867352 Validation Accuracy: 0.798866\n",
      "Epoch  5, Batch  81 -Loss:     0.8282 Training Accuracy: 0.865513 Validation Accuracy: 0.796599\n",
      "Epoch  5, Batch  82 -Loss:     0.7983 Training Accuracy: 0.864852 Validation Accuracy: 0.794785\n",
      "Epoch  5, Batch  83 -Loss:     1.0338 Training Accuracy: 0.862985 Validation Accuracy: 0.790476\n",
      "Epoch  5, Batch  84 -Loss:     0.9426 Training Accuracy: 0.867985 Validation Accuracy: 0.794785\n",
      "Epoch  5, Batch  85 -Loss:     0.8074 Training Accuracy: 0.864249 Validation Accuracy: 0.792971\n",
      "Epoch  5, Batch  86 -Loss:     0.9749 Training Accuracy: 0.858933 Validation Accuracy: 0.785261\n",
      "Epoch  5, Batch  87 -Loss:     0.9366 Training Accuracy: 0.863358 Validation Accuracy: 0.792290\n",
      "Epoch  5, Batch  88 -Loss:     0.8908 Training Accuracy: 0.872583 Validation Accuracy: 0.798639\n",
      "Epoch  5, Batch  89 -Loss:     1.0447 Training Accuracy: 0.880054 Validation Accuracy: 0.797732\n",
      "Epoch  5, Batch  90 -Loss:     0.9210 Training Accuracy: 0.874479 Validation Accuracy: 0.779592\n",
      "Epoch  5, Batch  91 -Loss:     1.0766 Training Accuracy: 0.863444 Validation Accuracy: 0.773923\n",
      "Epoch  5, Batch  92 -Loss:     1.0264 Training Accuracy: 0.861347 Validation Accuracy: 0.774603\n",
      "Epoch  5, Batch  93 -Loss:     0.9979 Training Accuracy: 0.862812 Validation Accuracy: 0.775964\n",
      "Epoch  5, Batch  94 -Loss:     0.9445 Training Accuracy: 0.866002 Validation Accuracy: 0.788209\n",
      "Epoch  5, Batch  95 -Loss:     0.9873 Training Accuracy: 0.862266 Validation Accuracy: 0.788889\n",
      "Epoch  5, Batch  96 -Loss:     0.8271 Training Accuracy: 0.855456 Validation Accuracy: 0.777551\n",
      "Epoch  5, Batch  97 -Loss:     0.9365 Training Accuracy: 0.858013 Validation Accuracy: 0.778685\n",
      "Epoch  5, Batch  98 -Loss:     0.9292 Training Accuracy: 0.864019 Validation Accuracy: 0.785488\n",
      "Epoch  5, Batch  99 -Loss:     1.1138 Training Accuracy: 0.851260 Validation Accuracy: 0.769388\n",
      "Epoch  5, Batch 100 -Loss:     0.8963 Training Accuracy: 0.831806 Validation Accuracy: 0.755782\n",
      "Epoch  5, Batch 101 -Loss:     0.9551 Training Accuracy: 0.846289 Validation Accuracy: 0.770522\n",
      "Epoch  5, Batch 102 -Loss:     0.9328 Training Accuracy: 0.867496 Validation Accuracy: 0.790249\n",
      "Epoch  5, Batch 103 -Loss:     0.9705 Training Accuracy: 0.864479 Validation Accuracy: 0.798186\n",
      "Epoch  5, Batch 104 -Loss:     0.9518 Training Accuracy: 0.856375 Validation Accuracy: 0.796825\n",
      "Epoch  5, Batch 105 -Loss:     0.8213 Training Accuracy: 0.850858 Validation Accuracy: 0.798186\n",
      "Epoch  5, Batch 106 -Loss:     0.9382 Training Accuracy: 0.852065 Validation Accuracy: 0.792971\n",
      "Epoch  5, Batch 107 -Loss:     0.9386 Training Accuracy: 0.850139 Validation Accuracy: 0.787302\n",
      "Epoch  5, Batch 108 -Loss:     1.1021 Training Accuracy: 0.845771 Validation Accuracy: 0.781633\n",
      "Epoch  5, Batch 109 -Loss:     0.9088 Training Accuracy: 0.841317 Validation Accuracy: 0.778458\n",
      "Epoch  5, Batch 110 -Loss:     0.9101 Training Accuracy: 0.846950 Validation Accuracy: 0.782993\n",
      "Epoch  5, Batch 111 -Loss:     1.1019 Training Accuracy: 0.856346 Validation Accuracy: 0.791156\n",
      "Epoch  5, Batch 112 -Loss:     0.9880 Training Accuracy: 0.858588 Validation Accuracy: 0.795011\n",
      "Epoch  5, Batch 113 -Loss:     1.0048 Training Accuracy: 0.858847 Validation Accuracy: 0.797279\n",
      "Epoch  5, Batch 114 -Loss:     0.9207 Training Accuracy: 0.873962 Validation Accuracy: 0.809977\n",
      "Epoch  5, Batch 115 -Loss:     0.9445 Training Accuracy: 0.877813 Validation Accuracy: 0.811338\n",
      "Epoch  5, Batch 116 -Loss:     0.9728 Training Accuracy: 0.863674 Validation Accuracy: 0.790023\n",
      "Epoch  5, Batch 117 -Loss:     0.9157 Training Accuracy: 0.847726 Validation Accuracy: 0.764399\n",
      "Epoch  5, Batch 118 -Loss:     1.0465 Training Accuracy: 0.861375 Validation Accuracy: 0.774150\n",
      "Epoch  5, Batch 119 -Loss:     0.7984 Training Accuracy: 0.872669 Validation Accuracy: 0.790023\n",
      "Epoch  5, Batch 120 -Loss:     0.8667 Training Accuracy: 0.875341 Validation Accuracy: 0.790476\n",
      "Epoch  5, Batch 121 -Loss:     1.0463 Training Accuracy: 0.863358 Validation Accuracy: 0.785714\n",
      "Epoch  5, Batch 122 -Loss:     1.0861 Training Accuracy: 0.847582 Validation Accuracy: 0.770975\n",
      "Epoch  5, Batch 123 -Loss:     0.9990 Training Accuracy: 0.860168 Validation Accuracy: 0.782086\n",
      "Epoch  5, Batch 124 -Loss:     0.8441 Training Accuracy: 0.872554 Validation Accuracy: 0.796599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5, Batch 125 -Loss:     0.8094 Training Accuracy: 0.878071 Validation Accuracy: 0.804989\n",
      "Epoch  5, Batch 126 -Loss:     0.8043 Training Accuracy: 0.875370 Validation Accuracy: 0.806576\n",
      "Epoch  5, Batch 127 -Loss:     0.9275 Training Accuracy: 0.864709 Validation Accuracy: 0.795692\n",
      "Epoch  5, Batch 128 -Loss:     0.9044 Training Accuracy: 0.868789 Validation Accuracy: 0.797959\n",
      "Epoch  5, Batch 129 -Loss:     0.9009 Training Accuracy: 0.872956 Validation Accuracy: 0.793878\n",
      "Epoch  5, Batch 130 -Loss:     0.9151 Training Accuracy: 0.875427 Validation Accuracy: 0.791383\n",
      "Epoch  5, Batch 131 -Loss:     0.9267 Training Accuracy: 0.873445 Validation Accuracy: 0.786848\n",
      "Epoch  5, Batch 132 -Loss:     1.0740 Training Accuracy: 0.870284 Validation Accuracy: 0.787528\n",
      "Epoch  5, Batch 133 -Loss:     0.9817 Training Accuracy: 0.871433 Validation Accuracy: 0.787302\n",
      "Epoch  5, Batch 134 -Loss:     0.9355 Training Accuracy: 0.866174 Validation Accuracy: 0.783673\n",
      "Epoch  5, Batch 135 -Loss:     0.8745 Training Accuracy: 0.849306 Validation Accuracy: 0.766893\n",
      "Epoch  5, Batch 136 -Loss:     0.8073 Training Accuracy: 0.847352 Validation Accuracy: 0.767800\n",
      "Epoch  5, Batch 137 -Loss:     0.8723 Training Accuracy: 0.861835 Validation Accuracy: 0.786395\n",
      "Epoch  5, Batch 138 -Loss:     0.9864 Training Accuracy: 0.864766 Validation Accuracy: 0.799093\n",
      "Epoch  5, Batch 139 -Loss:     1.1484 Training Accuracy: 0.866375 Validation Accuracy: 0.795465\n",
      "Epoch  5, Batch 140 -Loss:     0.9749 Training Accuracy: 0.858473 Validation Accuracy: 0.783220\n",
      "Epoch  5, Batch 141 -Loss:     0.9642 Training Accuracy: 0.865111 Validation Accuracy: 0.788435\n",
      "Epoch  5, Batch 142 -Loss:     0.8645 Training Accuracy: 0.875744 Validation Accuracy: 0.794785\n",
      "Epoch  5, Batch 143 -Loss:     0.9279 Training Accuracy: 0.877238 Validation Accuracy: 0.792517\n",
      "Epoch  5, Batch 144 -Loss:     0.8914 Training Accuracy: 0.858818 Validation Accuracy: 0.768707\n",
      "Epoch  5, Batch 145 -Loss:     0.9796 Training Accuracy: 0.848817 Validation Accuracy: 0.756916\n",
      "Epoch  5, Batch 146 -Loss:     0.9241 Training Accuracy: 0.855197 Validation Accuracy: 0.767800\n",
      "Epoch  5, Batch 147 -Loss:     0.8152 Training Accuracy: 0.855887 Validation Accuracy: 0.772789\n",
      "Epoch  5, Batch 148 -Loss:     1.0265 Training Accuracy: 0.866203 Validation Accuracy: 0.785714\n",
      "Epoch  5, Batch 149 -Loss:     0.9299 Training Accuracy: 0.877382 Validation Accuracy: 0.799546\n",
      "Epoch  5, Batch 150 -Loss:     0.9745 Training Accuracy: 0.877324 Validation Accuracy: 0.803628\n",
      "Epoch  5, Batch 151 -Loss:     0.8741 Training Accuracy: 0.876577 Validation Accuracy: 0.806122\n",
      "Epoch  5, Batch 152 -Loss:     0.9533 Training Accuracy: 0.866289 Validation Accuracy: 0.788662\n",
      "Epoch  5, Batch 153 -Loss:     0.8242 Training Accuracy: 0.857783 Validation Accuracy: 0.770522\n",
      "Epoch  5, Batch 154 -Loss:     0.8467 Training Accuracy: 0.858358 Validation Accuracy: 0.770748\n",
      "Epoch  5, Batch 155 -Loss:     0.9778 Training Accuracy: 0.865542 Validation Accuracy: 0.776644\n",
      "Epoch  5, Batch 156 -Loss:     0.8407 Training Accuracy: 0.873272 Validation Accuracy: 0.783900\n",
      "Epoch  5, Batch 157 -Loss:     0.8902 Training Accuracy: 0.871950 Validation Accuracy: 0.780726\n",
      "Epoch  5, Batch 158 -Loss:     0.9373 Training Accuracy: 0.869192 Validation Accuracy: 0.781859\n",
      "Epoch  5, Batch 159 -Loss:     0.9121 Training Accuracy: 0.861145 Validation Accuracy: 0.775510\n",
      "Epoch  5, Batch 160 -Loss:     0.8042 Training Accuracy: 0.868042 Validation Accuracy: 0.782540\n",
      "Epoch  5, Batch 161 -Loss:     0.8579 Training Accuracy: 0.879853 Validation Accuracy: 0.797732\n",
      "Epoch  5, Batch 162 -Loss:     1.0288 Training Accuracy: 0.890600 Validation Accuracy: 0.809751\n",
      "Epoch  5, Batch 163 -Loss:     0.8649 Training Accuracy: 0.880399 Validation Accuracy: 0.805442\n",
      "Epoch  5, Batch 164 -Loss:     0.9213 Training Accuracy: 0.867238 Validation Accuracy: 0.789342\n",
      "Epoch  5, Batch 165 -Loss:     0.9573 Training Accuracy: 0.860686 Validation Accuracy: 0.774376\n",
      "Epoch  5, Batch 166 -Loss:     0.9909 Training Accuracy: 0.849162 Validation Accuracy: 0.759864\n",
      "Epoch  5, Batch 167 -Loss:     1.0010 Training Accuracy: 0.856691 Validation Accuracy: 0.771202\n",
      "Epoch  5, Batch 168 -Loss:     1.0018 Training Accuracy: 0.873473 Validation Accuracy: 0.788662\n",
      "Epoch  5, Batch 169 -Loss:     0.8140 Training Accuracy: 0.872525 Validation Accuracy: 0.790023\n",
      "Epoch  5, Batch 170 -Loss:     1.0635 Training Accuracy: 0.865571 Validation Accuracy: 0.782540\n",
      "Epoch  5, Batch 171 -Loss:     1.0610 Training Accuracy: 0.866749 Validation Accuracy: 0.785714\n",
      "Epoch  5, Batch 172 -Loss:     0.9839 Training Accuracy: 0.865743 Validation Accuracy: 0.792290\n",
      "Epoch  5, Batch 173 -Loss:     0.8165 Training Accuracy: 0.849766 Validation Accuracy: 0.766893\n",
      "Epoch  5, Batch 174 -Loss:     0.9220 Training Accuracy: 0.863416 Validation Accuracy: 0.782086\n",
      "Epoch  5, Batch 175 -Loss:     1.0093 Training Accuracy: 0.882612 Validation Accuracy: 0.795238\n",
      "Epoch  5, Batch 176 -Loss:     0.8639 Training Accuracy: 0.877180 Validation Accuracy: 0.791610\n",
      "Epoch  5, Batch 177 -Loss:     0.8376 Training Accuracy: 0.867266 Validation Accuracy: 0.786168\n",
      "Epoch  5, Batch 178 -Loss:     0.9077 Training Accuracy: 0.864795 Validation Accuracy: 0.782766\n",
      "Epoch  5, Batch 179 -Loss:     0.8447 Training Accuracy: 0.864163 Validation Accuracy: 0.784127\n",
      "Epoch  5, Batch 180 -Loss:     0.9584 Training Accuracy: 0.855254 Validation Accuracy: 0.784807\n",
      "Epoch  5, Batch 181 -Loss:     0.8799 Training Accuracy: 0.841087 Validation Accuracy: 0.779138\n",
      "Epoch  5, Batch 182 -Loss:     0.9607 Training Accuracy: 0.855025 Validation Accuracy: 0.797052\n",
      "Epoch  5, Batch 183 -Loss:     1.0739 Training Accuracy: 0.859680 Validation Accuracy: 0.801587\n",
      "Epoch  5, Batch 184 -Loss:     0.8395 Training Accuracy: 0.840628 Validation Accuracy: 0.779365\n",
      "Epoch  5, Batch 185 -Loss:     0.9656 Training Accuracy: 0.859594 Validation Accuracy: 0.797052\n",
      "Epoch  5, Batch 186 -Loss:     0.8158 Training Accuracy: 0.879594 Validation Accuracy: 0.805896\n",
      "Epoch  5, Batch 187 -Loss:     0.8909 Training Accuracy: 0.836576 Validation Accuracy: 0.758277\n",
      "Epoch  5, Batch 188 -Loss:     0.9888 Training Accuracy: 0.797236 Validation Accuracy: 0.723810\n",
      "Epoch  5, Batch 189 -Loss:     0.8500 Training Accuracy: 0.852726 Validation Accuracy: 0.782766\n",
      "Epoch  5, Batch 190 -Loss:     0.9172 Training Accuracy: 0.873071 Validation Accuracy: 0.812245\n",
      "Epoch  5, Batch 191 -Loss:     0.9786 Training Accuracy: 0.867209 Validation Accuracy: 0.802721\n",
      "Epoch  5, Batch 192 -Loss:     1.0270 Training Accuracy: 0.870715 Validation Accuracy: 0.807483\n",
      "Epoch  5, Batch 193 -Loss:     1.0287 Training Accuracy: 0.881002 Validation Accuracy: 0.817460\n",
      "Epoch  5, Batch 194 -Loss:     0.8809 Training Accuracy: 0.873157 Validation Accuracy: 0.807483\n",
      "Epoch  5, Batch 195 -Loss:     1.0536 Training Accuracy: 0.846145 Validation Accuracy: 0.776871\n",
      "Epoch  5, Batch 196 -Loss:     1.0463 Training Accuracy: 0.837323 Validation Accuracy: 0.770522\n",
      "Epoch  5, Batch 197 -Loss:     0.9945 Training Accuracy: 0.862094 Validation Accuracy: 0.794558\n",
      "Epoch  5, Batch 198 -Loss:     0.9912 Training Accuracy: 0.877755 Validation Accuracy: 0.808163\n",
      "Epoch  5, Batch 199 -Loss:     0.9220 Training Accuracy: 0.869738 Validation Accuracy: 0.802041\n",
      "Epoch  5, Batch 200 -Loss:     0.9659 Training Accuracy: 0.867094 Validation Accuracy: 0.799546\n",
      "Epoch  5, Batch 201 -Loss:     0.9887 Training Accuracy: 0.873847 Validation Accuracy: 0.811111\n",
      "Epoch  5, Batch 202 -Loss:     0.8612 Training Accuracy: 0.880198 Validation Accuracy: 0.824036\n",
      "Epoch  5, Batch 203 -Loss:     1.0450 Training Accuracy: 0.869335 Validation Accuracy: 0.798639\n",
      "Epoch  5, Batch 204 -Loss:     0.8927 Training Accuracy: 0.855427 Validation Accuracy: 0.776190\n",
      "Epoch  5, Batch 205 -Loss:     0.8660 Training Accuracy: 0.842496 Validation Accuracy: 0.755556\n",
      "Epoch  5, Batch 206 -Loss:     0.8479 Training Accuracy: 0.853674 Validation Accuracy: 0.764172\n",
      "Epoch  5, Batch 207 -Loss:     1.0813 Training Accuracy: 0.854996 Validation Accuracy: 0.775510\n",
      "Epoch  5, Batch 208 -Loss:     0.9751 Training Accuracy: 0.858157 Validation Accuracy: 0.779819\n",
      "Epoch  5, Batch 209 -Loss:     0.8108 Training Accuracy: 0.863674 Validation Accuracy: 0.782313\n",
      "Epoch  5, Batch 210 -Loss:     0.8968 Training Accuracy: 0.867151 Validation Accuracy: 0.793197\n",
      "Epoch  5, Batch 211 -Loss:     0.9023 Training Accuracy: 0.858444 Validation Accuracy: 0.798186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5, Batch 212 -Loss:     0.8691 Training Accuracy: 0.851116 Validation Accuracy: 0.793878\n",
      "Epoch  5, Batch 213 -Loss:     0.9224 Training Accuracy: 0.863186 Validation Accuracy: 0.801361\n",
      "Epoch  5, Batch 214 -Loss:     0.8084 Training Accuracy: 0.875054 Validation Accuracy: 0.812698\n",
      "Epoch  5, Batch 215 -Loss:     0.8181 Training Accuracy: 0.872238 Validation Accuracy: 0.800000\n",
      "Epoch  5, Batch 216 -Loss:     0.8371 Training Accuracy: 0.867784 Validation Accuracy: 0.795011\n",
      "Epoch  5, Batch 217 -Loss:     0.8091 Training Accuracy: 0.872956 Validation Accuracy: 0.805215\n",
      "Epoch  5, Batch 218 -Loss:     0.8542 Training Accuracy: 0.874594 Validation Accuracy: 0.813605\n",
      "Epoch  5, Batch 219 -Loss:     0.9046 Training Accuracy: 0.873876 Validation Accuracy: 0.815646\n",
      "Epoch  5, Batch 220 -Loss:     0.9997 Training Accuracy: 0.876951 Validation Accuracy: 0.815419\n",
      "Epoch  5, Batch 221 -Loss:     1.1904 Training Accuracy: 0.886089 Validation Accuracy: 0.804308\n",
      "Epoch  5, Batch 222 -Loss:     0.9223 Training Accuracy: 0.879795 Validation Accuracy: 0.787302\n",
      "Epoch  5, Batch 223 -Loss:     0.8328 Training Accuracy: 0.850800 Validation Accuracy: 0.765986\n",
      "Epoch  5, Batch 224 -Loss:     0.9373 Training Accuracy: 0.847122 Validation Accuracy: 0.766667\n",
      "Epoch  5, Batch 225 -Loss:     0.9088 Training Accuracy: 0.870743 Validation Accuracy: 0.788209\n",
      "Epoch  5, Batch 226 -Loss:     0.9034 Training Accuracy: 0.878502 Validation Accuracy: 0.806576\n",
      "Epoch  5, Batch 227 -Loss:     1.0148 Training Accuracy: 0.877238 Validation Accuracy: 0.814059\n",
      "Epoch  5, Batch 228 -Loss:     0.8565 Training Accuracy: 0.882640 Validation Accuracy: 0.814739\n",
      "Epoch  5, Batch 229 -Loss:     0.8469 Training Accuracy: 0.890399 Validation Accuracy: 0.825397\n",
      "Epoch  5, Batch 230 -Loss:     0.7998 Training Accuracy: 0.885830 Validation Accuracy: 0.815873\n",
      "Epoch  5, Batch 231 -Loss:     0.8961 Training Accuracy: 0.862094 Validation Accuracy: 0.791610\n",
      "Epoch  5, Batch 232 -Loss:     0.9037 Training Accuracy: 0.856548 Validation Accuracy: 0.783673\n",
      "Epoch  5, Batch 233 -Loss:     0.9874 Training Accuracy: 0.873100 Validation Accuracy: 0.796825\n",
      "Epoch  5, Batch 234 -Loss:     0.9017 Training Accuracy: 0.892066 Validation Accuracy: 0.820635\n",
      "Epoch  5, Batch 235 -Loss:     0.9526 Training Accuracy: 0.885715 Validation Accuracy: 0.807936\n",
      "Epoch  5, Batch 236 -Loss:     0.9635 Training Accuracy: 0.870628 Validation Accuracy: 0.798413\n",
      "Epoch  5, Batch 237 -Loss:     0.9620 Training Accuracy: 0.867611 Validation Accuracy: 0.790930\n",
      "Epoch  5, Batch 238 -Loss:     1.0491 Training Accuracy: 0.875629 Validation Accuracy: 0.799773\n",
      "Epoch  5, Batch 239 -Loss:     0.9377 Training Accuracy: 0.864019 Validation Accuracy: 0.790930\n",
      "Epoch  5, Batch 240 -Loss:     0.9551 Training Accuracy: 0.847294 Validation Accuracy: 0.775283\n",
      "Epoch  5, Batch 241 -Loss:     0.9142 Training Accuracy: 0.849909 Validation Accuracy: 0.777098\n",
      "Epoch  5, Batch 242 -Loss:     0.9628 Training Accuracy: 0.879537 Validation Accuracy: 0.800680\n",
      "Epoch  5, Batch 243 -Loss:     0.8963 Training Accuracy: 0.886778 Validation Accuracy: 0.809751\n",
      "Epoch  5, Batch 244 -Loss:     0.9641 Training Accuracy: 0.877755 Validation Accuracy: 0.805669\n",
      "Epoch  5, Batch 245 -Loss:     1.1032 Training Accuracy: 0.879278 Validation Accuracy: 0.807029\n",
      "Epoch  5, Batch 246 -Loss:     0.8622 Training Accuracy: 0.888732 Validation Accuracy: 0.816553\n",
      "Epoch  5, Batch 247 -Loss:     0.9108 Training Accuracy: 0.885974 Validation Accuracy: 0.813379\n",
      "Epoch  5, Batch 248 -Loss:     0.9880 Training Accuracy: 0.872927 Validation Accuracy: 0.797506\n",
      "Epoch  5, Batch 249 -Loss:     0.7622 Training Accuracy: 0.870456 Validation Accuracy: 0.795918\n",
      "Epoch  5, Batch 250 -Loss:     0.9397 Training Accuracy: 0.872899 Validation Accuracy: 0.801814\n",
      "Epoch  5, Batch 251 -Loss:     0.7982 Training Accuracy: 0.865054 Validation Accuracy: 0.798186\n",
      "Epoch  5, Batch 252 -Loss:     0.8606 Training Accuracy: 0.857122 Validation Accuracy: 0.799320\n",
      "Epoch  5, Batch 253 -Loss:     0.9339 Training Accuracy: 0.861318 Validation Accuracy: 0.801361\n",
      "Epoch  5, Batch 254 -Loss:     0.8851 Training Accuracy: 0.867295 Validation Accuracy: 0.800454\n",
      "Epoch  5, Batch 255 -Loss:     0.9014 Training Accuracy: 0.879623 Validation Accuracy: 0.815193\n",
      "Epoch  5, Batch 256 -Loss:     0.8498 Training Accuracy: 0.878876 Validation Accuracy: 0.817687\n",
      "Epoch  5, Batch 257 -Loss:     0.8400 Training Accuracy: 0.870054 Validation Accuracy: 0.813605\n",
      "Epoch  5, Batch 258 -Loss:     1.0250 Training Accuracy: 0.863732 Validation Accuracy: 0.805896\n",
      "Epoch  5, Batch 259 -Loss:     0.9021 Training Accuracy: 0.856979 Validation Accuracy: 0.795465\n",
      "Epoch  5, Batch 260 -Loss:     0.8925 Training Accuracy: 0.872870 Validation Accuracy: 0.802721\n",
      "Epoch  5, Batch 261 -Loss:     0.8116 Training Accuracy: 0.882985 Validation Accuracy: 0.814739\n",
      "Epoch  5, Batch 262 -Loss:     0.8613 Training Accuracy: 0.880686 Validation Accuracy: 0.812472\n",
      "Epoch  5, Batch 263 -Loss:     0.8700 Training Accuracy: 0.873416 Validation Accuracy: 0.808617\n",
      "Epoch  5, Batch 264 -Loss:     0.8353 Training Accuracy: 0.872841 Validation Accuracy: 0.810658\n",
      "Epoch  5, Batch 265 -Loss:     0.9614 Training Accuracy: 0.883330 Validation Accuracy: 0.812925\n",
      "Epoch  5, Batch 266 -Loss:     0.9476 Training Accuracy: 0.886376 Validation Accuracy: 0.813605\n",
      "Epoch  5, Batch 267 -Loss:     0.8625 Training Accuracy: 0.873186 Validation Accuracy: 0.805215\n",
      "Epoch  5, Batch 268 -Loss:     0.9812 Training Accuracy: 0.863444 Validation Accuracy: 0.792063\n",
      "Epoch  5, Batch 269 -Loss:     0.8789 Training Accuracy: 0.869536 Validation Accuracy: 0.790930\n",
      "Epoch  5, Batch 270 -Loss:     0.9090 Training Accuracy: 0.881203 Validation Accuracy: 0.799546\n",
      "Epoch  5, Batch 271 -Loss:     0.9334 Training Accuracy: 0.879939 Validation Accuracy: 0.806576\n",
      "Epoch  5, Batch 272 -Loss:     0.9821 Training Accuracy: 0.875456 Validation Accuracy: 0.805442\n",
      "Epoch  6, Batch   1 -Loss:     0.9040 Training Accuracy: 0.878962 Validation Accuracy: 0.807256\n",
      "Epoch  6, Batch   2 -Loss:     0.8887 Training Accuracy: 0.879997 Validation Accuracy: 0.815419\n",
      "Epoch  6, Batch   3 -Loss:     0.9242 Training Accuracy: 0.879278 Validation Accuracy: 0.808390\n",
      "Epoch  6, Batch   4 -Loss:     0.9594 Training Accuracy: 0.866634 Validation Accuracy: 0.790023\n",
      "Epoch  6, Batch   5 -Loss:     0.9844 Training Accuracy: 0.867726 Validation Accuracy: 0.788662\n",
      "Epoch  6, Batch   6 -Loss:     0.8304 Training Accuracy: 0.876088 Validation Accuracy: 0.793424\n",
      "Epoch  6, Batch   7 -Loss:     0.8043 Training Accuracy: 0.872381 Validation Accuracy: 0.795692\n",
      "Epoch  6, Batch   8 -Loss:     0.9110 Training Accuracy: 0.867439 Validation Accuracy: 0.794331\n",
      "Epoch  6, Batch   9 -Loss:     0.8713 Training Accuracy: 0.866203 Validation Accuracy: 0.792971\n",
      "Epoch  6, Batch  10 -Loss:     0.9376 Training Accuracy: 0.865398 Validation Accuracy: 0.785714\n",
      "Epoch  6, Batch  11 -Loss:     0.8973 Training Accuracy: 0.861145 Validation Accuracy: 0.778912\n",
      "Epoch  6, Batch  12 -Loss:     0.8270 Training Accuracy: 0.864077 Validation Accuracy: 0.783447\n",
      "Epoch  6, Batch  13 -Loss:     0.9920 Training Accuracy: 0.873502 Validation Accuracy: 0.787075\n",
      "Epoch  6, Batch  14 -Loss:     0.9244 Training Accuracy: 0.886750 Validation Accuracy: 0.801587\n",
      "Epoch  6, Batch  15 -Loss:     0.9279 Training Accuracy: 0.893388 Validation Accuracy: 0.814966\n",
      "Epoch  6, Batch  16 -Loss:     0.8121 Training Accuracy: 0.888847 Validation Accuracy: 0.813605\n",
      "Epoch  6, Batch  17 -Loss:     1.0399 Training Accuracy: 0.884508 Validation Accuracy: 0.812698\n",
      "Epoch  6, Batch  18 -Loss:     0.8745 Training Accuracy: 0.868990 Validation Accuracy: 0.801134\n",
      "Epoch  6, Batch  19 -Loss:     0.8565 Training Accuracy: 0.865082 Validation Accuracy: 0.800454\n",
      "Epoch  6, Batch  20 -Loss:     1.0232 Training Accuracy: 0.882726 Validation Accuracy: 0.816100\n",
      "Epoch  6, Batch  21 -Loss:     0.8225 Training Accuracy: 0.895342 Validation Accuracy: 0.827664\n",
      "Epoch  6, Batch  22 -Loss:     0.9117 Training Accuracy: 0.887612 Validation Accuracy: 0.822676\n",
      "Epoch  6, Batch  23 -Loss:     0.8163 Training Accuracy: 0.881807 Validation Accuracy: 0.813832\n",
      "Epoch  6, Batch  24 -Loss:     0.8748 Training Accuracy: 0.883387 Validation Accuracy: 0.808844\n",
      "Epoch  6, Batch  25 -Loss:     0.7942 Training Accuracy: 0.882956 Validation Accuracy: 0.791383\n",
      "Epoch  6, Batch  26 -Loss:     0.9224 Training Accuracy: 0.878215 Validation Accuracy: 0.781179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6, Batch  27 -Loss:     0.9696 Training Accuracy: 0.859680 Validation Accuracy: 0.764853\n",
      "Epoch  6, Batch  28 -Loss:     0.8560 Training Accuracy: 0.856663 Validation Accuracy: 0.774376\n",
      "Epoch  6, Batch  29 -Loss:     0.8530 Training Accuracy: 0.867467 Validation Accuracy: 0.788435\n",
      "Epoch  6, Batch  30 -Loss:     1.0275 Training Accuracy: 0.881635 Validation Accuracy: 0.800000\n",
      "Epoch  6, Batch  31 -Loss:     0.9287 Training Accuracy: 0.883359 Validation Accuracy: 0.799320\n",
      "Epoch  6, Batch  32 -Loss:     0.9498 Training Accuracy: 0.871778 Validation Accuracy: 0.791156\n",
      "Epoch  6, Batch  33 -Loss:     0.9327 Training Accuracy: 0.872439 Validation Accuracy: 0.783673\n",
      "Epoch  6, Batch  34 -Loss:     0.9397 Training Accuracy: 0.880341 Validation Accuracy: 0.797279\n",
      "Epoch  6, Batch  35 -Loss:     0.8470 Training Accuracy: 0.883876 Validation Accuracy: 0.808390\n",
      "Epoch  6, Batch  36 -Loss:     0.8835 Training Accuracy: 0.871117 Validation Accuracy: 0.809977\n",
      "Epoch  6, Batch  37 -Loss:     0.8950 Training Accuracy: 0.859019 Validation Accuracy: 0.802721\n",
      "Epoch  6, Batch  38 -Loss:     1.0755 Training Accuracy: 0.865513 Validation Accuracy: 0.806803\n",
      "Epoch  6, Batch  39 -Loss:     0.7614 Training Accuracy: 0.864766 Validation Accuracy: 0.800000\n",
      "Epoch  6, Batch  40 -Loss:     0.9327 Training Accuracy: 0.870255 Validation Accuracy: 0.798186\n",
      "Epoch  6, Batch  41 -Loss:     0.9135 Training Accuracy: 0.880313 Validation Accuracy: 0.802494\n",
      "Epoch  6, Batch  42 -Loss:     0.8698 Training Accuracy: 0.886434 Validation Accuracy: 0.815419\n",
      "Epoch  6, Batch  43 -Loss:     1.0005 Training Accuracy: 0.886462 Validation Accuracy: 0.812925\n",
      "Epoch  6, Batch  44 -Loss:     0.8613 Training Accuracy: 0.884824 Validation Accuracy: 0.814739\n",
      "Epoch  6, Batch  45 -Loss:     0.8502 Training Accuracy: 0.872381 Validation Accuracy: 0.809070\n",
      "Epoch  6, Batch  46 -Loss:     0.8258 Training Accuracy: 0.843185 Validation Accuracy: 0.780045\n",
      "Epoch  6, Batch  47 -Loss:     0.8835 Training Accuracy: 0.844220 Validation Accuracy: 0.774376\n",
      "Epoch  6, Batch  48 -Loss:     0.9084 Training Accuracy: 0.864536 Validation Accuracy: 0.789342\n",
      "Epoch  6, Batch  49 -Loss:     0.9197 Training Accuracy: 0.868358 Validation Accuracy: 0.784354\n",
      "Epoch  6, Batch  50 -Loss:     1.0138 Training Accuracy: 0.867611 Validation Accuracy: 0.786621\n",
      "Epoch  6, Batch  51 -Loss:     1.0522 Training Accuracy: 0.872295 Validation Accuracy: 0.790476\n",
      "Epoch  6, Batch  52 -Loss:     0.8850 Training Accuracy: 0.868703 Validation Accuracy: 0.789796\n",
      "Epoch  6, Batch  53 -Loss:     0.8914 Training Accuracy: 0.868904 Validation Accuracy: 0.795011\n",
      "Epoch  6, Batch  54 -Loss:     0.8333 Training Accuracy: 0.873991 Validation Accuracy: 0.801814\n",
      "Epoch  6, Batch  55 -Loss:     0.9373 Training Accuracy: 0.874968 Validation Accuracy: 0.800000\n",
      "Epoch  6, Batch  56 -Loss:     0.8272 Training Accuracy: 0.866778 Validation Accuracy: 0.782086\n",
      "Epoch  6, Batch  57 -Loss:     0.9786 Training Accuracy: 0.864048 Validation Accuracy: 0.773923\n",
      "Epoch  6, Batch  58 -Loss:     0.8405 Training Accuracy: 0.868646 Validation Accuracy: 0.778458\n",
      "Epoch  6, Batch  59 -Loss:     0.8665 Training Accuracy: 0.877382 Validation Accuracy: 0.791837\n",
      "Epoch  6, Batch  60 -Loss:     0.8295 Training Accuracy: 0.889508 Validation Accuracy: 0.804535\n",
      "Epoch  6, Batch  61 -Loss:     0.9306 Training Accuracy: 0.885686 Validation Accuracy: 0.803401\n",
      "Epoch  6, Batch  62 -Loss:     0.9270 Training Accuracy: 0.881318 Validation Accuracy: 0.800454\n",
      "Epoch  6, Batch  63 -Loss:     0.8668 Training Accuracy: 0.884278 Validation Accuracy: 0.802721\n",
      "Epoch  6, Batch  64 -Loss:     0.8140 Training Accuracy: 0.886434 Validation Accuracy: 0.802041\n",
      "Epoch  6, Batch  65 -Loss:     0.7158 Training Accuracy: 0.879106 Validation Accuracy: 0.793197\n",
      "Epoch  6, Batch  66 -Loss:     0.7494 Training Accuracy: 0.867094 Validation Accuracy: 0.783673\n",
      "Epoch  6, Batch  67 -Loss:     0.7835 Training Accuracy: 0.871979 Validation Accuracy: 0.794104\n",
      "Epoch  6, Batch  68 -Loss:     0.8233 Training Accuracy: 0.880772 Validation Accuracy: 0.806122\n",
      "Epoch  6, Batch  69 -Loss:     0.8037 Training Accuracy: 0.891951 Validation Accuracy: 0.811791\n",
      "Epoch  6, Batch  70 -Loss:     0.8949 Training Accuracy: 0.891549 Validation Accuracy: 0.810658\n",
      "Epoch  6, Batch  71 -Loss:     0.8231 Training Accuracy: 0.879307 Validation Accuracy: 0.807029\n",
      "Epoch  6, Batch  72 -Loss:     0.9373 Training Accuracy: 0.864479 Validation Accuracy: 0.797506\n",
      "Epoch  6, Batch  73 -Loss:     0.8478 Training Accuracy: 0.854048 Validation Accuracy: 0.791383\n",
      "Epoch  6, Batch  74 -Loss:     0.9706 Training Accuracy: 0.856375 Validation Accuracy: 0.782993\n",
      "Epoch  6, Batch  75 -Loss:     0.9594 Training Accuracy: 0.866519 Validation Accuracy: 0.790023\n",
      "Epoch  6, Batch  76 -Loss:     0.8743 Training Accuracy: 0.876634 Validation Accuracy: 0.809524\n",
      "Epoch  6, Batch  77 -Loss:     0.7411 Training Accuracy: 0.869307 Validation Accuracy: 0.805669\n",
      "Epoch  6, Batch  78 -Loss:     0.8980 Training Accuracy: 0.861232 Validation Accuracy: 0.799773\n",
      "Epoch  6, Batch  79 -Loss:     0.8961 Training Accuracy: 0.881663 Validation Accuracy: 0.811338\n",
      "Epoch  6, Batch  80 -Loss:     0.8564 Training Accuracy: 0.893761 Validation Accuracy: 0.816780\n",
      "Epoch  6, Batch  81 -Loss:     0.9063 Training Accuracy: 0.897353 Validation Accuracy: 0.814966\n",
      "Epoch  6, Batch  82 -Loss:     0.7909 Training Accuracy: 0.885830 Validation Accuracy: 0.803175\n",
      "Epoch  6, Batch  83 -Loss:     1.0105 Training Accuracy: 0.862927 Validation Accuracy: 0.789569\n",
      "Epoch  6, Batch  84 -Loss:     0.8625 Training Accuracy: 0.857209 Validation Accuracy: 0.780045\n",
      "Epoch  6, Batch  85 -Loss:     0.7742 Training Accuracy: 0.862324 Validation Accuracy: 0.779138\n",
      "Epoch  6, Batch  86 -Loss:     0.7685 Training Accuracy: 0.870341 Validation Accuracy: 0.782086\n",
      "Epoch  6, Batch  87 -Loss:     0.7891 Training Accuracy: 0.890687 Validation Accuracy: 0.807256\n",
      "Epoch  6, Batch  88 -Loss:     0.8189 Training Accuracy: 0.893790 Validation Accuracy: 0.811565\n",
      "Epoch  6, Batch  89 -Loss:     1.0445 Training Accuracy: 0.887353 Validation Accuracy: 0.808163\n",
      "Epoch  6, Batch  90 -Loss:     0.9343 Training Accuracy: 0.881893 Validation Accuracy: 0.804535\n",
      "Epoch  6, Batch  91 -Loss:     0.8738 Training Accuracy: 0.886548 Validation Accuracy: 0.811111\n",
      "Epoch  6, Batch  92 -Loss:     0.8644 Training Accuracy: 0.889767 Validation Accuracy: 0.817687\n",
      "Epoch  6, Batch  93 -Loss:     0.8284 Training Accuracy: 0.884652 Validation Accuracy: 0.817914\n",
      "Epoch  6, Batch  94 -Loss:     0.8625 Training Accuracy: 0.885112 Validation Accuracy: 0.814966\n",
      "Epoch  6, Batch  95 -Loss:     0.8176 Training Accuracy: 0.884882 Validation Accuracy: 0.809524\n",
      "Epoch  6, Batch  96 -Loss:     0.7555 Training Accuracy: 0.885715 Validation Accuracy: 0.806803\n",
      "Epoch  6, Batch  97 -Loss:     0.9036 Training Accuracy: 0.884537 Validation Accuracy: 0.804082\n",
      "Epoch  6, Batch  98 -Loss:     0.8830 Training Accuracy: 0.882583 Validation Accuracy: 0.805669\n",
      "Epoch  6, Batch  99 -Loss:     0.8594 Training Accuracy: 0.885773 Validation Accuracy: 0.806803\n",
      "Epoch  6, Batch 100 -Loss:     0.8327 Training Accuracy: 0.891779 Validation Accuracy: 0.818594\n",
      "Epoch  6, Batch 101 -Loss:     0.7571 Training Accuracy: 0.899882 Validation Accuracy: 0.826077\n",
      "Epoch  6, Batch 102 -Loss:     0.7881 Training Accuracy: 0.900399 Validation Accuracy: 0.824717\n",
      "Epoch  6, Batch 103 -Loss:     0.8618 Training Accuracy: 0.891491 Validation Accuracy: 0.815873\n",
      "Epoch  6, Batch 104 -Loss:     0.8489 Training Accuracy: 0.891491 Validation Accuracy: 0.818141\n",
      "Epoch  6, Batch 105 -Loss:     0.7574 Training Accuracy: 0.889882 Validation Accuracy: 0.814739\n",
      "Epoch  6, Batch 106 -Loss:     0.9281 Training Accuracy: 0.888445 Validation Accuracy: 0.812245\n",
      "Epoch  6, Batch 107 -Loss:     0.7434 Training Accuracy: 0.886778 Validation Accuracy: 0.807936\n",
      "Epoch  6, Batch 108 -Loss:     0.9141 Training Accuracy: 0.893158 Validation Accuracy: 0.816780\n",
      "Epoch  6, Batch 109 -Loss:     0.8968 Training Accuracy: 0.895342 Validation Accuracy: 0.826531\n",
      "Epoch  6, Batch 110 -Loss:     0.8908 Training Accuracy: 0.891118 Validation Accuracy: 0.821542\n",
      "Epoch  6, Batch 111 -Loss:     0.8321 Training Accuracy: 0.890428 Validation Accuracy: 0.814966\n",
      "Epoch  6, Batch 112 -Loss:     0.8739 Training Accuracy: 0.888675 Validation Accuracy: 0.808617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6, Batch 113 -Loss:     0.8438 Training Accuracy: 0.890198 Validation Accuracy: 0.804762\n",
      "Epoch  6, Batch 114 -Loss:     0.7529 Training Accuracy: 0.890342 Validation Accuracy: 0.805669\n",
      "Epoch  6, Batch 115 -Loss:     0.8409 Training Accuracy: 0.886002 Validation Accuracy: 0.809297\n",
      "Epoch  6, Batch 116 -Loss:     0.8244 Training Accuracy: 0.884106 Validation Accuracy: 0.808844\n",
      "Epoch  6, Batch 117 -Loss:     0.7226 Training Accuracy: 0.883186 Validation Accuracy: 0.809977\n",
      "Epoch  6, Batch 118 -Loss:     0.9057 Training Accuracy: 0.874680 Validation Accuracy: 0.804535\n",
      "Epoch  6, Batch 119 -Loss:     0.8596 Training Accuracy: 0.867094 Validation Accuracy: 0.800227\n",
      "Epoch  6, Batch 120 -Loss:     0.8751 Training Accuracy: 0.882985 Validation Accuracy: 0.812925\n",
      "Epoch  6, Batch 121 -Loss:     0.9533 Training Accuracy: 0.890370 Validation Accuracy: 0.814286\n",
      "Epoch  6, Batch 122 -Loss:     0.9014 Training Accuracy: 0.879249 Validation Accuracy: 0.808390\n",
      "Epoch  6, Batch 123 -Loss:     0.8249 Training Accuracy: 0.881721 Validation Accuracy: 0.800680\n",
      "Epoch  6, Batch 124 -Loss:     0.8347 Training Accuracy: 0.880744 Validation Accuracy: 0.786621\n",
      "Epoch  6, Batch 125 -Loss:     0.8675 Training Accuracy: 0.876663 Validation Accuracy: 0.781406\n",
      "Epoch  6, Batch 126 -Loss:     0.8486 Training Accuracy: 0.885744 Validation Accuracy: 0.797959\n",
      "Epoch  6, Batch 127 -Loss:     0.8113 Training Accuracy: 0.889652 Validation Accuracy: 0.809977\n",
      "Epoch  6, Batch 128 -Loss:     1.1425 Training Accuracy: 0.886089 Validation Accuracy: 0.811338\n",
      "Epoch  6, Batch 129 -Loss:     0.8520 Training Accuracy: 0.882841 Validation Accuracy: 0.814966\n",
      "Epoch  6, Batch 130 -Loss:     0.8449 Training Accuracy: 0.894853 Validation Accuracy: 0.820181\n",
      "Epoch  6, Batch 131 -Loss:     0.8403 Training Accuracy: 0.902325 Validation Accuracy: 0.816780\n",
      "Epoch  6, Batch 132 -Loss:     0.8352 Training Accuracy: 0.885025 Validation Accuracy: 0.799773\n",
      "Epoch  6, Batch 133 -Loss:     0.8999 Training Accuracy: 0.875600 Validation Accuracy: 0.794558\n",
      "Epoch  6, Batch 134 -Loss:     0.8551 Training Accuracy: 0.878531 Validation Accuracy: 0.795918\n",
      "Epoch  6, Batch 135 -Loss:     0.8724 Training Accuracy: 0.888474 Validation Accuracy: 0.805669\n",
      "Epoch  6, Batch 136 -Loss:     0.8353 Training Accuracy: 0.891060 Validation Accuracy: 0.809297\n",
      "Epoch  6, Batch 137 -Loss:     0.8807 Training Accuracy: 0.879824 Validation Accuracy: 0.805896\n",
      "Epoch  6, Batch 138 -Loss:     0.7948 Training Accuracy: 0.869019 Validation Accuracy: 0.796372\n",
      "Epoch  6, Batch 139 -Loss:     0.8166 Training Accuracy: 0.869623 Validation Accuracy: 0.798186\n",
      "Epoch  6, Batch 140 -Loss:     0.7883 Training Accuracy: 0.875887 Validation Accuracy: 0.803628\n",
      "Epoch  6, Batch 141 -Loss:     0.7984 Training Accuracy: 0.887842 Validation Accuracy: 0.817460\n",
      "Epoch  6, Batch 142 -Loss:     0.9224 Training Accuracy: 0.893330 Validation Accuracy: 0.816780\n",
      "Epoch  6, Batch 143 -Loss:     0.7552 Training Accuracy: 0.890687 Validation Accuracy: 0.811791\n",
      "Epoch  6, Batch 144 -Loss:     0.7812 Training Accuracy: 0.890083 Validation Accuracy: 0.808163\n",
      "Epoch  6, Batch 145 -Loss:     0.7711 Training Accuracy: 0.884566 Validation Accuracy: 0.804989\n",
      "Epoch  6, Batch 146 -Loss:     0.7973 Training Accuracy: 0.893589 Validation Accuracy: 0.812925\n",
      "Epoch  6, Batch 147 -Loss:     0.8030 Training Accuracy: 0.895629 Validation Accuracy: 0.814966\n",
      "Epoch  6, Batch 148 -Loss:     0.8714 Training Accuracy: 0.895141 Validation Accuracy: 0.819955\n",
      "Epoch  6, Batch 149 -Loss:     0.9826 Training Accuracy: 0.889106 Validation Accuracy: 0.816327\n",
      "Epoch  6, Batch 150 -Loss:     0.9046 Training Accuracy: 0.887612 Validation Accuracy: 0.801361\n",
      "Epoch  6, Batch 151 -Loss:     0.7674 Training Accuracy: 0.891721 Validation Accuracy: 0.802494\n",
      "Epoch  6, Batch 152 -Loss:     0.9513 Training Accuracy: 0.895198 Validation Accuracy: 0.812018\n",
      "Epoch  6, Batch 153 -Loss:     0.8463 Training Accuracy: 0.893905 Validation Accuracy: 0.809070\n",
      "Epoch  6, Batch 154 -Loss:     0.7126 Training Accuracy: 0.894135 Validation Accuracy: 0.805442\n",
      "Epoch  6, Batch 155 -Loss:     0.8137 Training Accuracy: 0.891865 Validation Accuracy: 0.802948\n",
      "Epoch  6, Batch 156 -Loss:     0.7647 Training Accuracy: 0.886778 Validation Accuracy: 0.804989\n",
      "Epoch  6, Batch 157 -Loss:     0.8242 Training Accuracy: 0.884135 Validation Accuracy: 0.806803\n",
      "Epoch  6, Batch 158 -Loss:     0.9438 Training Accuracy: 0.881951 Validation Accuracy: 0.808163\n",
      "Epoch  6, Batch 159 -Loss:     0.7935 Training Accuracy: 0.884192 Validation Accuracy: 0.808844\n",
      "Epoch  6, Batch 160 -Loss:     0.7149 Training Accuracy: 0.887353 Validation Accuracy: 0.812018\n",
      "Epoch  6, Batch 161 -Loss:     0.8700 Training Accuracy: 0.893244 Validation Accuracy: 0.818141\n",
      "Epoch  6, Batch 162 -Loss:     0.8601 Training Accuracy: 0.899451 Validation Accuracy: 0.823810\n",
      "Epoch  6, Batch 163 -Loss:     0.7457 Training Accuracy: 0.900802 Validation Accuracy: 0.822222\n",
      "Epoch  6, Batch 164 -Loss:     0.7593 Training Accuracy: 0.892008 Validation Accuracy: 0.812698\n",
      "Epoch  6, Batch 165 -Loss:     0.7973 Training Accuracy: 0.895457 Validation Accuracy: 0.809751\n",
      "Epoch  6, Batch 166 -Loss:     0.7670 Training Accuracy: 0.898905 Validation Accuracy: 0.811791\n",
      "Epoch  6, Batch 167 -Loss:     0.8461 Training Accuracy: 0.899250 Validation Accuracy: 0.812245\n",
      "Epoch  6, Batch 168 -Loss:     0.7562 Training Accuracy: 0.889192 Validation Accuracy: 0.803401\n",
      "Epoch  6, Batch 169 -Loss:     0.9232 Training Accuracy: 0.881922 Validation Accuracy: 0.796825\n",
      "Epoch  6, Batch 170 -Loss:     0.7448 Training Accuracy: 0.874565 Validation Accuracy: 0.795011\n",
      "Epoch  6, Batch 171 -Loss:     0.7393 Training Accuracy: 0.875571 Validation Accuracy: 0.800454\n",
      "Epoch  6, Batch 172 -Loss:     0.7772 Training Accuracy: 0.892698 Validation Accuracy: 0.821315\n",
      "Epoch  6, Batch 173 -Loss:     0.8682 Training Accuracy: 0.897526 Validation Accuracy: 0.824036\n",
      "Epoch  6, Batch 174 -Loss:     0.8393 Training Accuracy: 0.897325 Validation Accuracy: 0.823356\n",
      "Epoch  6, Batch 175 -Loss:     0.6901 Training Accuracy: 0.893100 Validation Accuracy: 0.817234\n",
      "Epoch  6, Batch 176 -Loss:     0.7486 Training Accuracy: 0.883215 Validation Accuracy: 0.804308\n",
      "Epoch  6, Batch 177 -Loss:     0.8400 Training Accuracy: 0.880514 Validation Accuracy: 0.802268\n",
      "Epoch  6, Batch 178 -Loss:     0.8615 Training Accuracy: 0.882554 Validation Accuracy: 0.806122\n",
      "Epoch  6, Batch 179 -Loss:     0.9003 Training Accuracy: 0.881376 Validation Accuracy: 0.808844\n",
      "Epoch  6, Batch 180 -Loss:     0.7268 Training Accuracy: 0.878905 Validation Accuracy: 0.818141\n",
      "Epoch  6, Batch 181 -Loss:     0.8702 Training Accuracy: 0.890859 Validation Accuracy: 0.825397\n",
      "Epoch  6, Batch 182 -Loss:     0.7512 Training Accuracy: 0.897009 Validation Accuracy: 0.817914\n",
      "Epoch  6, Batch 183 -Loss:     0.9552 Training Accuracy: 0.892008 Validation Accuracy: 0.807710\n",
      "Epoch  6, Batch 184 -Loss:     0.8027 Training Accuracy: 0.883646 Validation Accuracy: 0.802948\n",
      "Epoch  6, Batch 185 -Loss:     0.8019 Training Accuracy: 0.882008 Validation Accuracy: 0.805442\n",
      "Epoch  6, Batch 186 -Loss:     0.9174 Training Accuracy: 0.876203 Validation Accuracy: 0.806349\n",
      "Epoch  6, Batch 187 -Loss:     0.7659 Training Accuracy: 0.866289 Validation Accuracy: 0.799773\n",
      "Epoch  6, Batch 188 -Loss:     0.7639 Training Accuracy: 0.862870 Validation Accuracy: 0.795238\n",
      "Epoch  6, Batch 189 -Loss:     0.8570 Training Accuracy: 0.873157 Validation Accuracy: 0.800907\n",
      "Epoch  6, Batch 190 -Loss:     0.8037 Training Accuracy: 0.887123 Validation Accuracy: 0.806803\n",
      "Epoch  6, Batch 191 -Loss:     0.8016 Training Accuracy: 0.894336 Validation Accuracy: 0.797279\n",
      "Epoch  6, Batch 192 -Loss:     0.7304 Training Accuracy: 0.882382 Validation Accuracy: 0.782086\n",
      "Epoch  6, Batch 193 -Loss:     0.8220 Training Accuracy: 0.869968 Validation Accuracy: 0.778912\n",
      "Epoch  6, Batch 194 -Loss:     0.7449 Training Accuracy: 0.865887 Validation Accuracy: 0.779138\n",
      "Epoch  6, Batch 195 -Loss:     0.7899 Training Accuracy: 0.875973 Validation Accuracy: 0.787755\n",
      "Epoch  6, Batch 196 -Loss:     0.7899 Training Accuracy: 0.900888 Validation Accuracy: 0.805896\n",
      "Epoch  6, Batch 197 -Loss:     0.7362 Training Accuracy: 0.885744 Validation Accuracy: 0.805669\n",
      "Epoch  6, Batch 198 -Loss:     0.8596 Training Accuracy: 0.846145 Validation Accuracy: 0.777324\n",
      "Epoch  6, Batch 199 -Loss:     0.8893 Training Accuracy: 0.849249 Validation Accuracy: 0.780952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6, Batch 200 -Loss:     0.8213 Training Accuracy: 0.881692 Validation Accuracy: 0.805669\n",
      "Epoch  6, Batch 201 -Loss:     0.7863 Training Accuracy: 0.897440 Validation Accuracy: 0.808390\n",
      "Epoch  6, Batch 202 -Loss:     0.8262 Training Accuracy: 0.889566 Validation Accuracy: 0.808390\n",
      "Epoch  6, Batch 203 -Loss:     0.7815 Training Accuracy: 0.877267 Validation Accuracy: 0.800454\n",
      "Epoch  6, Batch 204 -Loss:     0.7497 Training Accuracy: 0.881089 Validation Accuracy: 0.807483\n",
      "Epoch  6, Batch 205 -Loss:     0.7632 Training Accuracy: 0.890342 Validation Accuracy: 0.815193\n",
      "Epoch  6, Batch 206 -Loss:     0.8484 Training Accuracy: 0.898991 Validation Accuracy: 0.823129\n",
      "Epoch  6, Batch 207 -Loss:     0.9195 Training Accuracy: 0.902497 Validation Accuracy: 0.827211\n",
      "Epoch  6, Batch 208 -Loss:     0.9234 Training Accuracy: 0.899652 Validation Accuracy: 0.821995\n",
      "Epoch  6, Batch 209 -Loss:     0.8694 Training Accuracy: 0.891347 Validation Accuracy: 0.808844\n",
      "Epoch  6, Batch 210 -Loss:     0.8650 Training Accuracy: 0.879795 Validation Accuracy: 0.793424\n",
      "Epoch  6, Batch 211 -Loss:     0.8801 Training Accuracy: 0.890830 Validation Accuracy: 0.799546\n",
      "Epoch  6, Batch 212 -Loss:     0.8508 Training Accuracy: 0.901578 Validation Accuracy: 0.815646\n",
      "Epoch  6, Batch 213 -Loss:     0.7954 Training Accuracy: 0.897152 Validation Accuracy: 0.818594\n",
      "Epoch  6, Batch 214 -Loss:     0.8231 Training Accuracy: 0.891865 Validation Accuracy: 0.821088\n",
      "Epoch  6, Batch 215 -Loss:     0.9410 Training Accuracy: 0.890773 Validation Accuracy: 0.818367\n",
      "Epoch  6, Batch 216 -Loss:     0.8074 Training Accuracy: 0.895629 Validation Accuracy: 0.826757\n",
      "Epoch  6, Batch 217 -Loss:     0.8194 Training Accuracy: 0.899422 Validation Accuracy: 0.831066\n",
      "Epoch  6, Batch 218 -Loss:     1.0958 Training Accuracy: 0.887008 Validation Accuracy: 0.819501\n",
      "Epoch  6, Batch 219 -Loss:     0.8205 Training Accuracy: 0.874939 Validation Accuracy: 0.801814\n",
      "Epoch  6, Batch 220 -Loss:     0.8544 Training Accuracy: 0.889106 Validation Accuracy: 0.811111\n",
      "Epoch  6, Batch 221 -Loss:     0.7889 Training Accuracy: 0.900716 Validation Accuracy: 0.819274\n",
      "Epoch  6, Batch 222 -Loss:     0.8003 Training Accuracy: 0.883474 Validation Accuracy: 0.801814\n",
      "Epoch  6, Batch 223 -Loss:     0.8721 Training Accuracy: 0.875858 Validation Accuracy: 0.797052\n",
      "Epoch  6, Batch 224 -Loss:     0.6932 Training Accuracy: 0.893646 Validation Accuracy: 0.810431\n",
      "Epoch  6, Batch 225 -Loss:     0.7466 Training Accuracy: 0.901750 Validation Accuracy: 0.814739\n",
      "Epoch  6, Batch 226 -Loss:     0.7838 Training Accuracy: 0.896577 Validation Accuracy: 0.806349\n",
      "Epoch  6, Batch 227 -Loss:     0.9006 Training Accuracy: 0.902095 Validation Accuracy: 0.813832\n",
      "Epoch  6, Batch 228 -Loss:     0.8246 Training Accuracy: 0.906463 Validation Accuracy: 0.825170\n",
      "Epoch  6, Batch 229 -Loss:     0.8472 Training Accuracy: 0.902641 Validation Accuracy: 0.826077\n",
      "Epoch  6, Batch 230 -Loss:     1.0039 Training Accuracy: 0.900658 Validation Accuracy: 0.822676\n",
      "Epoch  6, Batch 231 -Loss:     0.7574 Training Accuracy: 0.897095 Validation Accuracy: 0.816100\n",
      "Epoch  6, Batch 232 -Loss:     0.8583 Training Accuracy: 0.896750 Validation Accuracy: 0.815193\n",
      "Epoch  6, Batch 233 -Loss:     0.8874 Training Accuracy: 0.893618 Validation Accuracy: 0.813605\n",
      "Epoch  6, Batch 234 -Loss:     0.8786 Training Accuracy: 0.880600 Validation Accuracy: 0.796372\n",
      "Epoch  6, Batch 235 -Loss:     0.8032 Training Accuracy: 0.890830 Validation Accuracy: 0.803628\n",
      "Epoch  6, Batch 236 -Loss:     0.9135 Training Accuracy: 0.904049 Validation Accuracy: 0.819728\n",
      "Epoch  6, Batch 237 -Loss:     0.9214 Training Accuracy: 0.883158 Validation Accuracy: 0.809297\n",
      "Epoch  6, Batch 238 -Loss:     0.8930 Training Accuracy: 0.846317 Validation Accuracy: 0.782313\n",
      "Epoch  6, Batch 239 -Loss:     0.7666 Training Accuracy: 0.852927 Validation Accuracy: 0.792971\n",
      "Epoch  6, Batch 240 -Loss:     0.8399 Training Accuracy: 0.878157 Validation Accuracy: 0.819955\n",
      "Epoch  6, Batch 241 -Loss:     0.8483 Training Accuracy: 0.877669 Validation Accuracy: 0.813605\n",
      "Epoch  6, Batch 242 -Loss:     0.9751 Training Accuracy: 0.871261 Validation Accuracy: 0.801587\n",
      "Epoch  6, Batch 243 -Loss:     0.7768 Training Accuracy: 0.874910 Validation Accuracy: 0.802494\n",
      "Epoch  6, Batch 244 -Loss:     0.7772 Training Accuracy: 0.888301 Validation Accuracy: 0.806576\n",
      "Epoch  6, Batch 245 -Loss:     0.7306 Training Accuracy: 0.898647 Validation Accuracy: 0.821088\n",
      "Epoch  6, Batch 246 -Loss:     0.7526 Training Accuracy: 0.876749 Validation Accuracy: 0.797279\n",
      "Epoch  6, Batch 247 -Loss:     0.8872 Training Accuracy: 0.878502 Validation Accuracy: 0.801361\n",
      "Epoch  6, Batch 248 -Loss:     0.8378 Training Accuracy: 0.889221 Validation Accuracy: 0.815873\n",
      "Epoch  6, Batch 249 -Loss:     0.9584 Training Accuracy: 0.897813 Validation Accuracy: 0.833333\n",
      "Epoch  6, Batch 250 -Loss:     0.8303 Training Accuracy: 0.899997 Validation Accuracy: 0.836961\n",
      "Epoch  6, Batch 251 -Loss:     0.8007 Training Accuracy: 0.896233 Validation Accuracy: 0.825850\n",
      "Epoch  6, Batch 252 -Loss:     0.8872 Training Accuracy: 0.883933 Validation Accuracy: 0.808617\n",
      "Epoch  6, Batch 253 -Loss:     0.9107 Training Accuracy: 0.878790 Validation Accuracy: 0.796372\n",
      "Epoch  6, Batch 254 -Loss:     0.7251 Training Accuracy: 0.878502 Validation Accuracy: 0.795465\n",
      "Epoch  6, Batch 255 -Loss:     0.9579 Training Accuracy: 0.889221 Validation Accuracy: 0.807256\n",
      "Epoch  6, Batch 256 -Loss:     0.9821 Training Accuracy: 0.877784 Validation Accuracy: 0.796825\n",
      "Epoch  6, Batch 257 -Loss:     0.8834 Training Accuracy: 0.868128 Validation Accuracy: 0.793651\n",
      "Epoch  6, Batch 258 -Loss:     1.0096 Training Accuracy: 0.877353 Validation Accuracy: 0.810204\n",
      "Epoch  6, Batch 259 -Loss:     0.8359 Training Accuracy: 0.888158 Validation Accuracy: 0.813832\n",
      "Epoch  6, Batch 260 -Loss:     0.8065 Training Accuracy: 0.883502 Validation Accuracy: 0.811338\n",
      "Epoch  6, Batch 261 -Loss:     0.8168 Training Accuracy: 0.863214 Validation Accuracy: 0.774603\n",
      "Epoch  6, Batch 262 -Loss:     0.8241 Training Accuracy: 0.851950 Validation Accuracy: 0.757370\n",
      "Epoch  6, Batch 263 -Loss:     0.8994 Training Accuracy: 0.877554 Validation Accuracy: 0.786168\n",
      "Epoch  6, Batch 264 -Loss:     0.8395 Training Accuracy: 0.888732 Validation Accuracy: 0.795692\n",
      "Epoch  6, Batch 265 -Loss:     0.9001 Training Accuracy: 0.870197 Validation Accuracy: 0.789116\n",
      "Epoch  6, Batch 266 -Loss:     0.7792 Training Accuracy: 0.854134 Validation Accuracy: 0.775283\n",
      "Epoch  6, Batch 267 -Loss:     0.9083 Training Accuracy: 0.865082 Validation Accuracy: 0.785488\n",
      "Epoch  6, Batch 268 -Loss:     0.8855 Training Accuracy: 0.894566 Validation Accuracy: 0.820181\n",
      "Epoch  6, Batch 269 -Loss:     0.9023 Training Accuracy: 0.903704 Validation Accuracy: 0.828118\n",
      "Epoch  6, Batch 270 -Loss:     0.9153 Training Accuracy: 0.878042 Validation Accuracy: 0.804762\n",
      "Epoch  6, Batch 271 -Loss:     0.9826 Training Accuracy: 0.843645 Validation Accuracy: 0.768481\n",
      "Epoch  6, Batch 272 -Loss:     0.8574 Training Accuracy: 0.851116 Validation Accuracy: 0.782766\n",
      "Epoch  7, Batch   1 -Loss:     0.8661 Training Accuracy: 0.883244 Validation Accuracy: 0.815419\n",
      "Epoch  7, Batch   2 -Loss:     0.7008 Training Accuracy: 0.886491 Validation Accuracy: 0.812698\n",
      "Epoch  7, Batch   3 -Loss:     0.9446 Training Accuracy: 0.879106 Validation Accuracy: 0.801587\n",
      "Epoch  7, Batch   4 -Loss:     0.7995 Training Accuracy: 0.880169 Validation Accuracy: 0.803401\n",
      "Epoch  7, Batch   5 -Loss:     0.8806 Training Accuracy: 0.881376 Validation Accuracy: 0.800680\n",
      "Epoch  7, Batch   6 -Loss:     0.7768 Training Accuracy: 0.883819 Validation Accuracy: 0.797959\n",
      "Epoch  7, Batch   7 -Loss:     0.6734 Training Accuracy: 0.879824 Validation Accuracy: 0.792971\n",
      "Epoch  7, Batch   8 -Loss:     0.7849 Training Accuracy: 0.874767 Validation Accuracy: 0.791837\n",
      "Epoch  7, Batch   9 -Loss:     0.8806 Training Accuracy: 0.891405 Validation Accuracy: 0.806576\n",
      "Epoch  7, Batch  10 -Loss:     0.8343 Training Accuracy: 0.908532 Validation Accuracy: 0.827438\n",
      "Epoch  7, Batch  11 -Loss:     0.7951 Training Accuracy: 0.909739 Validation Accuracy: 0.836961\n",
      "Epoch  7, Batch  12 -Loss:     0.7912 Training Accuracy: 0.901549 Validation Accuracy: 0.836508\n",
      "Epoch  7, Batch  13 -Loss:     0.9794 Training Accuracy: 0.889595 Validation Accuracy: 0.826984\n",
      "Epoch  7, Batch  14 -Loss:     0.9545 Training Accuracy: 0.891175 Validation Accuracy: 0.830386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7, Batch  15 -Loss:     0.8037 Training Accuracy: 0.901865 Validation Accuracy: 0.834921\n",
      "Epoch  7, Batch  16 -Loss:     0.7835 Training Accuracy: 0.908790 Validation Accuracy: 0.833333\n",
      "Epoch  7, Batch  17 -Loss:     0.8741 Training Accuracy: 0.906348 Validation Accuracy: 0.820635\n",
      "Epoch  7, Batch  18 -Loss:     0.8968 Training Accuracy: 0.893962 Validation Accuracy: 0.810884\n",
      "Epoch  7, Batch  19 -Loss:     0.9165 Training Accuracy: 0.890112 Validation Accuracy: 0.807710\n",
      "Epoch  7, Batch  20 -Loss:     0.8759 Training Accuracy: 0.898302 Validation Accuracy: 0.818594\n",
      "Epoch  7, Batch  21 -Loss:     0.7966 Training Accuracy: 0.894767 Validation Accuracy: 0.810431\n",
      "Epoch  7, Batch  22 -Loss:     0.8246 Training Accuracy: 0.887353 Validation Accuracy: 0.805896\n",
      "Epoch  7, Batch  23 -Loss:     0.8416 Training Accuracy: 0.902124 Validation Accuracy: 0.821542\n",
      "Epoch  7, Batch  24 -Loss:     0.8789 Training Accuracy: 0.908388 Validation Accuracy: 0.834921\n",
      "Epoch  7, Batch  25 -Loss:     0.8662 Training Accuracy: 0.911377 Validation Accuracy: 0.836054\n",
      "Epoch  7, Batch  26 -Loss:     0.8675 Training Accuracy: 0.906894 Validation Accuracy: 0.828118\n",
      "Epoch  7, Batch  27 -Loss:     0.7938 Training Accuracy: 0.903589 Validation Accuracy: 0.819955\n",
      "Epoch  7, Batch  28 -Loss:     0.8233 Training Accuracy: 0.900601 Validation Accuracy: 0.818594\n",
      "Epoch  7, Batch  29 -Loss:     0.7788 Training Accuracy: 0.898330 Validation Accuracy: 0.807936\n",
      "Epoch  7, Batch  30 -Loss:     0.7063 Training Accuracy: 0.896980 Validation Accuracy: 0.803175\n",
      "Epoch  7, Batch  31 -Loss:     0.8193 Training Accuracy: 0.896635 Validation Accuracy: 0.804082\n",
      "Epoch  7, Batch  32 -Loss:     0.7776 Training Accuracy: 0.899940 Validation Accuracy: 0.810884\n",
      "Epoch  7, Batch  33 -Loss:     0.8346 Training Accuracy: 0.902009 Validation Accuracy: 0.818141\n",
      "Epoch  7, Batch  34 -Loss:     0.6572 Training Accuracy: 0.900284 Validation Accuracy: 0.817460\n",
      "Epoch  7, Batch  35 -Loss:     0.8235 Training Accuracy: 0.896118 Validation Accuracy: 0.813605\n",
      "Epoch  7, Batch  36 -Loss:     0.7287 Training Accuracy: 0.894451 Validation Accuracy: 0.814739\n",
      "Epoch  7, Batch  37 -Loss:     0.8158 Training Accuracy: 0.891922 Validation Accuracy: 0.815419\n",
      "Epoch  7, Batch  38 -Loss:     0.7599 Training Accuracy: 0.888704 Validation Accuracy: 0.818594\n",
      "Epoch  7, Batch  39 -Loss:     0.8104 Training Accuracy: 0.888445 Validation Accuracy: 0.821542\n",
      "Epoch  7, Batch  40 -Loss:     0.9443 Training Accuracy: 0.901836 Validation Accuracy: 0.826984\n",
      "Epoch  7, Batch  41 -Loss:     0.7377 Training Accuracy: 0.908733 Validation Accuracy: 0.835147\n",
      "Epoch  7, Batch  42 -Loss:     0.7675 Training Accuracy: 0.902612 Validation Accuracy: 0.831973\n",
      "Epoch  7, Batch  43 -Loss:     0.8182 Training Accuracy: 0.893129 Validation Accuracy: 0.827438\n",
      "Epoch  7, Batch  44 -Loss:     0.7987 Training Accuracy: 0.891146 Validation Accuracy: 0.828571\n",
      "Epoch  7, Batch  45 -Loss:     0.7618 Training Accuracy: 0.894997 Validation Accuracy: 0.828118\n",
      "Epoch  7, Batch  46 -Loss:     0.8420 Training Accuracy: 0.899681 Validation Accuracy: 0.830386\n",
      "Epoch  7, Batch  47 -Loss:     0.8313 Training Accuracy: 0.897928 Validation Accuracy: 0.824717\n",
      "Epoch  7, Batch  48 -Loss:     0.7372 Training Accuracy: 0.894422 Validation Accuracy: 0.818594\n",
      "Epoch  7, Batch  49 -Loss:     0.8036 Training Accuracy: 0.896951 Validation Accuracy: 0.817460\n",
      "Epoch  7, Batch  50 -Loss:     0.8748 Training Accuracy: 0.901951 Validation Accuracy: 0.819501\n",
      "Epoch  7, Batch  51 -Loss:     0.7388 Training Accuracy: 0.903905 Validation Accuracy: 0.822222\n",
      "Epoch  7, Batch  52 -Loss:     0.7773 Training Accuracy: 0.895715 Validation Accuracy: 0.813605\n",
      "Epoch  7, Batch  53 -Loss:     0.8176 Training Accuracy: 0.884192 Validation Accuracy: 0.793424\n",
      "Epoch  7, Batch  54 -Loss:     0.8368 Training Accuracy: 0.890198 Validation Accuracy: 0.797959\n",
      "Epoch  7, Batch  55 -Loss:     0.9584 Training Accuracy: 0.893244 Validation Accuracy: 0.813152\n",
      "Epoch  7, Batch  56 -Loss:     0.8265 Training Accuracy: 0.886606 Validation Accuracy: 0.813379\n",
      "Epoch  7, Batch  57 -Loss:     0.8098 Training Accuracy: 0.892181 Validation Accuracy: 0.824717\n",
      "Epoch  7, Batch  58 -Loss:     0.8269 Training Accuracy: 0.903819 Validation Accuracy: 0.840136\n",
      "Epoch  7, Batch  59 -Loss:     0.6818 Training Accuracy: 0.900342 Validation Accuracy: 0.832426\n",
      "Epoch  7, Batch  60 -Loss:     0.7945 Training Accuracy: 0.891779 Validation Accuracy: 0.827211\n",
      "Epoch  7, Batch  61 -Loss:     0.9119 Training Accuracy: 0.891549 Validation Accuracy: 0.831519\n",
      "Epoch  7, Batch  62 -Loss:     0.8994 Training Accuracy: 0.887152 Validation Accuracy: 0.823810\n",
      "Epoch  7, Batch  63 -Loss:     0.8353 Training Accuracy: 0.891692 Validation Accuracy: 0.828571\n",
      "Epoch  7, Batch  64 -Loss:     0.7000 Training Accuracy: 0.890830 Validation Accuracy: 0.832426\n",
      "Epoch  7, Batch  65 -Loss:     0.8095 Training Accuracy: 0.895026 Validation Accuracy: 0.832426\n",
      "Epoch  7, Batch  66 -Loss:     0.8447 Training Accuracy: 0.887066 Validation Accuracy: 0.825170\n",
      "Epoch  7, Batch  67 -Loss:     0.8139 Training Accuracy: 0.884882 Validation Accuracy: 0.820408\n",
      "Epoch  7, Batch  68 -Loss:     0.9797 Training Accuracy: 0.900141 Validation Accuracy: 0.834921\n",
      "Epoch  7, Batch  69 -Loss:     0.8536 Training Accuracy: 0.909451 Validation Accuracy: 0.837415\n",
      "Epoch  7, Batch  70 -Loss:     0.8133 Training Accuracy: 0.897411 Validation Accuracy: 0.825850\n",
      "Epoch  7, Batch  71 -Loss:     0.9492 Training Accuracy: 0.890572 Validation Accuracy: 0.818367\n",
      "Epoch  7, Batch  72 -Loss:     0.7843 Training Accuracy: 0.898417 Validation Accuracy: 0.825624\n",
      "Epoch  7, Batch  73 -Loss:     0.7051 Training Accuracy: 0.904767 Validation Accuracy: 0.829478\n",
      "Epoch  7, Batch  74 -Loss:     0.7848 Training Accuracy: 0.904394 Validation Accuracy: 0.832880\n",
      "Epoch  7, Batch  75 -Loss:     0.8991 Training Accuracy: 0.906463 Validation Accuracy: 0.836735\n",
      "Epoch  7, Batch  76 -Loss:     0.8073 Training Accuracy: 0.902296 Validation Accuracy: 0.827664\n",
      "Epoch  7, Batch  77 -Loss:     0.6315 Training Accuracy: 0.876491 Validation Accuracy: 0.804989\n",
      "Epoch  7, Batch  78 -Loss:     0.8352 Training Accuracy: 0.878445 Validation Accuracy: 0.800454\n",
      "Epoch  7, Batch  79 -Loss:     0.8895 Training Accuracy: 0.900859 Validation Accuracy: 0.826304\n",
      "Epoch  7, Batch  80 -Loss:     0.7326 Training Accuracy: 0.906549 Validation Accuracy: 0.834240\n",
      "Epoch  7, Batch  81 -Loss:     0.9182 Training Accuracy: 0.906693 Validation Accuracy: 0.832426\n",
      "Epoch  7, Batch  82 -Loss:     0.9494 Training Accuracy: 0.903014 Validation Accuracy: 0.824036\n",
      "Epoch  7, Batch  83 -Loss:     0.8937 Training Accuracy: 0.904250 Validation Accuracy: 0.822676\n",
      "Epoch  7, Batch  84 -Loss:     0.8049 Training Accuracy: 0.907670 Validation Accuracy: 0.824943\n",
      "Epoch  7, Batch  85 -Loss:     0.7640 Training Accuracy: 0.904652 Validation Accuracy: 0.824036\n",
      "Epoch  7, Batch  86 -Loss:     0.6995 Training Accuracy: 0.899336 Validation Accuracy: 0.815646\n",
      "Epoch  7, Batch  87 -Loss:     0.7731 Training Accuracy: 0.897698 Validation Accuracy: 0.812245\n",
      "Epoch  7, Batch  88 -Loss:     0.7291 Training Accuracy: 0.904537 Validation Accuracy: 0.818367\n",
      "Epoch  7, Batch  89 -Loss:     0.8003 Training Accuracy: 0.902900 Validation Accuracy: 0.822449\n",
      "Epoch  7, Batch  90 -Loss:     0.9067 Training Accuracy: 0.902267 Validation Accuracy: 0.824717\n",
      "Epoch  7, Batch  91 -Loss:     0.7430 Training Accuracy: 0.906032 Validation Accuracy: 0.828571\n",
      "Epoch  7, Batch  92 -Loss:     0.7690 Training Accuracy: 0.905198 Validation Accuracy: 0.829705\n",
      "Epoch  7, Batch  93 -Loss:     0.7164 Training Accuracy: 0.902382 Validation Accuracy: 0.826304\n",
      "Epoch  7, Batch  94 -Loss:     0.8087 Training Accuracy: 0.897555 Validation Accuracy: 0.823129\n",
      "Epoch  7, Batch  95 -Loss:     0.8583 Training Accuracy: 0.894825 Validation Accuracy: 0.817914\n",
      "Epoch  7, Batch  96 -Loss:     0.7675 Training Accuracy: 0.895543 Validation Accuracy: 0.817234\n",
      "Epoch  7, Batch  97 -Loss:     0.7971 Training Accuracy: 0.898014 Validation Accuracy: 0.828118\n",
      "Epoch  7, Batch  98 -Loss:     0.7038 Training Accuracy: 0.898876 Validation Accuracy: 0.828798\n",
      "Epoch  7, Batch  99 -Loss:     0.8332 Training Accuracy: 0.904854 Validation Accuracy: 0.830612\n",
      "Epoch  7, Batch 100 -Loss:     0.8450 Training Accuracy: 0.907469 Validation Accuracy: 0.825397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7, Batch 101 -Loss:     0.6938 Training Accuracy: 0.905026 Validation Accuracy: 0.819048\n",
      "Epoch  7, Batch 102 -Loss:     0.7720 Training Accuracy: 0.906377 Validation Accuracy: 0.817460\n",
      "Epoch  7, Batch 103 -Loss:     0.8462 Training Accuracy: 0.904825 Validation Accuracy: 0.817914\n",
      "Epoch  7, Batch 104 -Loss:     0.7338 Training Accuracy: 0.901434 Validation Accuracy: 0.824036\n",
      "Epoch  7, Batch 105 -Loss:     0.8504 Training Accuracy: 0.903589 Validation Accuracy: 0.826984\n",
      "Epoch  7, Batch 106 -Loss:     0.7581 Training Accuracy: 0.907038 Validation Accuracy: 0.831066\n",
      "Epoch  7, Batch 107 -Loss:     0.8044 Training Accuracy: 0.895457 Validation Accuracy: 0.826304\n",
      "Epoch  7, Batch 108 -Loss:     0.8407 Training Accuracy: 0.894451 Validation Accuracy: 0.825850\n",
      "Epoch  7, Batch 109 -Loss:     0.8253 Training Accuracy: 0.904423 Validation Accuracy: 0.835828\n",
      "Epoch  7, Batch 110 -Loss:     0.6360 Training Accuracy: 0.912440 Validation Accuracy: 0.834921\n",
      "Epoch  7, Batch 111 -Loss:     0.6897 Training Accuracy: 0.904969 Validation Accuracy: 0.818594\n",
      "Epoch  7, Batch 112 -Loss:     0.8409 Training Accuracy: 0.887267 Validation Accuracy: 0.795918\n",
      "Epoch  7, Batch 113 -Loss:     0.8204 Training Accuracy: 0.891980 Validation Accuracy: 0.801814\n",
      "Epoch  7, Batch 114 -Loss:     0.7442 Training Accuracy: 0.899767 Validation Accuracy: 0.819501\n",
      "Epoch  7, Batch 115 -Loss:     0.8443 Training Accuracy: 0.902124 Validation Accuracy: 0.830386\n",
      "Epoch  7, Batch 116 -Loss:     0.7748 Training Accuracy: 0.898991 Validation Accuracy: 0.828571\n",
      "Epoch  7, Batch 117 -Loss:     0.8126 Training Accuracy: 0.888560 Validation Accuracy: 0.818821\n",
      "Epoch  7, Batch 118 -Loss:     0.7908 Training Accuracy: 0.882094 Validation Accuracy: 0.817007\n",
      "Epoch  7, Batch 119 -Loss:     0.7888 Training Accuracy: 0.877496 Validation Accuracy: 0.806122\n",
      "Epoch  7, Batch 120 -Loss:     0.8066 Training Accuracy: 0.889192 Validation Accuracy: 0.809297\n",
      "Epoch  7, Batch 121 -Loss:     0.7655 Training Accuracy: 0.896520 Validation Accuracy: 0.801361\n",
      "Epoch  7, Batch 122 -Loss:     0.6596 Training Accuracy: 0.888503 Validation Accuracy: 0.795692\n",
      "Epoch  7, Batch 123 -Loss:     0.8033 Training Accuracy: 0.878301 Validation Accuracy: 0.794331\n",
      "Epoch  7, Batch 124 -Loss:     1.0248 Training Accuracy: 0.883014 Validation Accuracy: 0.804535\n",
      "Epoch  7, Batch 125 -Loss:     0.7811 Training Accuracy: 0.879336 Validation Accuracy: 0.803855\n",
      "Epoch  7, Batch 126 -Loss:     0.8039 Training Accuracy: 0.887698 Validation Accuracy: 0.807710\n",
      "Epoch  7, Batch 127 -Loss:     0.8152 Training Accuracy: 0.910745 Validation Accuracy: 0.821995\n",
      "Epoch  7, Batch 128 -Loss:     0.7136 Training Accuracy: 0.904078 Validation Accuracy: 0.816100\n",
      "Epoch  7, Batch 129 -Loss:     0.7825 Training Accuracy: 0.880198 Validation Accuracy: 0.801587\n",
      "Epoch  7, Batch 130 -Loss:     0.8676 Training Accuracy: 0.878703 Validation Accuracy: 0.800000\n",
      "Epoch  7, Batch 131 -Loss:     0.8078 Training Accuracy: 0.892152 Validation Accuracy: 0.808390\n",
      "Epoch  7, Batch 132 -Loss:     0.7375 Training Accuracy: 0.898359 Validation Accuracy: 0.819048\n",
      "Epoch  7, Batch 133 -Loss:     0.7219 Training Accuracy: 0.891204 Validation Accuracy: 0.815646\n",
      "Epoch  7, Batch 134 -Loss:     0.8101 Training Accuracy: 0.888618 Validation Accuracy: 0.814966\n",
      "Epoch  7, Batch 135 -Loss:     0.7146 Training Accuracy: 0.887267 Validation Accuracy: 0.815193\n",
      "Epoch  7, Batch 136 -Loss:     0.7512 Training Accuracy: 0.896146 Validation Accuracy: 0.818141\n",
      "Epoch  7, Batch 137 -Loss:     0.7821 Training Accuracy: 0.902440 Validation Accuracy: 0.824036\n",
      "Epoch  7, Batch 138 -Loss:     0.8167 Training Accuracy: 0.903819 Validation Accuracy: 0.812925\n",
      "Epoch  7, Batch 139 -Loss:     0.7541 Training Accuracy: 0.896089 Validation Accuracy: 0.798186\n",
      "Epoch  7, Batch 140 -Loss:     0.7588 Training Accuracy: 0.895256 Validation Accuracy: 0.798186\n",
      "Epoch  7, Batch 141 -Loss:     0.8217 Training Accuracy: 0.896491 Validation Accuracy: 0.800680\n",
      "Epoch  7, Batch 142 -Loss:     0.7596 Training Accuracy: 0.892842 Validation Accuracy: 0.806803\n",
      "Epoch  7, Batch 143 -Loss:     0.7708 Training Accuracy: 0.892181 Validation Accuracy: 0.804082\n",
      "Epoch  7, Batch 144 -Loss:     0.7929 Training Accuracy: 0.894451 Validation Accuracy: 0.809524\n",
      "Epoch  7, Batch 145 -Loss:     0.7716 Training Accuracy: 0.907670 Validation Accuracy: 0.823583\n",
      "Epoch  7, Batch 146 -Loss:     0.7688 Training Accuracy: 0.908244 Validation Accuracy: 0.823583\n",
      "Epoch  7, Batch 147 -Loss:     0.8048 Training Accuracy: 0.900026 Validation Accuracy: 0.821542\n",
      "Epoch  7, Batch 148 -Loss:     0.7353 Training Accuracy: 0.882410 Validation Accuracy: 0.812925\n",
      "Epoch  7, Batch 149 -Loss:     0.8259 Training Accuracy: 0.881290 Validation Accuracy: 0.810884\n",
      "Epoch  7, Batch 150 -Loss:     0.8091 Training Accuracy: 0.895543 Validation Accuracy: 0.823583\n",
      "Epoch  7, Batch 151 -Loss:     0.7588 Training Accuracy: 0.907986 Validation Accuracy: 0.835601\n",
      "Epoch  7, Batch 152 -Loss:     0.7208 Training Accuracy: 0.900371 Validation Accuracy: 0.819048\n",
      "Epoch  7, Batch 153 -Loss:     0.8785 Training Accuracy: 0.891577 Validation Accuracy: 0.804762\n",
      "Epoch  7, Batch 154 -Loss:     0.8534 Training Accuracy: 0.895744 Validation Accuracy: 0.808163\n",
      "Epoch  7, Batch 155 -Loss:     0.7949 Training Accuracy: 0.898445 Validation Accuracy: 0.810431\n",
      "Epoch  7, Batch 156 -Loss:     0.8539 Training Accuracy: 0.901175 Validation Accuracy: 0.815646\n",
      "Epoch  7, Batch 157 -Loss:     0.6936 Training Accuracy: 0.889939 Validation Accuracy: 0.805442\n",
      "Epoch  7, Batch 158 -Loss:     0.7137 Training Accuracy: 0.874163 Validation Accuracy: 0.790476\n",
      "Epoch  7, Batch 159 -Loss:     0.8003 Training Accuracy: 0.885773 Validation Accuracy: 0.795238\n",
      "Epoch  7, Batch 160 -Loss:     0.7106 Training Accuracy: 0.900342 Validation Accuracy: 0.805896\n",
      "Epoch  7, Batch 161 -Loss:     0.7304 Training Accuracy: 0.909854 Validation Accuracy: 0.814739\n",
      "Epoch  7, Batch 162 -Loss:     0.6705 Training Accuracy: 0.906233 Validation Accuracy: 0.821542\n",
      "Epoch  7, Batch 163 -Loss:     0.8632 Training Accuracy: 0.901319 Validation Accuracy: 0.820635\n",
      "Epoch  7, Batch 164 -Loss:     0.7182 Training Accuracy: 0.908934 Validation Accuracy: 0.833560\n",
      "Epoch  7, Batch 165 -Loss:     0.7980 Training Accuracy: 0.913762 Validation Accuracy: 0.837642\n",
      "Epoch  7, Batch 166 -Loss:     0.7085 Training Accuracy: 0.911635 Validation Accuracy: 0.832880\n",
      "Epoch  7, Batch 167 -Loss:     0.7482 Training Accuracy: 0.910084 Validation Accuracy: 0.831746\n",
      "Epoch  7, Batch 168 -Loss:     0.6559 Training Accuracy: 0.907756 Validation Accuracy: 0.831746\n",
      "Epoch  7, Batch 169 -Loss:     0.7711 Training Accuracy: 0.906664 Validation Accuracy: 0.830612\n",
      "Epoch  7, Batch 170 -Loss:     0.7744 Training Accuracy: 0.906290 Validation Accuracy: 0.827891\n",
      "Epoch  7, Batch 171 -Loss:     0.8214 Training Accuracy: 0.908474 Validation Accuracy: 0.827891\n",
      "Epoch  7, Batch 172 -Loss:     0.7393 Training Accuracy: 0.910486 Validation Accuracy: 0.826531\n",
      "Epoch  7, Batch 173 -Loss:     0.7356 Training Accuracy: 0.908417 Validation Accuracy: 0.826077\n",
      "Epoch  7, Batch 174 -Loss:     0.7472 Training Accuracy: 0.908848 Validation Accuracy: 0.826304\n",
      "Epoch  7, Batch 175 -Loss:     0.9238 Training Accuracy: 0.913101 Validation Accuracy: 0.829705\n",
      "Epoch  7, Batch 176 -Loss:     0.7427 Training Accuracy: 0.914940 Validation Accuracy: 0.828345\n",
      "Epoch  7, Batch 177 -Loss:     0.8245 Training Accuracy: 0.915314 Validation Accuracy: 0.823810\n",
      "Epoch  7, Batch 178 -Loss:     0.8107 Training Accuracy: 0.914423 Validation Accuracy: 0.819048\n",
      "Epoch  7, Batch 179 -Loss:     0.8224 Training Accuracy: 0.912699 Validation Accuracy: 0.814966\n",
      "Epoch  7, Batch 180 -Loss:     0.7784 Training Accuracy: 0.914681 Validation Accuracy: 0.821769\n",
      "Epoch  7, Batch 181 -Loss:     0.7742 Training Accuracy: 0.908446 Validation Accuracy: 0.827891\n",
      "Epoch  7, Batch 182 -Loss:     0.7488 Training Accuracy: 0.902382 Validation Accuracy: 0.821088\n",
      "Epoch  7, Batch 183 -Loss:     0.7882 Training Accuracy: 0.894307 Validation Accuracy: 0.811791\n",
      "Epoch  7, Batch 184 -Loss:     0.7761 Training Accuracy: 0.901262 Validation Accuracy: 0.818141\n",
      "Epoch  7, Batch 185 -Loss:     0.7493 Training Accuracy: 0.913273 Validation Accuracy: 0.830159\n",
      "Epoch  7, Batch 186 -Loss:     0.8479 Training Accuracy: 0.917296 Validation Accuracy: 0.836281\n",
      "Epoch  7, Batch 187 -Loss:     0.7270 Training Accuracy: 0.918848 Validation Accuracy: 0.837415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7, Batch 188 -Loss:     0.9201 Training Accuracy: 0.917469 Validation Accuracy: 0.843311\n",
      "Epoch  7, Batch 189 -Loss:     0.7703 Training Accuracy: 0.912756 Validation Accuracy: 0.849206\n",
      "Epoch  7, Batch 190 -Loss:     0.7985 Training Accuracy: 0.906549 Validation Accuracy: 0.847846\n",
      "Epoch  7, Batch 191 -Loss:     0.7458 Training Accuracy: 0.898330 Validation Accuracy: 0.839456\n",
      "Epoch  7, Batch 192 -Loss:     0.8383 Training Accuracy: 0.904652 Validation Accuracy: 0.843537\n",
      "Epoch  7, Batch 193 -Loss:     0.7518 Training Accuracy: 0.902382 Validation Accuracy: 0.837188\n",
      "Epoch  7, Batch 194 -Loss:     0.7480 Training Accuracy: 0.903877 Validation Accuracy: 0.839229\n",
      "Epoch  7, Batch 195 -Loss:     0.7138 Training Accuracy: 0.906664 Validation Accuracy: 0.842404\n",
      "Epoch  7, Batch 196 -Loss:     0.7908 Training Accuracy: 0.905198 Validation Accuracy: 0.835147\n",
      "Epoch  7, Batch 197 -Loss:     0.8090 Training Accuracy: 0.896290 Validation Accuracy: 0.819501\n",
      "Epoch  7, Batch 198 -Loss:     0.8934 Training Accuracy: 0.893962 Validation Accuracy: 0.813152\n",
      "Epoch  7, Batch 199 -Loss:     0.7525 Training Accuracy: 0.902583 Validation Accuracy: 0.816553\n",
      "Epoch  7, Batch 200 -Loss:     0.8956 Training Accuracy: 0.904250 Validation Accuracy: 0.816327\n",
      "Epoch  7, Batch 201 -Loss:     0.7750 Training Accuracy: 0.890773 Validation Accuracy: 0.808617\n",
      "Epoch  7, Batch 202 -Loss:     0.8473 Training Accuracy: 0.898934 Validation Accuracy: 0.816100\n",
      "Epoch  7, Batch 203 -Loss:     0.7772 Training Accuracy: 0.910227 Validation Accuracy: 0.832200\n",
      "Epoch  7, Batch 204 -Loss:     0.7378 Training Accuracy: 0.914279 Validation Accuracy: 0.845351\n",
      "Epoch  7, Batch 205 -Loss:     0.7877 Training Accuracy: 0.911894 Validation Accuracy: 0.844444\n",
      "Epoch  7, Batch 206 -Loss:     0.8844 Training Accuracy: 0.911319 Validation Accuracy: 0.839909\n",
      "Epoch  7, Batch 207 -Loss:     0.7331 Training Accuracy: 0.917986 Validation Accuracy: 0.837642\n",
      "Epoch  7, Batch 208 -Loss:     0.6953 Training Accuracy: 0.923274 Validation Accuracy: 0.836508\n",
      "Epoch  7, Batch 209 -Loss:     0.8732 Training Accuracy: 0.923935 Validation Accuracy: 0.832653\n",
      "Epoch  7, Batch 210 -Loss:     0.7225 Training Accuracy: 0.918676 Validation Accuracy: 0.829025\n",
      "Epoch  7, Batch 211 -Loss:     0.7653 Training Accuracy: 0.908359 Validation Accuracy: 0.814286\n",
      "Epoch  7, Batch 212 -Loss:     0.8461 Training Accuracy: 0.905198 Validation Accuracy: 0.813605\n",
      "Epoch  7, Batch 213 -Loss:     0.8336 Training Accuracy: 0.909423 Validation Accuracy: 0.819955\n",
      "Epoch  7, Batch 214 -Loss:     0.6847 Training Accuracy: 0.908130 Validation Accuracy: 0.822222\n",
      "Epoch  7, Batch 215 -Loss:     0.7027 Training Accuracy: 0.905974 Validation Accuracy: 0.821995\n",
      "Epoch  7, Batch 216 -Loss:     0.7683 Training Accuracy: 0.908446 Validation Accuracy: 0.823129\n",
      "Epoch  7, Batch 217 -Loss:     0.8157 Training Accuracy: 0.910026 Validation Accuracy: 0.820181\n",
      "Epoch  7, Batch 218 -Loss:     0.7952 Training Accuracy: 0.894049 Validation Accuracy: 0.812018\n",
      "Epoch  7, Batch 219 -Loss:     0.8208 Training Accuracy: 0.884106 Validation Accuracy: 0.806803\n",
      "Epoch  7, Batch 220 -Loss:     0.8012 Training Accuracy: 0.889853 Validation Accuracy: 0.808390\n",
      "Epoch  7, Batch 221 -Loss:     0.7197 Training Accuracy: 0.897468 Validation Accuracy: 0.818821\n",
      "Epoch  7, Batch 222 -Loss:     0.7890 Training Accuracy: 0.894853 Validation Accuracy: 0.811338\n",
      "Epoch  7, Batch 223 -Loss:     0.8706 Training Accuracy: 0.890773 Validation Accuracy: 0.805896\n",
      "Epoch  7, Batch 224 -Loss:     0.7925 Training Accuracy: 0.881318 Validation Accuracy: 0.800680\n",
      "Epoch  7, Batch 225 -Loss:     0.6681 Training Accuracy: 0.868157 Validation Accuracy: 0.780045\n",
      "Epoch  7, Batch 226 -Loss:     0.7318 Training Accuracy: 0.866663 Validation Accuracy: 0.775283\n",
      "Epoch  7, Batch 227 -Loss:     0.8378 Training Accuracy: 0.884221 Validation Accuracy: 0.793197\n",
      "Epoch  7, Batch 228 -Loss:     0.8619 Training Accuracy: 0.899681 Validation Accuracy: 0.807483\n",
      "Epoch  7, Batch 229 -Loss:     0.7601 Training Accuracy: 0.904308 Validation Accuracy: 0.823810\n",
      "Epoch  7, Batch 230 -Loss:     0.8064 Training Accuracy: 0.896376 Validation Accuracy: 0.817687\n",
      "Epoch  7, Batch 231 -Loss:     0.8327 Training Accuracy: 0.898072 Validation Accuracy: 0.817007\n",
      "Epoch  7, Batch 232 -Loss:     0.7632 Training Accuracy: 0.900572 Validation Accuracy: 0.821088\n",
      "Epoch  7, Batch 233 -Loss:     0.8614 Training Accuracy: 0.891549 Validation Accuracy: 0.807936\n",
      "Epoch  7, Batch 234 -Loss:     0.7391 Training Accuracy: 0.870226 Validation Accuracy: 0.785941\n",
      "Epoch  7, Batch 235 -Loss:     0.8989 Training Accuracy: 0.883905 Validation Accuracy: 0.796825\n",
      "Epoch  7, Batch 236 -Loss:     0.8878 Training Accuracy: 0.914710 Validation Accuracy: 0.840136\n",
      "Epoch  7, Batch 237 -Loss:     0.8161 Training Accuracy: 0.913130 Validation Accuracy: 0.839683\n",
      "Epoch  7, Batch 238 -Loss:     0.7402 Training Accuracy: 0.884336 Validation Accuracy: 0.811791\n",
      "Epoch  7, Batch 239 -Loss:     0.9173 Training Accuracy: 0.878962 Validation Accuracy: 0.809977\n",
      "Epoch  7, Batch 240 -Loss:     0.8251 Training Accuracy: 0.892526 Validation Accuracy: 0.819501\n",
      "Epoch  7, Batch 241 -Loss:     0.7073 Training Accuracy: 0.908244 Validation Accuracy: 0.830386\n",
      "Epoch  7, Batch 242 -Loss:     0.7407 Training Accuracy: 0.902181 Validation Accuracy: 0.811111\n",
      "Epoch  7, Batch 243 -Loss:     0.7690 Training Accuracy: 0.889595 Validation Accuracy: 0.794331\n",
      "Epoch  7, Batch 244 -Loss:     0.7487 Training Accuracy: 0.898503 Validation Accuracy: 0.806576\n",
      "Epoch  7, Batch 245 -Loss:     0.7948 Training Accuracy: 0.911808 Validation Accuracy: 0.827211\n",
      "Epoch  7, Batch 246 -Loss:     0.7143 Training Accuracy: 0.906377 Validation Accuracy: 0.817914\n",
      "Epoch  7, Batch 247 -Loss:     0.8765 Training Accuracy: 0.898388 Validation Accuracy: 0.814739\n",
      "Epoch  7, Batch 248 -Loss:     0.7425 Training Accuracy: 0.906520 Validation Accuracy: 0.825850\n",
      "Epoch  7, Batch 249 -Loss:     0.7419 Training Accuracy: 0.908848 Validation Accuracy: 0.832653\n",
      "Epoch  7, Batch 250 -Loss:     0.7471 Training Accuracy: 0.907354 Validation Accuracy: 0.830159\n",
      "Epoch  7, Batch 251 -Loss:     0.8035 Training Accuracy: 0.904135 Validation Accuracy: 0.827664\n",
      "Epoch  7, Batch 252 -Loss:     0.6591 Training Accuracy: 0.897698 Validation Accuracy: 0.815419\n",
      "Epoch  7, Batch 253 -Loss:     0.7437 Training Accuracy: 0.898790 Validation Accuracy: 0.817914\n",
      "Epoch  7, Batch 254 -Loss:     0.7154 Training Accuracy: 0.904509 Validation Accuracy: 0.821542\n",
      "Epoch  7, Batch 255 -Loss:     0.7223 Training Accuracy: 0.907038 Validation Accuracy: 0.826984\n",
      "Epoch  7, Batch 256 -Loss:     0.8190 Training Accuracy: 0.905083 Validation Accuracy: 0.830386\n",
      "Epoch  7, Batch 257 -Loss:     0.7422 Training Accuracy: 0.914969 Validation Accuracy: 0.843311\n",
      "Epoch  7, Batch 258 -Loss:     0.6873 Training Accuracy: 0.916319 Validation Accuracy: 0.844444\n",
      "Epoch  7, Batch 259 -Loss:     0.8043 Training Accuracy: 0.909739 Validation Accuracy: 0.837415\n",
      "Epoch  7, Batch 260 -Loss:     0.8118 Training Accuracy: 0.905831 Validation Accuracy: 0.836735\n",
      "Epoch  7, Batch 261 -Loss:     0.7449 Training Accuracy: 0.906606 Validation Accuracy: 0.838322\n",
      "Epoch  7, Batch 262 -Loss:     0.7530 Training Accuracy: 0.914768 Validation Accuracy: 0.839456\n",
      "Epoch  7, Batch 263 -Loss:     0.7220 Training Accuracy: 0.915773 Validation Accuracy: 0.837868\n",
      "Epoch  7, Batch 264 -Loss:     0.7157 Training Accuracy: 0.914193 Validation Accuracy: 0.831293\n",
      "Epoch  7, Batch 265 -Loss:     0.7331 Training Accuracy: 0.910026 Validation Accuracy: 0.827211\n",
      "Epoch  7, Batch 266 -Loss:     0.7219 Training Accuracy: 0.905744 Validation Accuracy: 0.821995\n",
      "Epoch  7, Batch 267 -Loss:     0.7338 Training Accuracy: 0.889221 Validation Accuracy: 0.806803\n",
      "Epoch  7, Batch 268 -Loss:     0.9160 Training Accuracy: 0.871634 Validation Accuracy: 0.789796\n",
      "Epoch  7, Batch 269 -Loss:     0.8161 Training Accuracy: 0.883416 Validation Accuracy: 0.806122\n",
      "Epoch  7, Batch 270 -Loss:     0.7675 Training Accuracy: 0.912641 Validation Accuracy: 0.831066\n",
      "Epoch  7, Batch 271 -Loss:     0.7476 Training Accuracy: 0.921118 Validation Accuracy: 0.839909\n",
      "Epoch  7, Batch 272 -Loss:     0.7074 Training Accuracy: 0.919653 Validation Accuracy: 0.845351\n",
      "Epoch  8, Batch   1 -Loss:     0.6867 Training Accuracy: 0.911061 Validation Accuracy: 0.832653\n",
      "Epoch  8, Batch   2 -Loss:     0.7113 Training Accuracy: 0.906750 Validation Accuracy: 0.829705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8, Batch   3 -Loss:     0.8734 Training Accuracy: 0.908704 Validation Accuracy: 0.835828\n",
      "Epoch  8, Batch   4 -Loss:     0.7450 Training Accuracy: 0.904451 Validation Accuracy: 0.832426\n",
      "Epoch  8, Batch   5 -Loss:     0.7661 Training Accuracy: 0.901147 Validation Accuracy: 0.831746\n",
      "Epoch  8, Batch   6 -Loss:     0.7549 Training Accuracy: 0.898330 Validation Accuracy: 0.818141\n",
      "Epoch  8, Batch   7 -Loss:     0.7646 Training Accuracy: 0.898474 Validation Accuracy: 0.819274\n",
      "Epoch  8, Batch   8 -Loss:     0.7857 Training Accuracy: 0.904624 Validation Accuracy: 0.818141\n",
      "Epoch  8, Batch   9 -Loss:     0.6984 Training Accuracy: 0.909049 Validation Accuracy: 0.826077\n",
      "Epoch  8, Batch  10 -Loss:     0.7071 Training Accuracy: 0.904796 Validation Accuracy: 0.825850\n",
      "Epoch  8, Batch  11 -Loss:     0.8005 Training Accuracy: 0.907497 Validation Accuracy: 0.828798\n",
      "Epoch  8, Batch  12 -Loss:     0.7147 Training Accuracy: 0.917383 Validation Accuracy: 0.842177\n",
      "Epoch  8, Batch  13 -Loss:     0.6158 Training Accuracy: 0.913848 Validation Accuracy: 0.842857\n",
      "Epoch  8, Batch  14 -Loss:     0.7686 Training Accuracy: 0.907986 Validation Accuracy: 0.836281\n",
      "Epoch  8, Batch  15 -Loss:     0.7194 Training Accuracy: 0.913216 Validation Accuracy: 0.840590\n",
      "Epoch  8, Batch  16 -Loss:     0.6951 Training Accuracy: 0.912814 Validation Accuracy: 0.835601\n",
      "Epoch  8, Batch  17 -Loss:     0.7547 Training Accuracy: 0.917842 Validation Accuracy: 0.839456\n",
      "Epoch  8, Batch  18 -Loss:     0.6618 Training Accuracy: 0.912440 Validation Accuracy: 0.838095\n",
      "Epoch  8, Batch  19 -Loss:     0.7149 Training Accuracy: 0.899595 Validation Accuracy: 0.821315\n",
      "Epoch  8, Batch  20 -Loss:     0.7438 Training Accuracy: 0.907699 Validation Accuracy: 0.831066\n",
      "Epoch  8, Batch  21 -Loss:     0.6270 Training Accuracy: 0.911980 Validation Accuracy: 0.841723\n",
      "Epoch  8, Batch  22 -Loss:     0.7069 Training Accuracy: 0.908302 Validation Accuracy: 0.833107\n",
      "Epoch  8, Batch  23 -Loss:     0.7551 Training Accuracy: 0.903331 Validation Accuracy: 0.824943\n",
      "Epoch  8, Batch  24 -Loss:     0.7190 Training Accuracy: 0.902037 Validation Accuracy: 0.821542\n",
      "Epoch  8, Batch  25 -Loss:     0.8167 Training Accuracy: 0.908503 Validation Accuracy: 0.822222\n",
      "Epoch  8, Batch  26 -Loss:     0.7375 Training Accuracy: 0.909336 Validation Accuracy: 0.819274\n",
      "Epoch  8, Batch  27 -Loss:     0.6681 Training Accuracy: 0.909940 Validation Accuracy: 0.820408\n",
      "Epoch  8, Batch  28 -Loss:     0.6587 Training Accuracy: 0.910400 Validation Accuracy: 0.819728\n",
      "Epoch  8, Batch  29 -Loss:     0.6841 Training Accuracy: 0.914854 Validation Accuracy: 0.829025\n",
      "Epoch  8, Batch  30 -Loss:     0.7663 Training Accuracy: 0.914567 Validation Accuracy: 0.831746\n",
      "Epoch  8, Batch  31 -Loss:     0.8760 Training Accuracy: 0.916319 Validation Accuracy: 0.830386\n",
      "Epoch  8, Batch  32 -Loss:     0.8938 Training Accuracy: 0.913475 Validation Accuracy: 0.829252\n",
      "Epoch  8, Batch  33 -Loss:     0.6675 Training Accuracy: 0.907670 Validation Accuracy: 0.824943\n",
      "Epoch  8, Batch  34 -Loss:     0.7185 Training Accuracy: 0.907612 Validation Accuracy: 0.822676\n",
      "Epoch  8, Batch  35 -Loss:     0.8898 Training Accuracy: 0.916636 Validation Accuracy: 0.827664\n",
      "Epoch  8, Batch  36 -Loss:     0.6279 Training Accuracy: 0.916894 Validation Accuracy: 0.836735\n",
      "Epoch  8, Batch  37 -Loss:     0.7116 Training Accuracy: 0.910946 Validation Accuracy: 0.840363\n",
      "Epoch  8, Batch  38 -Loss:     0.7388 Training Accuracy: 0.906721 Validation Accuracy: 0.831293\n",
      "Epoch  8, Batch  39 -Loss:     0.8167 Training Accuracy: 0.906894 Validation Accuracy: 0.824717\n",
      "Epoch  8, Batch  40 -Loss:     0.7010 Training Accuracy: 0.909624 Validation Accuracy: 0.816327\n",
      "Epoch  8, Batch  41 -Loss:     0.6209 Training Accuracy: 0.911951 Validation Accuracy: 0.818367\n",
      "Epoch  8, Batch  42 -Loss:     0.7585 Training Accuracy: 0.915860 Validation Accuracy: 0.821315\n",
      "Epoch  8, Batch  43 -Loss:     0.7518 Training Accuracy: 0.918791 Validation Accuracy: 0.826984\n",
      "Epoch  8, Batch  44 -Loss:     0.6783 Training Accuracy: 0.921176 Validation Accuracy: 0.830839\n",
      "Epoch  8, Batch  45 -Loss:     0.7415 Training Accuracy: 0.916492 Validation Accuracy: 0.829932\n",
      "Epoch  8, Batch  46 -Loss:     0.6377 Training Accuracy: 0.910141 Validation Accuracy: 0.826304\n",
      "Epoch  8, Batch  47 -Loss:     0.7068 Training Accuracy: 0.909049 Validation Accuracy: 0.827211\n",
      "Epoch  8, Batch  48 -Loss:     0.7757 Training Accuracy: 0.912066 Validation Accuracy: 0.827664\n",
      "Epoch  8, Batch  49 -Loss:     0.6356 Training Accuracy: 0.919049 Validation Accuracy: 0.826757\n",
      "Epoch  8, Batch  50 -Loss:     0.6642 Training Accuracy: 0.914911 Validation Accuracy: 0.829932\n",
      "Epoch  8, Batch  51 -Loss:     0.6179 Training Accuracy: 0.909796 Validation Accuracy: 0.826757\n",
      "Epoch  8, Batch  52 -Loss:     0.7383 Training Accuracy: 0.915658 Validation Accuracy: 0.828118\n",
      "Epoch  8, Batch  53 -Loss:     0.7620 Training Accuracy: 0.920745 Validation Accuracy: 0.838322\n",
      "Epoch  8, Batch  54 -Loss:     0.7041 Training Accuracy: 0.914595 Validation Accuracy: 0.835828\n",
      "Epoch  8, Batch  55 -Loss:     0.6705 Training Accuracy: 0.908043 Validation Accuracy: 0.827438\n",
      "Epoch  8, Batch  56 -Loss:     0.6947 Training Accuracy: 0.907469 Validation Accuracy: 0.826304\n",
      "Epoch  8, Batch  57 -Loss:     0.6419 Training Accuracy: 0.900026 Validation Accuracy: 0.812018\n",
      "Epoch  8, Batch  58 -Loss:     0.7758 Training Accuracy: 0.899279 Validation Accuracy: 0.810204\n",
      "Epoch  8, Batch  59 -Loss:     0.8159 Training Accuracy: 0.902440 Validation Accuracy: 0.820862\n",
      "Epoch  8, Batch  60 -Loss:     0.6909 Training Accuracy: 0.910601 Validation Accuracy: 0.834467\n",
      "Epoch  8, Batch  61 -Loss:     0.7308 Training Accuracy: 0.913475 Validation Accuracy: 0.836961\n",
      "Epoch  8, Batch  62 -Loss:     0.8104 Training Accuracy: 0.911262 Validation Accuracy: 0.834694\n",
      "Epoch  8, Batch  63 -Loss:     0.7481 Training Accuracy: 0.911233 Validation Accuracy: 0.832880\n",
      "Epoch  8, Batch  64 -Loss:     0.8461 Training Accuracy: 0.908733 Validation Accuracy: 0.828798\n",
      "Epoch  8, Batch  65 -Loss:     0.7005 Training Accuracy: 0.905141 Validation Accuracy: 0.823583\n",
      "Epoch  8, Batch  66 -Loss:     0.6320 Training Accuracy: 0.904509 Validation Accuracy: 0.823810\n",
      "Epoch  8, Batch  67 -Loss:     0.7181 Training Accuracy: 0.911176 Validation Accuracy: 0.828798\n",
      "Epoch  8, Batch  68 -Loss:     0.7573 Training Accuracy: 0.913015 Validation Accuracy: 0.828345\n",
      "Epoch  8, Batch  69 -Loss:     0.7338 Training Accuracy: 0.915572 Validation Accuracy: 0.828345\n",
      "Epoch  8, Batch  70 -Loss:     0.6152 Training Accuracy: 0.914796 Validation Accuracy: 0.829478\n",
      "Epoch  8, Batch  71 -Loss:     0.6669 Training Accuracy: 0.916319 Validation Accuracy: 0.830386\n",
      "Epoch  8, Batch  72 -Loss:     0.7959 Training Accuracy: 0.921205 Validation Accuracy: 0.834694\n",
      "Epoch  8, Batch  73 -Loss:     0.7252 Training Accuracy: 0.919337 Validation Accuracy: 0.836735\n",
      "Epoch  8, Batch  74 -Loss:     0.7415 Training Accuracy: 0.911750 Validation Accuracy: 0.826077\n",
      "Epoch  8, Batch  75 -Loss:     0.8771 Training Accuracy: 0.905716 Validation Accuracy: 0.820408\n",
      "Epoch  8, Batch  76 -Loss:     0.8217 Training Accuracy: 0.908704 Validation Accuracy: 0.825170\n",
      "Epoch  8, Batch  77 -Loss:     0.6854 Training Accuracy: 0.917613 Validation Accuracy: 0.835601\n",
      "Epoch  8, Batch  78 -Loss:     0.7130 Training Accuracy: 0.922440 Validation Accuracy: 0.844218\n",
      "Epoch  8, Batch  79 -Loss:     0.9033 Training Accuracy: 0.920802 Validation Accuracy: 0.838776\n",
      "Epoch  8, Batch  80 -Loss:     0.6707 Training Accuracy: 0.916262 Validation Accuracy: 0.833107\n",
      "Epoch  8, Batch  81 -Loss:     0.8267 Training Accuracy: 0.907928 Validation Accuracy: 0.833333\n",
      "Epoch  8, Batch  82 -Loss:     0.7473 Training Accuracy: 0.903560 Validation Accuracy: 0.840363\n",
      "Epoch  8, Batch  83 -Loss:     0.6948 Training Accuracy: 0.895026 Validation Accuracy: 0.831066\n",
      "Epoch  8, Batch  84 -Loss:     0.7318 Training Accuracy: 0.899997 Validation Accuracy: 0.833333\n",
      "Epoch  8, Batch  85 -Loss:     0.8687 Training Accuracy: 0.915860 Validation Accuracy: 0.844898\n",
      "Epoch  8, Batch  86 -Loss:     0.7962 Training Accuracy: 0.925170 Validation Accuracy: 0.854422\n",
      "Epoch  8, Batch  87 -Loss:     0.6468 Training Accuracy: 0.918877 Validation Accuracy: 0.843311\n",
      "Epoch  8, Batch  88 -Loss:     0.7220 Training Accuracy: 0.913475 Validation Accuracy: 0.831746\n",
      "Epoch  8, Batch  89 -Loss:     0.7166 Training Accuracy: 0.912354 Validation Accuracy: 0.828571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8, Batch  90 -Loss:     0.7800 Training Accuracy: 0.915860 Validation Accuracy: 0.824036\n",
      "Epoch  8, Batch  91 -Loss:     0.6950 Training Accuracy: 0.910601 Validation Accuracy: 0.824036\n",
      "Epoch  8, Batch  92 -Loss:     0.7244 Training Accuracy: 0.900342 Validation Accuracy: 0.813152\n",
      "Epoch  8, Batch  93 -Loss:     0.7111 Training Accuracy: 0.907411 Validation Accuracy: 0.823129\n",
      "Epoch  8, Batch  94 -Loss:     0.6751 Training Accuracy: 0.919337 Validation Accuracy: 0.829478\n",
      "Epoch  8, Batch  95 -Loss:     0.8298 Training Accuracy: 0.914279 Validation Accuracy: 0.830839\n",
      "Epoch  8, Batch  96 -Loss:     0.6783 Training Accuracy: 0.912641 Validation Accuracy: 0.832880\n",
      "Epoch  8, Batch  97 -Loss:     0.7170 Training Accuracy: 0.912296 Validation Accuracy: 0.827891\n",
      "Epoch  8, Batch  98 -Loss:     0.6891 Training Accuracy: 0.914423 Validation Accuracy: 0.828571\n",
      "Epoch  8, Batch  99 -Loss:     0.6880 Training Accuracy: 0.913072 Validation Accuracy: 0.829705\n",
      "Epoch  8, Batch 100 -Loss:     0.7293 Training Accuracy: 0.907670 Validation Accuracy: 0.825397\n",
      "Epoch  8, Batch 101 -Loss:     0.7670 Training Accuracy: 0.905227 Validation Accuracy: 0.824490\n",
      "Epoch  8, Batch 102 -Loss:     0.8576 Training Accuracy: 0.909796 Validation Accuracy: 0.827664\n",
      "Epoch  8, Batch 103 -Loss:     0.7727 Training Accuracy: 0.909854 Validation Accuracy: 0.837188\n",
      "Epoch  8, Batch 104 -Loss:     0.8867 Training Accuracy: 0.912383 Validation Accuracy: 0.839002\n",
      "Epoch  8, Batch 105 -Loss:     0.8200 Training Accuracy: 0.910658 Validation Accuracy: 0.829025\n",
      "Epoch  8, Batch 106 -Loss:     0.7105 Training Accuracy: 0.901836 Validation Accuracy: 0.814059\n",
      "Epoch  8, Batch 107 -Loss:     0.7502 Training Accuracy: 0.898100 Validation Accuracy: 0.809751\n",
      "Epoch  8, Batch 108 -Loss:     0.6845 Training Accuracy: 0.906693 Validation Accuracy: 0.822222\n",
      "Epoch  8, Batch 109 -Loss:     0.8618 Training Accuracy: 0.916262 Validation Accuracy: 0.825850\n",
      "Epoch  8, Batch 110 -Loss:     0.6600 Training Accuracy: 0.911204 Validation Accuracy: 0.817234\n",
      "Epoch  8, Batch 111 -Loss:     0.7663 Training Accuracy: 0.890026 Validation Accuracy: 0.802494\n",
      "Epoch  8, Batch 112 -Loss:     0.6833 Training Accuracy: 0.882640 Validation Accuracy: 0.798866\n",
      "Epoch  8, Batch 113 -Loss:     0.7089 Training Accuracy: 0.905601 Validation Accuracy: 0.818367\n",
      "Epoch  8, Batch 114 -Loss:     0.7303 Training Accuracy: 0.916262 Validation Accuracy: 0.829252\n",
      "Epoch  8, Batch 115 -Loss:     0.7795 Training Accuracy: 0.905744 Validation Accuracy: 0.816327\n",
      "Epoch  8, Batch 116 -Loss:     0.7801 Training Accuracy: 0.883761 Validation Accuracy: 0.792971\n",
      "Epoch  8, Batch 117 -Loss:     0.7716 Training Accuracy: 0.884738 Validation Accuracy: 0.787755\n",
      "Epoch  8, Batch 118 -Loss:     0.7514 Training Accuracy: 0.899738 Validation Accuracy: 0.804989\n",
      "Epoch  8, Batch 119 -Loss:     0.7361 Training Accuracy: 0.902986 Validation Accuracy: 0.815419\n",
      "Epoch  8, Batch 120 -Loss:     0.7534 Training Accuracy: 0.893445 Validation Accuracy: 0.813152\n",
      "Epoch  8, Batch 121 -Loss:     0.7094 Training Accuracy: 0.881778 Validation Accuracy: 0.807029\n",
      "Epoch  8, Batch 122 -Loss:     0.8918 Training Accuracy: 0.883215 Validation Accuracy: 0.807710\n",
      "Epoch  8, Batch 123 -Loss:     0.8152 Training Accuracy: 0.892899 Validation Accuracy: 0.821769\n",
      "Epoch  8, Batch 124 -Loss:     0.7314 Training Accuracy: 0.907612 Validation Accuracy: 0.842404\n",
      "Epoch  8, Batch 125 -Loss:     0.7211 Training Accuracy: 0.917728 Validation Accuracy: 0.849660\n",
      "Epoch  8, Batch 126 -Loss:     0.7137 Training Accuracy: 0.918963 Validation Accuracy: 0.843991\n",
      "Epoch  8, Batch 127 -Loss:     0.7576 Training Accuracy: 0.914825 Validation Accuracy: 0.832880\n",
      "Epoch  8, Batch 128 -Loss:     0.7961 Training Accuracy: 0.912038 Validation Accuracy: 0.831746\n",
      "Epoch  8, Batch 129 -Loss:     0.8409 Training Accuracy: 0.916463 Validation Accuracy: 0.832426\n",
      "Epoch  8, Batch 130 -Loss:     0.6422 Training Accuracy: 0.915371 Validation Accuracy: 0.829705\n",
      "Epoch  8, Batch 131 -Loss:     0.8866 Training Accuracy: 0.906980 Validation Accuracy: 0.828571\n",
      "Epoch  8, Batch 132 -Loss:     0.7629 Training Accuracy: 0.896146 Validation Accuracy: 0.819048\n",
      "Epoch  8, Batch 133 -Loss:     0.8836 Training Accuracy: 0.898618 Validation Accuracy: 0.818367\n",
      "Epoch  8, Batch 134 -Loss:     0.7235 Training Accuracy: 0.902928 Validation Accuracy: 0.818594\n",
      "Epoch  8, Batch 135 -Loss:     0.6798 Training Accuracy: 0.914452 Validation Accuracy: 0.830839\n",
      "Epoch  8, Batch 136 -Loss:     0.9030 Training Accuracy: 0.911176 Validation Accuracy: 0.833560\n",
      "Epoch  8, Batch 137 -Loss:     0.8525 Training Accuracy: 0.908905 Validation Accuracy: 0.833560\n",
      "Epoch  8, Batch 138 -Loss:     0.6956 Training Accuracy: 0.917728 Validation Accuracy: 0.836281\n",
      "Epoch  8, Batch 139 -Loss:     0.8631 Training Accuracy: 0.926032 Validation Accuracy: 0.849660\n",
      "Epoch  8, Batch 140 -Loss:     0.6515 Training Accuracy: 0.922297 Validation Accuracy: 0.846712\n",
      "Epoch  8, Batch 141 -Loss:     0.7985 Training Accuracy: 0.915860 Validation Accuracy: 0.845351\n",
      "Epoch  8, Batch 142 -Loss:     0.7754 Training Accuracy: 0.905515 Validation Accuracy: 0.838095\n",
      "Epoch  8, Batch 143 -Loss:     0.6414 Training Accuracy: 0.911089 Validation Accuracy: 0.846259\n",
      "Epoch  8, Batch 144 -Loss:     0.7569 Training Accuracy: 0.918992 Validation Accuracy: 0.853741\n",
      "Epoch  8, Batch 145 -Loss:     0.7254 Training Accuracy: 0.922670 Validation Accuracy: 0.846259\n",
      "Epoch  8, Batch 146 -Loss:     0.7478 Training Accuracy: 0.924912 Validation Accuracy: 0.844898\n",
      "Epoch  8, Batch 147 -Loss:     0.7600 Training Accuracy: 0.925687 Validation Accuracy: 0.844898\n",
      "Epoch  8, Batch 148 -Loss:     0.6510 Training Accuracy: 0.921952 Validation Accuracy: 0.837415\n",
      "Epoch  8, Batch 149 -Loss:     0.8422 Training Accuracy: 0.918676 Validation Accuracy: 0.833560\n",
      "Epoch  8, Batch 150 -Loss:     0.6491 Training Accuracy: 0.915716 Validation Accuracy: 0.832200\n",
      "Epoch  8, Batch 151 -Loss:     0.7250 Training Accuracy: 0.917009 Validation Accuracy: 0.831746\n",
      "Epoch  8, Batch 152 -Loss:     0.6198 Training Accuracy: 0.918072 Validation Accuracy: 0.831293\n",
      "Epoch  8, Batch 153 -Loss:     0.6940 Training Accuracy: 0.922641 Validation Accuracy: 0.837868\n",
      "Epoch  8, Batch 154 -Loss:     0.8241 Training Accuracy: 0.922383 Validation Accuracy: 0.837642\n",
      "Epoch  8, Batch 155 -Loss:     0.7111 Training Accuracy: 0.920860 Validation Accuracy: 0.838549\n",
      "Epoch  8, Batch 156 -Loss:     0.7698 Training Accuracy: 0.918819 Validation Accuracy: 0.845805\n",
      "Epoch  8, Batch 157 -Loss:     0.8419 Training Accuracy: 0.921090 Validation Accuracy: 0.854422\n",
      "Epoch  8, Batch 158 -Loss:     0.6194 Training Accuracy: 0.915745 Validation Accuracy: 0.849206\n",
      "Epoch  8, Batch 159 -Loss:     0.8771 Training Accuracy: 0.914021 Validation Accuracy: 0.838549\n",
      "Epoch  8, Batch 160 -Loss:     0.6448 Training Accuracy: 0.919998 Validation Accuracy: 0.839909\n",
      "Epoch  8, Batch 161 -Loss:     0.7635 Training Accuracy: 0.922613 Validation Accuracy: 0.842857\n",
      "Epoch  8, Batch 162 -Loss:     0.7370 Training Accuracy: 0.921262 Validation Accuracy: 0.833787\n",
      "Epoch  8, Batch 163 -Loss:     0.7636 Training Accuracy: 0.918532 Validation Accuracy: 0.831519\n",
      "Epoch  8, Batch 164 -Loss:     0.7433 Training Accuracy: 0.915831 Validation Accuracy: 0.822222\n",
      "Epoch  8, Batch 165 -Loss:     0.6328 Training Accuracy: 0.913216 Validation Accuracy: 0.819728\n",
      "Epoch  8, Batch 166 -Loss:     0.6575 Training Accuracy: 0.912038 Validation Accuracy: 0.820181\n",
      "Epoch  8, Batch 167 -Loss:     0.6845 Training Accuracy: 0.907727 Validation Accuracy: 0.818821\n",
      "Epoch  8, Batch 168 -Loss:     0.7832 Training Accuracy: 0.908331 Validation Accuracy: 0.819728\n",
      "Epoch  8, Batch 169 -Loss:     0.6889 Training Accuracy: 0.915745 Validation Accuracy: 0.825624\n",
      "Epoch  8, Batch 170 -Loss:     0.7165 Training Accuracy: 0.920486 Validation Accuracy: 0.831973\n",
      "Epoch  8, Batch 171 -Loss:     0.7240 Training Accuracy: 0.923590 Validation Accuracy: 0.837188\n",
      "Epoch  8, Batch 172 -Loss:     0.8282 Training Accuracy: 0.918676 Validation Accuracy: 0.828571\n",
      "Epoch  8, Batch 173 -Loss:     0.6838 Training Accuracy: 0.912411 Validation Accuracy: 0.825850\n",
      "Epoch  8, Batch 174 -Loss:     0.7230 Training Accuracy: 0.907526 Validation Accuracy: 0.814286\n",
      "Epoch  8, Batch 175 -Loss:     0.7153 Training Accuracy: 0.903733 Validation Accuracy: 0.803401\n",
      "Epoch  8, Batch 176 -Loss:     0.7072 Training Accuracy: 0.899882 Validation Accuracy: 0.807936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8, Batch 177 -Loss:     0.6768 Training Accuracy: 0.904566 Validation Accuracy: 0.809751\n",
      "Epoch  8, Batch 178 -Loss:     0.7638 Training Accuracy: 0.910342 Validation Accuracy: 0.827438\n",
      "Epoch  8, Batch 179 -Loss:     0.7350 Training Accuracy: 0.903359 Validation Accuracy: 0.830159\n",
      "Epoch  8, Batch 180 -Loss:     0.7609 Training Accuracy: 0.897181 Validation Accuracy: 0.819501\n",
      "Epoch  8, Batch 181 -Loss:     0.7059 Training Accuracy: 0.898819 Validation Accuracy: 0.820635\n",
      "Epoch  8, Batch 182 -Loss:     0.7238 Training Accuracy: 0.909222 Validation Accuracy: 0.817914\n",
      "Epoch  8, Batch 183 -Loss:     0.9306 Training Accuracy: 0.914567 Validation Accuracy: 0.814286\n",
      "Epoch  8, Batch 184 -Loss:     0.7161 Training Accuracy: 0.920285 Validation Accuracy: 0.816780\n",
      "Epoch  8, Batch 185 -Loss:     0.6764 Training Accuracy: 0.920400 Validation Accuracy: 0.819955\n",
      "Epoch  8, Batch 186 -Loss:     0.7844 Training Accuracy: 0.919480 Validation Accuracy: 0.828571\n",
      "Epoch  8, Batch 187 -Loss:     0.7829 Training Accuracy: 0.910486 Validation Accuracy: 0.822449\n",
      "Epoch  8, Batch 188 -Loss:     0.8039 Training Accuracy: 0.900859 Validation Accuracy: 0.809751\n",
      "Epoch  8, Batch 189 -Loss:     0.7090 Training Accuracy: 0.904652 Validation Accuracy: 0.810431\n",
      "Epoch  8, Batch 190 -Loss:     0.6317 Training Accuracy: 0.918475 Validation Accuracy: 0.827438\n",
      "Epoch  8, Batch 191 -Loss:     0.6789 Training Accuracy: 0.926262 Validation Accuracy: 0.836508\n",
      "Epoch  8, Batch 192 -Loss:     0.6576 Training Accuracy: 0.924366 Validation Accuracy: 0.827891\n",
      "Epoch  8, Batch 193 -Loss:     0.7807 Training Accuracy: 0.915342 Validation Accuracy: 0.822222\n",
      "Epoch  8, Batch 194 -Loss:     0.7536 Training Accuracy: 0.916693 Validation Accuracy: 0.819274\n",
      "Epoch  8, Batch 195 -Loss:     0.6864 Training Accuracy: 0.923561 Validation Accuracy: 0.825850\n",
      "Epoch  8, Batch 196 -Loss:     0.9349 Training Accuracy: 0.925142 Validation Accuracy: 0.834014\n",
      "Epoch  8, Batch 197 -Loss:     0.6550 Training Accuracy: 0.916291 Validation Accuracy: 0.832880\n",
      "Epoch  8, Batch 198 -Loss:     0.6888 Training Accuracy: 0.906980 Validation Accuracy: 0.828118\n",
      "Epoch  8, Batch 199 -Loss:     0.7642 Training Accuracy: 0.908273 Validation Accuracy: 0.829252\n",
      "Epoch  8, Batch 200 -Loss:     0.6942 Training Accuracy: 0.912469 Validation Accuracy: 0.832880\n",
      "Epoch  8, Batch 201 -Loss:     0.8909 Training Accuracy: 0.909882 Validation Accuracy: 0.826757\n",
      "Epoch  8, Batch 202 -Loss:     0.6822 Training Accuracy: 0.908704 Validation Accuracy: 0.826531\n",
      "Epoch  8, Batch 203 -Loss:     0.7084 Training Accuracy: 0.908446 Validation Accuracy: 0.827664\n",
      "Epoch  8, Batch 204 -Loss:     0.6361 Training Accuracy: 0.903474 Validation Accuracy: 0.825624\n",
      "Epoch  8, Batch 205 -Loss:     0.7467 Training Accuracy: 0.903331 Validation Accuracy: 0.822449\n",
      "Epoch  8, Batch 206 -Loss:     0.6935 Training Accuracy: 0.917756 Validation Accuracy: 0.835374\n",
      "Epoch  8, Batch 207 -Loss:     0.6777 Training Accuracy: 0.917871 Validation Accuracy: 0.827891\n",
      "Epoch  8, Batch 208 -Loss:     0.7742 Training Accuracy: 0.905572 Validation Accuracy: 0.818367\n",
      "Epoch  8, Batch 209 -Loss:     0.7091 Training Accuracy: 0.894164 Validation Accuracy: 0.809297\n",
      "Epoch  8, Batch 210 -Loss:     0.7038 Training Accuracy: 0.891721 Validation Accuracy: 0.808163\n",
      "Epoch  8, Batch 211 -Loss:     0.8723 Training Accuracy: 0.910285 Validation Accuracy: 0.824717\n",
      "Epoch  8, Batch 212 -Loss:     0.7089 Training Accuracy: 0.923360 Validation Accuracy: 0.838095\n",
      "Epoch  8, Batch 213 -Loss:     0.7328 Training Accuracy: 0.928963 Validation Accuracy: 0.846939\n",
      "Epoch  8, Batch 214 -Loss:     1.0295 Training Accuracy: 0.928245 Validation Accuracy: 0.848753\n",
      "Epoch  8, Batch 215 -Loss:     0.6789 Training Accuracy: 0.925573 Validation Accuracy: 0.845805\n",
      "Epoch  8, Batch 216 -Loss:     0.7578 Training Accuracy: 0.927067 Validation Accuracy: 0.851020\n",
      "Epoch  8, Batch 217 -Loss:     0.7039 Training Accuracy: 0.927498 Validation Accuracy: 0.854422\n",
      "Epoch  8, Batch 218 -Loss:     0.7823 Training Accuracy: 0.921607 Validation Accuracy: 0.854875\n",
      "Epoch  8, Batch 219 -Loss:     0.6496 Training Accuracy: 0.914768 Validation Accuracy: 0.851474\n",
      "Epoch  8, Batch 220 -Loss:     0.7691 Training Accuracy: 0.918647 Validation Accuracy: 0.853288\n",
      "Epoch  8, Batch 221 -Loss:     0.7627 Training Accuracy: 0.922268 Validation Accuracy: 0.844218\n",
      "Epoch  8, Batch 222 -Loss:     0.7057 Training Accuracy: 0.923676 Validation Accuracy: 0.840136\n",
      "Epoch  8, Batch 223 -Loss:     0.7544 Training Accuracy: 0.923848 Validation Accuracy: 0.836735\n",
      "Epoch  8, Batch 224 -Loss:     0.7070 Training Accuracy: 0.927584 Validation Accuracy: 0.837415\n",
      "Epoch  8, Batch 225 -Loss:     0.6975 Training Accuracy: 0.920343 Validation Accuracy: 0.813605\n",
      "Epoch  8, Batch 226 -Loss:     0.7111 Training Accuracy: 0.912095 Validation Accuracy: 0.800680\n",
      "Epoch  8, Batch 227 -Loss:     0.7254 Training Accuracy: 0.916521 Validation Accuracy: 0.810204\n",
      "Epoch  8, Batch 228 -Loss:     0.6278 Training Accuracy: 0.917009 Validation Accuracy: 0.828345\n",
      "Epoch  8, Batch 229 -Loss:     0.7784 Training Accuracy: 0.917469 Validation Accuracy: 0.832200\n",
      "Epoch  8, Batch 230 -Loss:     0.8031 Training Accuracy: 0.921090 Validation Accuracy: 0.840816\n",
      "Epoch  8, Batch 231 -Loss:     0.7070 Training Accuracy: 0.918072 Validation Accuracy: 0.837188\n",
      "Epoch  8, Batch 232 -Loss:     0.6697 Training Accuracy: 0.903675 Validation Accuracy: 0.821995\n",
      "Epoch  8, Batch 233 -Loss:     0.7555 Training Accuracy: 0.912526 Validation Accuracy: 0.831293\n",
      "Epoch  8, Batch 234 -Loss:     0.6343 Training Accuracy: 0.919825 Validation Accuracy: 0.837415\n",
      "Epoch  8, Batch 235 -Loss:     0.6611 Training Accuracy: 0.921923 Validation Accuracy: 0.844218\n",
      "Epoch  8, Batch 236 -Loss:     0.7380 Training Accuracy: 0.928245 Validation Accuracy: 0.852381\n",
      "Epoch  8, Batch 237 -Loss:     0.6874 Training Accuracy: 0.930027 Validation Accuracy: 0.852381\n",
      "Epoch  8, Batch 238 -Loss:     0.7063 Training Accuracy: 0.921492 Validation Accuracy: 0.841043\n",
      "Epoch  8, Batch 239 -Loss:     0.6396 Training Accuracy: 0.914365 Validation Accuracy: 0.828571\n",
      "Epoch  8, Batch 240 -Loss:     0.7356 Training Accuracy: 0.915227 Validation Accuracy: 0.816780\n",
      "Epoch  8, Batch 241 -Loss:     0.7778 Training Accuracy: 0.915170 Validation Accuracy: 0.807029\n",
      "Epoch  8, Batch 242 -Loss:     0.7298 Training Accuracy: 0.912814 Validation Accuracy: 0.802948\n",
      "Epoch  8, Batch 243 -Loss:     0.7251 Training Accuracy: 0.916607 Validation Accuracy: 0.807256\n",
      "Epoch  8, Batch 244 -Loss:     0.7949 Training Accuracy: 0.921607 Validation Accuracy: 0.813832\n",
      "Epoch  8, Batch 245 -Loss:     0.6529 Training Accuracy: 0.922814 Validation Accuracy: 0.824263\n",
      "Epoch  8, Batch 246 -Loss:     0.6495 Training Accuracy: 0.915199 Validation Accuracy: 0.823810\n",
      "Epoch  8, Batch 247 -Loss:     0.7320 Training Accuracy: 0.913589 Validation Accuracy: 0.829478\n",
      "Epoch  8, Batch 248 -Loss:     0.6827 Training Accuracy: 0.922584 Validation Accuracy: 0.842857\n",
      "Epoch  8, Batch 249 -Loss:     0.5827 Training Accuracy: 0.923389 Validation Accuracy: 0.841723\n",
      "Epoch  8, Batch 250 -Loss:     0.8057 Training Accuracy: 0.921866 Validation Accuracy: 0.839456\n",
      "Epoch  8, Batch 251 -Loss:     0.7227 Training Accuracy: 0.923848 Validation Accuracy: 0.834467\n",
      "Epoch  8, Batch 252 -Loss:     0.6742 Training Accuracy: 0.919394 Validation Accuracy: 0.824263\n",
      "Epoch  8, Batch 253 -Loss:     0.7036 Training Accuracy: 0.918475 Validation Accuracy: 0.824943\n",
      "Epoch  8, Batch 254 -Loss:     0.7008 Training Accuracy: 0.921435 Validation Accuracy: 0.830612\n",
      "Epoch  8, Batch 255 -Loss:     0.6304 Training Accuracy: 0.917641 Validation Accuracy: 0.828345\n",
      "Epoch  8, Batch 256 -Loss:     0.7709 Training Accuracy: 0.908733 Validation Accuracy: 0.813832\n",
      "Epoch  8, Batch 257 -Loss:     0.7284 Training Accuracy: 0.908819 Validation Accuracy: 0.813605\n",
      "Epoch  8, Batch 258 -Loss:     0.7972 Training Accuracy: 0.908474 Validation Accuracy: 0.812472\n",
      "Epoch  8, Batch 259 -Loss:     0.8420 Training Accuracy: 0.907699 Validation Accuracy: 0.817687\n",
      "Epoch  8, Batch 260 -Loss:     0.6188 Training Accuracy: 0.906721 Validation Accuracy: 0.819728\n",
      "Epoch  8, Batch 261 -Loss:     0.7648 Training Accuracy: 0.901693 Validation Accuracy: 0.814059\n",
      "Epoch  8, Batch 262 -Loss:     0.6631 Training Accuracy: 0.902928 Validation Accuracy: 0.818141\n",
      "Epoch  8, Batch 263 -Loss:     0.6629 Training Accuracy: 0.903129 Validation Accuracy: 0.820181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8, Batch 264 -Loss:     0.6156 Training Accuracy: 0.916636 Validation Accuracy: 0.835374\n",
      "Epoch  8, Batch 265 -Loss:     0.7841 Training Accuracy: 0.924366 Validation Accuracy: 0.846485\n",
      "Epoch  8, Batch 266 -Loss:     0.8385 Training Accuracy: 0.917986 Validation Accuracy: 0.838322\n",
      "Epoch  8, Batch 267 -Loss:     0.5820 Training Accuracy: 0.902813 Validation Accuracy: 0.813832\n",
      "Epoch  8, Batch 268 -Loss:     0.6702 Training Accuracy: 0.896405 Validation Accuracy: 0.801587\n",
      "Epoch  8, Batch 269 -Loss:     0.7273 Training Accuracy: 0.891118 Validation Accuracy: 0.799546\n",
      "Epoch  8, Batch 270 -Loss:     0.6969 Training Accuracy: 0.916147 Validation Accuracy: 0.834921\n",
      "Epoch  8, Batch 271 -Loss:     0.6591 Training Accuracy: 0.919883 Validation Accuracy: 0.837188\n",
      "Epoch  8, Batch 272 -Loss:     0.8154 Training Accuracy: 0.905342 Validation Accuracy: 0.822903\n",
      "Epoch  9, Batch   1 -Loss:     0.7172 Training Accuracy: 0.897440 Validation Accuracy: 0.817234\n",
      "Epoch  9, Batch   2 -Loss:     0.7433 Training Accuracy: 0.917785 Validation Accuracy: 0.829478\n",
      "Epoch  9, Batch   3 -Loss:     0.6442 Training Accuracy: 0.912785 Validation Accuracy: 0.817007\n",
      "Epoch  9, Batch   4 -Loss:     0.7773 Training Accuracy: 0.871548 Validation Accuracy: 0.773923\n",
      "Epoch  9, Batch   5 -Loss:     0.7846 Training Accuracy: 0.837955 Validation Accuracy: 0.734467\n",
      "Epoch  9, Batch   6 -Loss:     0.8168 Training Accuracy: 0.886405 Validation Accuracy: 0.794558\n",
      "Epoch  9, Batch   7 -Loss:     0.6657 Training Accuracy: 0.920457 Validation Accuracy: 0.845125\n",
      "Epoch  9, Batch   8 -Loss:     0.7704 Training Accuracy: 0.901635 Validation Accuracy: 0.828798\n",
      "Epoch  9, Batch   9 -Loss:     0.7298 Training Accuracy: 0.891836 Validation Accuracy: 0.823356\n",
      "Epoch  9, Batch  10 -Loss:     0.7664 Training Accuracy: 0.905313 Validation Accuracy: 0.831519\n",
      "Epoch  9, Batch  11 -Loss:     0.8268 Training Accuracy: 0.915572 Validation Accuracy: 0.832653\n",
      "Epoch  9, Batch  12 -Loss:     0.7411 Training Accuracy: 0.908934 Validation Accuracy: 0.831066\n",
      "Epoch  9, Batch  13 -Loss:     0.7349 Training Accuracy: 0.890514 Validation Accuracy: 0.820181\n",
      "Epoch  9, Batch  14 -Loss:     0.7756 Training Accuracy: 0.884939 Validation Accuracy: 0.822903\n",
      "Epoch  9, Batch  15 -Loss:     0.7008 Training Accuracy: 0.901894 Validation Accuracy: 0.842630\n",
      "Epoch  9, Batch  16 -Loss:     0.6909 Training Accuracy: 0.922239 Validation Accuracy: 0.850340\n",
      "Epoch  9, Batch  17 -Loss:     0.7178 Training Accuracy: 0.921233 Validation Accuracy: 0.850340\n",
      "Epoch  9, Batch  18 -Loss:     0.7182 Training Accuracy: 0.908905 Validation Accuracy: 0.842857\n",
      "Epoch  9, Batch  19 -Loss:     0.6653 Training Accuracy: 0.900371 Validation Accuracy: 0.835601\n",
      "Epoch  9, Batch  20 -Loss:     0.7639 Training Accuracy: 0.908130 Validation Accuracy: 0.844671\n",
      "Epoch  9, Batch  21 -Loss:     0.6201 Training Accuracy: 0.914739 Validation Accuracy: 0.852154\n",
      "Epoch  9, Batch  22 -Loss:     0.6956 Training Accuracy: 0.913475 Validation Accuracy: 0.843537\n",
      "Epoch  9, Batch  23 -Loss:     0.7080 Training Accuracy: 0.908848 Validation Accuracy: 0.826984\n",
      "Epoch  9, Batch  24 -Loss:     0.7309 Training Accuracy: 0.907612 Validation Accuracy: 0.814059\n",
      "Epoch  9, Batch  25 -Loss:     0.6580 Training Accuracy: 0.904279 Validation Accuracy: 0.805442\n",
      "Epoch  9, Batch  26 -Loss:     0.6980 Training Accuracy: 0.907871 Validation Accuracy: 0.811565\n",
      "Epoch  9, Batch  27 -Loss:     0.7445 Training Accuracy: 0.900601 Validation Accuracy: 0.818141\n",
      "Epoch  9, Batch  28 -Loss:     0.7239 Training Accuracy: 0.899968 Validation Accuracy: 0.821542\n",
      "Epoch  9, Batch  29 -Loss:     0.8131 Training Accuracy: 0.907038 Validation Accuracy: 0.830612\n",
      "Epoch  9, Batch  30 -Loss:     0.8343 Training Accuracy: 0.921090 Validation Accuracy: 0.837188\n",
      "Epoch  9, Batch  31 -Loss:     0.7084 Training Accuracy: 0.919825 Validation Accuracy: 0.834694\n",
      "Epoch  9, Batch  32 -Loss:     0.8672 Training Accuracy: 0.915371 Validation Accuracy: 0.836961\n",
      "Epoch  9, Batch  33 -Loss:     0.6696 Training Accuracy: 0.909825 Validation Accuracy: 0.841723\n",
      "Epoch  9, Batch  34 -Loss:     0.6802 Training Accuracy: 0.921549 Validation Accuracy: 0.850567\n",
      "Epoch  9, Batch  35 -Loss:     0.6983 Training Accuracy: 0.926348 Validation Accuracy: 0.850113\n",
      "Epoch  9, Batch  36 -Loss:     0.6836 Training Accuracy: 0.922325 Validation Accuracy: 0.848526\n",
      "Epoch  9, Batch  37 -Loss:     0.7453 Training Accuracy: 0.920371 Validation Accuracy: 0.843991\n",
      "Epoch  9, Batch  38 -Loss:     0.7113 Training Accuracy: 0.922153 Validation Accuracy: 0.841950\n",
      "Epoch  9, Batch  39 -Loss:     0.6443 Training Accuracy: 0.916521 Validation Accuracy: 0.835601\n",
      "Epoch  9, Batch  40 -Loss:     0.7256 Training Accuracy: 0.909825 Validation Accuracy: 0.827891\n",
      "Epoch  9, Batch  41 -Loss:     0.7813 Training Accuracy: 0.910141 Validation Accuracy: 0.826077\n",
      "Epoch  9, Batch  42 -Loss:     0.7110 Training Accuracy: 0.915141 Validation Accuracy: 0.826077\n",
      "Epoch  9, Batch  43 -Loss:     0.6887 Training Accuracy: 0.923159 Validation Accuracy: 0.827438\n",
      "Epoch  9, Batch  44 -Loss:     0.6441 Training Accuracy: 0.921492 Validation Accuracy: 0.829932\n",
      "Epoch  9, Batch  45 -Loss:     0.6773 Training Accuracy: 0.915975 Validation Accuracy: 0.826984\n",
      "Epoch  9, Batch  46 -Loss:     0.7902 Training Accuracy: 0.916463 Validation Accuracy: 0.826077\n",
      "Epoch  9, Batch  47 -Loss:     0.7289 Training Accuracy: 0.921837 Validation Accuracy: 0.830159\n",
      "Epoch  9, Batch  48 -Loss:     0.6477 Training Accuracy: 0.922009 Validation Accuracy: 0.830839\n",
      "Epoch  9, Batch  49 -Loss:     0.7033 Training Accuracy: 0.915457 Validation Accuracy: 0.833333\n",
      "Epoch  9, Batch  50 -Loss:     0.6500 Training Accuracy: 0.920946 Validation Accuracy: 0.839002\n",
      "Epoch  9, Batch  51 -Loss:     0.6913 Training Accuracy: 0.915371 Validation Accuracy: 0.825624\n",
      "Epoch  9, Batch  52 -Loss:     0.8815 Training Accuracy: 0.908963 Validation Accuracy: 0.814059\n",
      "Epoch  9, Batch  53 -Loss:     0.6510 Training Accuracy: 0.914768 Validation Accuracy: 0.818141\n",
      "Epoch  9, Batch  54 -Loss:     0.6943 Training Accuracy: 0.923245 Validation Accuracy: 0.826984\n",
      "Epoch  9, Batch  55 -Loss:     0.6299 Training Accuracy: 0.926176 Validation Accuracy: 0.836735\n",
      "Epoch  9, Batch  56 -Loss:     0.7668 Training Accuracy: 0.921377 Validation Accuracy: 0.843764\n",
      "Epoch  9, Batch  57 -Loss:     0.6915 Training Accuracy: 0.914509 Validation Accuracy: 0.838776\n",
      "Epoch  9, Batch  58 -Loss:     0.7480 Training Accuracy: 0.909710 Validation Accuracy: 0.834921\n",
      "Epoch  9, Batch  59 -Loss:     0.6193 Training Accuracy: 0.916319 Validation Accuracy: 0.836281\n",
      "Epoch  9, Batch  60 -Loss:     0.6341 Training Accuracy: 0.925256 Validation Accuracy: 0.843537\n",
      "Epoch  9, Batch  61 -Loss:     0.6666 Training Accuracy: 0.920917 Validation Accuracy: 0.838322\n",
      "Epoch  9, Batch  62 -Loss:     0.6955 Training Accuracy: 0.913331 Validation Accuracy: 0.828798\n",
      "Epoch  9, Batch  63 -Loss:     0.7858 Training Accuracy: 0.908704 Validation Accuracy: 0.828798\n",
      "Epoch  9, Batch  64 -Loss:     0.6859 Training Accuracy: 0.914653 Validation Accuracy: 0.832426\n",
      "Epoch  9, Batch  65 -Loss:     0.6640 Training Accuracy: 0.920400 Validation Accuracy: 0.837188\n",
      "Epoch  9, Batch  66 -Loss:     0.7044 Training Accuracy: 0.924452 Validation Accuracy: 0.846485\n",
      "Epoch  9, Batch  67 -Loss:     0.7398 Training Accuracy: 0.925084 Validation Accuracy: 0.847846\n",
      "Epoch  9, Batch  68 -Loss:     0.6528 Training Accuracy: 0.924308 Validation Accuracy: 0.840816\n",
      "Epoch  9, Batch  69 -Loss:     0.7353 Training Accuracy: 0.922641 Validation Accuracy: 0.837642\n",
      "Epoch  9, Batch  70 -Loss:     0.6136 Training Accuracy: 0.917756 Validation Accuracy: 0.830159\n",
      "Epoch  9, Batch  71 -Loss:     0.6602 Training Accuracy: 0.918762 Validation Accuracy: 0.833787\n",
      "Epoch  9, Batch  72 -Loss:     0.6723 Training Accuracy: 0.930544 Validation Accuracy: 0.848299\n",
      "Epoch  9, Batch  73 -Loss:     0.6429 Training Accuracy: 0.932326 Validation Accuracy: 0.859184\n",
      "Epoch  9, Batch  74 -Loss:     0.7048 Training Accuracy: 0.927469 Validation Accuracy: 0.852834\n",
      "Epoch  9, Batch  75 -Loss:     0.6372 Training Accuracy: 0.927785 Validation Accuracy: 0.855102\n",
      "Epoch  9, Batch  76 -Loss:     0.6046 Training Accuracy: 0.928044 Validation Accuracy: 0.854195\n",
      "Epoch  9, Batch  77 -Loss:     0.6777 Training Accuracy: 0.925055 Validation Accuracy: 0.845578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9, Batch  78 -Loss:     0.6386 Training Accuracy: 0.922584 Validation Accuracy: 0.845351\n",
      "Epoch  9, Batch  79 -Loss:     0.7606 Training Accuracy: 0.926521 Validation Accuracy: 0.849660\n",
      "Epoch  9, Batch  80 -Loss:     0.7008 Training Accuracy: 0.931349 Validation Accuracy: 0.854649\n",
      "Epoch  9, Batch  81 -Loss:     0.8291 Training Accuracy: 0.933992 Validation Accuracy: 0.859864\n",
      "Epoch  9, Batch  82 -Loss:     0.6711 Training Accuracy: 0.931579 Validation Accuracy: 0.865986\n",
      "Epoch  9, Batch  83 -Loss:     0.6425 Training Accuracy: 0.924596 Validation Accuracy: 0.859864\n",
      "Epoch  9, Batch  84 -Loss:     0.7737 Training Accuracy: 0.921492 Validation Accuracy: 0.852154\n",
      "Epoch  9, Batch  85 -Loss:     0.6067 Training Accuracy: 0.920400 Validation Accuracy: 0.841497\n",
      "Epoch  9, Batch  86 -Loss:     0.6500 Training Accuracy: 0.929251 Validation Accuracy: 0.846032\n",
      "Epoch  9, Batch  87 -Loss:     0.7453 Training Accuracy: 0.933418 Validation Accuracy: 0.848753\n",
      "Epoch  9, Batch  88 -Loss:     0.6672 Training Accuracy: 0.930170 Validation Accuracy: 0.846939\n",
      "Epoch  9, Batch  89 -Loss:     0.6386 Training Accuracy: 0.924021 Validation Accuracy: 0.841497\n",
      "Epoch  9, Batch  90 -Loss:     0.6720 Training Accuracy: 0.925659 Validation Accuracy: 0.840816\n",
      "Epoch  9, Batch  91 -Loss:     0.6597 Training Accuracy: 0.930228 Validation Accuracy: 0.841723\n",
      "Epoch  9, Batch  92 -Loss:     0.6662 Training Accuracy: 0.929222 Validation Accuracy: 0.844218\n",
      "Epoch  9, Batch  93 -Loss:     0.6886 Training Accuracy: 0.924768 Validation Accuracy: 0.839002\n",
      "Epoch  9, Batch  94 -Loss:     0.5612 Training Accuracy: 0.919854 Validation Accuracy: 0.836961\n",
      "Epoch  9, Batch  95 -Loss:     0.7168 Training Accuracy: 0.917153 Validation Accuracy: 0.836508\n",
      "Epoch  9, Batch  96 -Loss:     0.7496 Training Accuracy: 0.919193 Validation Accuracy: 0.840363\n",
      "Epoch  9, Batch  97 -Loss:     0.6522 Training Accuracy: 0.917555 Validation Accuracy: 0.836054\n",
      "Epoch  9, Batch  98 -Loss:     0.8042 Training Accuracy: 0.921291 Validation Accuracy: 0.836961\n",
      "Epoch  9, Batch  99 -Loss:     0.7229 Training Accuracy: 0.927067 Validation Accuracy: 0.841270\n",
      "Epoch  9, Batch 100 -Loss:     0.6545 Training Accuracy: 0.926205 Validation Accuracy: 0.832653\n",
      "Epoch  9, Batch 101 -Loss:     0.6581 Training Accuracy: 0.919337 Validation Accuracy: 0.827891\n",
      "Epoch  9, Batch 102 -Loss:     0.6285 Training Accuracy: 0.919423 Validation Accuracy: 0.825850\n",
      "Epoch  9, Batch 103 -Loss:     0.6911 Training Accuracy: 0.927412 Validation Accuracy: 0.840590\n",
      "Epoch  9, Batch 104 -Loss:     0.5729 Training Accuracy: 0.923877 Validation Accuracy: 0.850113\n",
      "Epoch  9, Batch 105 -Loss:     0.8463 Training Accuracy: 0.914854 Validation Accuracy: 0.847619\n",
      "Epoch  9, Batch 106 -Loss:     0.8168 Training Accuracy: 0.915371 Validation Accuracy: 0.849206\n",
      "Epoch  9, Batch 107 -Loss:     0.7115 Training Accuracy: 0.925745 Validation Accuracy: 0.853741\n",
      "Epoch  9, Batch 108 -Loss:     0.6729 Training Accuracy: 0.927728 Validation Accuracy: 0.837868\n",
      "Epoch  9, Batch 109 -Loss:     0.7674 Training Accuracy: 0.920285 Validation Accuracy: 0.824263\n",
      "Epoch  9, Batch 110 -Loss:     0.7063 Training Accuracy: 0.916090 Validation Accuracy: 0.824036\n",
      "Epoch  9, Batch 111 -Loss:     0.6940 Training Accuracy: 0.916664 Validation Accuracy: 0.826757\n",
      "Epoch  9, Batch 112 -Loss:     0.7530 Training Accuracy: 0.920515 Validation Accuracy: 0.839229\n",
      "Epoch  9, Batch 113 -Loss:     0.6623 Training Accuracy: 0.921233 Validation Accuracy: 0.847619\n",
      "Epoch  9, Batch 114 -Loss:     0.6802 Training Accuracy: 0.913187 Validation Accuracy: 0.838549\n",
      "Epoch  9, Batch 115 -Loss:     0.6692 Training Accuracy: 0.915572 Validation Accuracy: 0.839909\n",
      "Epoch  9, Batch 116 -Loss:     0.6044 Training Accuracy: 0.920343 Validation Accuracy: 0.841950\n",
      "Epoch  9, Batch 117 -Loss:     0.6136 Training Accuracy: 0.917641 Validation Accuracy: 0.837188\n",
      "Epoch  9, Batch 118 -Loss:     0.7724 Training Accuracy: 0.918072 Validation Accuracy: 0.829705\n",
      "Epoch  9, Batch 119 -Loss:     0.8047 Training Accuracy: 0.911980 Validation Accuracy: 0.822222\n",
      "Epoch  9, Batch 120 -Loss:     0.6163 Training Accuracy: 0.920113 Validation Accuracy: 0.837415\n",
      "Epoch  9, Batch 121 -Loss:     0.6672 Training Accuracy: 0.929826 Validation Accuracy: 0.851474\n",
      "Epoch  9, Batch 122 -Loss:     0.6576 Training Accuracy: 0.918331 Validation Accuracy: 0.840363\n",
      "Epoch  9, Batch 123 -Loss:     0.6987 Training Accuracy: 0.906463 Validation Accuracy: 0.829025\n",
      "Epoch  9, Batch 124 -Loss:     0.6368 Training Accuracy: 0.903273 Validation Accuracy: 0.827211\n",
      "Epoch  9, Batch 125 -Loss:     0.7480 Training Accuracy: 0.918072 Validation Accuracy: 0.837188\n",
      "Epoch  9, Batch 126 -Loss:     0.6389 Training Accuracy: 0.916722 Validation Accuracy: 0.832200\n",
      "Epoch  9, Batch 127 -Loss:     0.6623 Training Accuracy: 0.907957 Validation Accuracy: 0.818367\n",
      "Epoch  9, Batch 128 -Loss:     0.6283 Training Accuracy: 0.907813 Validation Accuracy: 0.821769\n",
      "Epoch  9, Batch 129 -Loss:     0.5843 Training Accuracy: 0.919509 Validation Accuracy: 0.836735\n",
      "Epoch  9, Batch 130 -Loss:     0.7684 Training Accuracy: 0.924940 Validation Accuracy: 0.846259\n",
      "Epoch  9, Batch 131 -Loss:     0.6812 Training Accuracy: 0.919308 Validation Accuracy: 0.841497\n",
      "Epoch  9, Batch 132 -Loss:     0.5910 Training Accuracy: 0.913043 Validation Accuracy: 0.837188\n",
      "Epoch  9, Batch 133 -Loss:     0.7192 Training Accuracy: 0.914193 Validation Accuracy: 0.843991\n",
      "Epoch  9, Batch 134 -Loss:     0.7491 Training Accuracy: 0.920917 Validation Accuracy: 0.855329\n",
      "Epoch  9, Batch 135 -Loss:     0.7303 Training Accuracy: 0.924251 Validation Accuracy: 0.863039\n",
      "Epoch  9, Batch 136 -Loss:     0.7213 Training Accuracy: 0.926176 Validation Accuracy: 0.869841\n",
      "Epoch  9, Batch 137 -Loss:     0.6719 Training Accuracy: 0.927268 Validation Accuracy: 0.867347\n",
      "Epoch  9, Batch 138 -Loss:     0.5939 Training Accuracy: 0.928791 Validation Accuracy: 0.864399\n",
      "Epoch  9, Batch 139 -Loss:     0.6737 Training Accuracy: 0.932757 Validation Accuracy: 0.865760\n",
      "Epoch  9, Batch 140 -Loss:     0.7013 Training Accuracy: 0.930601 Validation Accuracy: 0.858277\n",
      "Epoch  9, Batch 141 -Loss:     0.7328 Training Accuracy: 0.920630 Validation Accuracy: 0.837642\n",
      "Epoch  9, Batch 142 -Loss:     0.6702 Training Accuracy: 0.912641 Validation Accuracy: 0.826304\n",
      "Epoch  9, Batch 143 -Loss:     0.8151 Training Accuracy: 0.913762 Validation Accuracy: 0.826757\n",
      "Epoch  9, Batch 144 -Loss:     0.7021 Training Accuracy: 0.917526 Validation Accuracy: 0.830839\n",
      "Epoch  9, Batch 145 -Loss:     0.6896 Training Accuracy: 0.919912 Validation Accuracy: 0.833787\n",
      "Epoch  9, Batch 146 -Loss:     0.6737 Training Accuracy: 0.912066 Validation Accuracy: 0.831066\n",
      "Epoch  9, Batch 147 -Loss:     0.7973 Training Accuracy: 0.911089 Validation Accuracy: 0.827438\n",
      "Epoch  9, Batch 148 -Loss:     0.6629 Training Accuracy: 0.909825 Validation Accuracy: 0.819501\n",
      "Epoch  9, Batch 149 -Loss:     0.7697 Training Accuracy: 0.923647 Validation Accuracy: 0.832200\n",
      "Epoch  9, Batch 150 -Loss:     0.7396 Training Accuracy: 0.932498 Validation Accuracy: 0.846032\n",
      "Epoch  9, Batch 151 -Loss:     0.8138 Training Accuracy: 0.919854 Validation Accuracy: 0.839456\n",
      "Epoch  9, Batch 152 -Loss:     0.7506 Training Accuracy: 0.908474 Validation Accuracy: 0.827664\n",
      "Epoch  9, Batch 153 -Loss:     0.6687 Training Accuracy: 0.907957 Validation Accuracy: 0.827664\n",
      "Epoch  9, Batch 154 -Loss:     0.5992 Training Accuracy: 0.915773 Validation Accuracy: 0.834240\n",
      "Epoch  9, Batch 155 -Loss:     0.6310 Training Accuracy: 0.923475 Validation Accuracy: 0.834694\n",
      "Epoch  9, Batch 156 -Loss:     0.8082 Training Accuracy: 0.925027 Validation Accuracy: 0.830612\n",
      "Epoch  9, Batch 157 -Loss:     0.6846 Training Accuracy: 0.920457 Validation Accuracy: 0.830839\n",
      "Epoch  9, Batch 158 -Loss:     0.6527 Training Accuracy: 0.918877 Validation Accuracy: 0.833560\n",
      "Epoch  9, Batch 159 -Loss:     0.7032 Training Accuracy: 0.921607 Validation Accuracy: 0.836735\n",
      "Epoch  9, Batch 160 -Loss:     0.6961 Training Accuracy: 0.924538 Validation Accuracy: 0.845805\n",
      "Epoch  9, Batch 161 -Loss:     0.6902 Training Accuracy: 0.915946 Validation Accuracy: 0.838322\n",
      "Epoch  9, Batch 162 -Loss:     0.7715 Training Accuracy: 0.911118 Validation Accuracy: 0.829252\n",
      "Epoch  9, Batch 163 -Loss:     0.7074 Training Accuracy: 0.918963 Validation Accuracy: 0.836054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9, Batch 164 -Loss:     0.6354 Training Accuracy: 0.926291 Validation Accuracy: 0.841270\n",
      "Epoch  9, Batch 165 -Loss:     0.7125 Training Accuracy: 0.927900 Validation Accuracy: 0.843311\n",
      "Epoch  9, Batch 166 -Loss:     0.7097 Training Accuracy: 0.926004 Validation Accuracy: 0.837642\n",
      "Epoch  9, Batch 167 -Loss:     0.7647 Training Accuracy: 0.925831 Validation Accuracy: 0.842177\n",
      "Epoch  9, Batch 168 -Loss:     0.6688 Training Accuracy: 0.929567 Validation Accuracy: 0.847166\n",
      "Epoch  9, Batch 169 -Loss:     0.6329 Training Accuracy: 0.925113 Validation Accuracy: 0.845805\n",
      "Epoch  9, Batch 170 -Loss:     0.6591 Training Accuracy: 0.917009 Validation Accuracy: 0.841497\n",
      "Epoch  9, Batch 171 -Loss:     0.7822 Training Accuracy: 0.918705 Validation Accuracy: 0.846032\n",
      "Epoch  9, Batch 172 -Loss:     0.7470 Training Accuracy: 0.926751 Validation Accuracy: 0.847619\n",
      "Epoch  9, Batch 173 -Loss:     0.7410 Training Accuracy: 0.927986 Validation Accuracy: 0.845578\n",
      "Epoch  9, Batch 174 -Loss:     0.7253 Training Accuracy: 0.930228 Validation Accuracy: 0.844444\n",
      "Epoch  9, Batch 175 -Loss:     0.8163 Training Accuracy: 0.922699 Validation Accuracy: 0.831519\n",
      "Epoch  9, Batch 176 -Loss:     0.7117 Training Accuracy: 0.926607 Validation Accuracy: 0.829705\n",
      "Epoch  9, Batch 177 -Loss:     0.5794 Training Accuracy: 0.923963 Validation Accuracy: 0.826531\n",
      "Epoch  9, Batch 178 -Loss:     0.6918 Training Accuracy: 0.917383 Validation Accuracy: 0.815419\n",
      "Epoch  9, Batch 179 -Loss:     0.6108 Training Accuracy: 0.902354 Validation Accuracy: 0.805442\n",
      "Epoch  9, Batch 180 -Loss:     0.6118 Training Accuracy: 0.901089 Validation Accuracy: 0.806803\n",
      "Epoch  9, Batch 181 -Loss:     0.8442 Training Accuracy: 0.905428 Validation Accuracy: 0.813379\n",
      "Epoch  9, Batch 182 -Loss:     0.6032 Training Accuracy: 0.901405 Validation Accuracy: 0.810204\n",
      "Epoch  9, Batch 183 -Loss:     0.7105 Training Accuracy: 0.907699 Validation Accuracy: 0.822903\n",
      "Epoch  9, Batch 184 -Loss:     0.5947 Training Accuracy: 0.915658 Validation Accuracy: 0.833787\n",
      "Epoch  9, Batch 185 -Loss:     0.6525 Training Accuracy: 0.925170 Validation Accuracy: 0.834240\n",
      "Epoch  9, Batch 186 -Loss:     0.5897 Training Accuracy: 0.921923 Validation Accuracy: 0.823356\n",
      "Epoch  9, Batch 187 -Loss:     0.6556 Training Accuracy: 0.910400 Validation Accuracy: 0.817460\n",
      "Epoch  9, Batch 188 -Loss:     0.6688 Training Accuracy: 0.910227 Validation Accuracy: 0.819048\n",
      "Epoch  9, Batch 189 -Loss:     0.6727 Training Accuracy: 0.916980 Validation Accuracy: 0.834014\n",
      "Epoch  9, Batch 190 -Loss:     0.6882 Training Accuracy: 0.922095 Validation Accuracy: 0.840816\n",
      "Epoch  9, Batch 191 -Loss:     0.6736 Training Accuracy: 0.928044 Validation Accuracy: 0.853968\n",
      "Epoch  9, Batch 192 -Loss:     0.6605 Training Accuracy: 0.926406 Validation Accuracy: 0.852154\n",
      "Epoch  9, Batch 193 -Loss:     0.7198 Training Accuracy: 0.915773 Validation Accuracy: 0.842857\n",
      "Epoch  9, Batch 194 -Loss:     0.6982 Training Accuracy: 0.920946 Validation Accuracy: 0.842857\n",
      "Epoch  9, Batch 195 -Loss:     0.6517 Training Accuracy: 0.925371 Validation Accuracy: 0.838776\n",
      "Epoch  9, Batch 196 -Loss:     0.8028 Training Accuracy: 0.920572 Validation Accuracy: 0.821769\n",
      "Epoch  9, Batch 197 -Loss:     0.7653 Training Accuracy: 0.920831 Validation Accuracy: 0.822222\n",
      "Epoch  9, Batch 198 -Loss:     0.6412 Training Accuracy: 0.927038 Validation Accuracy: 0.834014\n",
      "Epoch  9, Batch 199 -Loss:     0.5938 Training Accuracy: 0.927383 Validation Accuracy: 0.842404\n",
      "Epoch  9, Batch 200 -Loss:     0.6953 Training Accuracy: 0.921636 Validation Accuracy: 0.838549\n",
      "Epoch  9, Batch 201 -Loss:     0.6800 Training Accuracy: 0.919480 Validation Accuracy: 0.842177\n",
      "Epoch  9, Batch 202 -Loss:     0.6625 Training Accuracy: 0.920026 Validation Accuracy: 0.850794\n",
      "Epoch  9, Batch 203 -Loss:     0.6004 Training Accuracy: 0.922325 Validation Accuracy: 0.855782\n",
      "Epoch  9, Batch 204 -Loss:     0.7310 Training Accuracy: 0.926550 Validation Accuracy: 0.860317\n",
      "Epoch  9, Batch 205 -Loss:     0.7016 Training Accuracy: 0.929941 Validation Accuracy: 0.865306\n",
      "Epoch  9, Batch 206 -Loss:     0.8125 Training Accuracy: 0.931952 Validation Accuracy: 0.862812\n",
      "Epoch  9, Batch 207 -Loss:     0.7564 Training Accuracy: 0.932354 Validation Accuracy: 0.855329\n",
      "Epoch  9, Batch 208 -Loss:     0.7212 Training Accuracy: 0.927584 Validation Accuracy: 0.848299\n",
      "Epoch  9, Batch 209 -Loss:     0.7077 Training Accuracy: 0.928303 Validation Accuracy: 0.841723\n",
      "Epoch  9, Batch 210 -Loss:     0.7194 Training Accuracy: 0.927038 Validation Accuracy: 0.835147\n",
      "Epoch  9, Batch 211 -Loss:     0.6878 Training Accuracy: 0.922641 Validation Accuracy: 0.830612\n",
      "Epoch  9, Batch 212 -Loss:     0.6876 Training Accuracy: 0.927440 Validation Accuracy: 0.840136\n",
      "Epoch  9, Batch 213 -Loss:     0.6702 Training Accuracy: 0.928762 Validation Accuracy: 0.846485\n",
      "Epoch  9, Batch 214 -Loss:     0.7043 Training Accuracy: 0.927900 Validation Accuracy: 0.850340\n",
      "Epoch  9, Batch 215 -Loss:     0.6897 Training Accuracy: 0.922929 Validation Accuracy: 0.839229\n",
      "Epoch  9, Batch 216 -Loss:     0.7650 Training Accuracy: 0.918791 Validation Accuracy: 0.838322\n",
      "Epoch  9, Batch 217 -Loss:     0.6191 Training Accuracy: 0.927297 Validation Accuracy: 0.849887\n",
      "Epoch  9, Batch 218 -Loss:     0.7434 Training Accuracy: 0.931377 Validation Accuracy: 0.847846\n",
      "Epoch  9, Batch 219 -Loss:     0.5978 Training Accuracy: 0.932728 Validation Accuracy: 0.845351\n",
      "Epoch  9, Batch 220 -Loss:     0.5921 Training Accuracy: 0.929509 Validation Accuracy: 0.846712\n",
      "Epoch  9, Batch 221 -Loss:     0.6795 Training Accuracy: 0.930343 Validation Accuracy: 0.843764\n",
      "Epoch  9, Batch 222 -Loss:     0.6201 Training Accuracy: 0.932010 Validation Accuracy: 0.845351\n",
      "Epoch  9, Batch 223 -Loss:     0.6480 Training Accuracy: 0.930716 Validation Accuracy: 0.844898\n",
      "Epoch  9, Batch 224 -Loss:     0.5871 Training Accuracy: 0.930372 Validation Accuracy: 0.842630\n",
      "Epoch  9, Batch 225 -Loss:     0.6433 Training Accuracy: 0.930429 Validation Accuracy: 0.839909\n",
      "Epoch  9, Batch 226 -Loss:     0.7877 Training Accuracy: 0.929193 Validation Accuracy: 0.841497\n",
      "Epoch  9, Batch 227 -Loss:     0.7348 Training Accuracy: 0.931895 Validation Accuracy: 0.847166\n",
      "Epoch  9, Batch 228 -Loss:     0.6089 Training Accuracy: 0.933015 Validation Accuracy: 0.853515\n",
      "Epoch  9, Batch 229 -Loss:     0.6447 Training Accuracy: 0.930314 Validation Accuracy: 0.853515\n",
      "Epoch  9, Batch 230 -Loss:     0.6460 Training Accuracy: 0.924567 Validation Accuracy: 0.853288\n",
      "Epoch  9, Batch 231 -Loss:     0.6845 Training Accuracy: 0.931636 Validation Accuracy: 0.863039\n",
      "Epoch  9, Batch 232 -Loss:     0.6199 Training Accuracy: 0.931320 Validation Accuracy: 0.855102\n",
      "Epoch  9, Batch 233 -Loss:     0.6761 Training Accuracy: 0.904365 Validation Accuracy: 0.822676\n",
      "Epoch  9, Batch 234 -Loss:     0.7498 Training Accuracy: 0.892411 Validation Accuracy: 0.806576\n",
      "Epoch  9, Batch 235 -Loss:     0.7682 Training Accuracy: 0.897095 Validation Accuracy: 0.811791\n",
      "Epoch  9, Batch 236 -Loss:     0.6337 Training Accuracy: 0.921118 Validation Accuracy: 0.845351\n",
      "Epoch  9, Batch 237 -Loss:     0.8545 Training Accuracy: 0.917929 Validation Accuracy: 0.847846\n",
      "Epoch  9, Batch 238 -Loss:     0.6736 Training Accuracy: 0.900572 Validation Accuracy: 0.828571\n",
      "Epoch  9, Batch 239 -Loss:     0.7095 Training Accuracy: 0.889365 Validation Accuracy: 0.817234\n",
      "Epoch  9, Batch 240 -Loss:     0.6636 Training Accuracy: 0.890744 Validation Accuracy: 0.816553\n",
      "Epoch  9, Batch 241 -Loss:     0.7007 Training Accuracy: 0.913532 Validation Accuracy: 0.835601\n",
      "Epoch  9, Batch 242 -Loss:     0.6029 Training Accuracy: 0.921435 Validation Accuracy: 0.837415\n",
      "Epoch  9, Batch 243 -Loss:     0.6428 Training Accuracy: 0.910946 Validation Accuracy: 0.824943\n",
      "Epoch  9, Batch 244 -Loss:     0.7713 Training Accuracy: 0.909336 Validation Accuracy: 0.834467\n",
      "Epoch  9, Batch 245 -Loss:     0.6176 Training Accuracy: 0.916521 Validation Accuracy: 0.835374\n",
      "Epoch  9, Batch 246 -Loss:     0.8214 Training Accuracy: 0.919423 Validation Accuracy: 0.846939\n",
      "Epoch  9, Batch 247 -Loss:     0.6784 Training Accuracy: 0.912756 Validation Accuracy: 0.844898\n",
      "Epoch  9, Batch 248 -Loss:     0.6860 Training Accuracy: 0.918934 Validation Accuracy: 0.848299\n",
      "Epoch  9, Batch 249 -Loss:     0.6872 Training Accuracy: 0.926722 Validation Accuracy: 0.853741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9, Batch 250 -Loss:     0.7369 Training Accuracy: 0.927325 Validation Accuracy: 0.849660\n",
      "Epoch  9, Batch 251 -Loss:     0.7151 Training Accuracy: 0.922958 Validation Accuracy: 0.839229\n",
      "Epoch  9, Batch 252 -Loss:     0.7524 Training Accuracy: 0.917785 Validation Accuracy: 0.831973\n",
      "Epoch  9, Batch 253 -Loss:     0.6339 Training Accuracy: 0.917526 Validation Accuracy: 0.830386\n",
      "Epoch  9, Batch 254 -Loss:     0.6599 Training Accuracy: 0.920026 Validation Accuracy: 0.829932\n",
      "Epoch  9, Batch 255 -Loss:     0.7990 Training Accuracy: 0.926550 Validation Accuracy: 0.831519\n",
      "Epoch  9, Batch 256 -Loss:     0.7086 Training Accuracy: 0.924050 Validation Accuracy: 0.827664\n",
      "Epoch  9, Batch 257 -Loss:     0.6392 Training Accuracy: 0.919854 Validation Accuracy: 0.822222\n",
      "Epoch  9, Batch 258 -Loss:     0.6259 Training Accuracy: 0.912497 Validation Accuracy: 0.822449\n",
      "Epoch  9, Batch 259 -Loss:     0.6322 Training Accuracy: 0.914681 Validation Accuracy: 0.825850\n",
      "Epoch  9, Batch 260 -Loss:     0.6892 Training Accuracy: 0.923216 Validation Accuracy: 0.835374\n",
      "Epoch  9, Batch 261 -Loss:     0.7118 Training Accuracy: 0.932613 Validation Accuracy: 0.845578\n",
      "Epoch  9, Batch 262 -Loss:     0.6208 Training Accuracy: 0.929337 Validation Accuracy: 0.849433\n",
      "Epoch  9, Batch 263 -Loss:     0.6869 Training Accuracy: 0.927325 Validation Accuracy: 0.847619\n",
      "Epoch  9, Batch 264 -Loss:     0.7524 Training Accuracy: 0.932699 Validation Accuracy: 0.844444\n",
      "Epoch  9, Batch 265 -Loss:     0.8179 Training Accuracy: 0.925946 Validation Accuracy: 0.838549\n",
      "Epoch  9, Batch 266 -Loss:     0.6759 Training Accuracy: 0.920544 Validation Accuracy: 0.833560\n",
      "Epoch  9, Batch 267 -Loss:     0.6215 Training Accuracy: 0.923216 Validation Accuracy: 0.835601\n",
      "Epoch  9, Batch 268 -Loss:     0.6692 Training Accuracy: 0.927354 Validation Accuracy: 0.841497\n",
      "Epoch  9, Batch 269 -Loss:     0.7050 Training Accuracy: 0.931464 Validation Accuracy: 0.849660\n",
      "Epoch  9, Batch 270 -Loss:     0.6961 Training Accuracy: 0.936234 Validation Accuracy: 0.852608\n",
      "Epoch  9, Batch 271 -Loss:     0.6839 Training Accuracy: 0.933992 Validation Accuracy: 0.852381\n",
      "Epoch  9, Batch 272 -Loss:     0.6202 Training Accuracy: 0.935429 Validation Accuracy: 0.852608\n",
      "Epoch 10, Batch   1 -Loss:     0.6292 Training Accuracy: 0.929509 Validation Accuracy: 0.843311\n",
      "Epoch 10, Batch   2 -Loss:     0.6856 Training Accuracy: 0.918877 Validation Accuracy: 0.834921\n",
      "Epoch 10, Batch   3 -Loss:     0.6144 Training Accuracy: 0.909250 Validation Accuracy: 0.831293\n",
      "Epoch 10, Batch   4 -Loss:     0.6206 Training Accuracy: 0.904940 Validation Accuracy: 0.823356\n",
      "Epoch 10, Batch   5 -Loss:     0.7374 Training Accuracy: 0.918647 Validation Accuracy: 0.833333\n",
      "Epoch 10, Batch   6 -Loss:     0.7140 Training Accuracy: 0.927009 Validation Accuracy: 0.836961\n",
      "Epoch 10, Batch   7 -Loss:     0.6472 Training Accuracy: 0.919969 Validation Accuracy: 0.831293\n",
      "Epoch 10, Batch   8 -Loss:     0.6949 Training Accuracy: 0.917929 Validation Accuracy: 0.832200\n",
      "Epoch 10, Batch   9 -Loss:     0.7177 Training Accuracy: 0.927067 Validation Accuracy: 0.846712\n",
      "Epoch 10, Batch  10 -Loss:     0.6858 Training Accuracy: 0.932326 Validation Accuracy: 0.850113\n",
      "Epoch 10, Batch  11 -Loss:     0.6110 Training Accuracy: 0.923475 Validation Accuracy: 0.843537\n",
      "Epoch 10, Batch  12 -Loss:     0.6782 Training Accuracy: 0.916980 Validation Accuracy: 0.833787\n",
      "Epoch 10, Batch  13 -Loss:     0.6723 Training Accuracy: 0.921808 Validation Accuracy: 0.836508\n",
      "Epoch 10, Batch  14 -Loss:     0.6713 Training Accuracy: 0.922641 Validation Accuracy: 0.835147\n",
      "Epoch 10, Batch  15 -Loss:     0.7053 Training Accuracy: 0.927412 Validation Accuracy: 0.841043\n",
      "Epoch 10, Batch  16 -Loss:     0.6508 Training Accuracy: 0.926032 Validation Accuracy: 0.844218\n",
      "Epoch 10, Batch  17 -Loss:     0.6904 Training Accuracy: 0.915975 Validation Accuracy: 0.840816\n",
      "Epoch 10, Batch  18 -Loss:     0.7110 Training Accuracy: 0.920572 Validation Accuracy: 0.848073\n",
      "Epoch 10, Batch  19 -Loss:     0.7548 Training Accuracy: 0.938590 Validation Accuracy: 0.866213\n",
      "Epoch 10, Batch  20 -Loss:     0.5935 Training Accuracy: 0.935113 Validation Accuracy: 0.853741\n",
      "Epoch 10, Batch  21 -Loss:     0.6971 Training Accuracy: 0.917182 Validation Accuracy: 0.834467\n",
      "Epoch 10, Batch  22 -Loss:     0.5692 Training Accuracy: 0.912038 Validation Accuracy: 0.820635\n",
      "Epoch 10, Batch  23 -Loss:     0.6262 Training Accuracy: 0.924998 Validation Accuracy: 0.828571\n",
      "Epoch 10, Batch  24 -Loss:     0.5911 Training Accuracy: 0.925601 Validation Accuracy: 0.835147\n",
      "Epoch 10, Batch  25 -Loss:     0.7724 Training Accuracy: 0.914250 Validation Accuracy: 0.831293\n",
      "Epoch 10, Batch  26 -Loss:     0.7084 Training Accuracy: 0.912986 Validation Accuracy: 0.835601\n",
      "Epoch 10, Batch  27 -Loss:     0.6487 Training Accuracy: 0.922814 Validation Accuracy: 0.845578\n",
      "Epoch 10, Batch  28 -Loss:     0.6669 Training Accuracy: 0.932268 Validation Accuracy: 0.850794\n",
      "Epoch 10, Batch  29 -Loss:     0.6278 Training Accuracy: 0.920601 Validation Accuracy: 0.843991\n",
      "Epoch 10, Batch  30 -Loss:     0.7179 Training Accuracy: 0.903417 Validation Accuracy: 0.833107\n",
      "Epoch 10, Batch  31 -Loss:     0.6536 Training Accuracy: 0.897382 Validation Accuracy: 0.817460\n",
      "Epoch 10, Batch  32 -Loss:     0.7396 Training Accuracy: 0.924710 Validation Accuracy: 0.845351\n",
      "Epoch 10, Batch  33 -Loss:     0.7159 Training Accuracy: 0.927383 Validation Accuracy: 0.854422\n",
      "Epoch 10, Batch  34 -Loss:     0.7423 Training Accuracy: 0.912986 Validation Accuracy: 0.845125\n",
      "Epoch 10, Batch  35 -Loss:     0.6175 Training Accuracy: 0.903819 Validation Accuracy: 0.833107\n",
      "Epoch 10, Batch  36 -Loss:     0.6742 Training Accuracy: 0.909480 Validation Accuracy: 0.831066\n",
      "Epoch 10, Batch  37 -Loss:     0.6621 Training Accuracy: 0.916118 Validation Accuracy: 0.828345\n",
      "Epoch 10, Batch  38 -Loss:     0.7041 Training Accuracy: 0.916549 Validation Accuracy: 0.821542\n",
      "Epoch 10, Batch  39 -Loss:     0.8160 Training Accuracy: 0.912181 Validation Accuracy: 0.815193\n",
      "Epoch 10, Batch  40 -Loss:     0.7589 Training Accuracy: 0.915400 Validation Accuracy: 0.821315\n",
      "Epoch 10, Batch  41 -Loss:     0.7306 Training Accuracy: 0.925142 Validation Accuracy: 0.834240\n",
      "Epoch 10, Batch  42 -Loss:     0.7379 Training Accuracy: 0.929395 Validation Accuracy: 0.838776\n",
      "Epoch 10, Batch  43 -Loss:     0.6312 Training Accuracy: 0.923647 Validation Accuracy: 0.840816\n",
      "Epoch 10, Batch  44 -Loss:     0.6504 Training Accuracy: 0.918015 Validation Accuracy: 0.832653\n",
      "Epoch 10, Batch  45 -Loss:     0.6393 Training Accuracy: 0.916578 Validation Accuracy: 0.827664\n",
      "Epoch 10, Batch  46 -Loss:     0.7128 Training Accuracy: 0.921664 Validation Accuracy: 0.833107\n",
      "Epoch 10, Batch  47 -Loss:     0.6436 Training Accuracy: 0.925055 Validation Accuracy: 0.836054\n",
      "Epoch 10, Batch  48 -Loss:     0.7542 Training Accuracy: 0.926234 Validation Accuracy: 0.841497\n",
      "Epoch 10, Batch  49 -Loss:     0.6335 Training Accuracy: 0.921578 Validation Accuracy: 0.840590\n",
      "Epoch 10, Batch  50 -Loss:     0.6056 Training Accuracy: 0.920802 Validation Accuracy: 0.841497\n",
      "Epoch 10, Batch  51 -Loss:     0.6217 Training Accuracy: 0.922843 Validation Accuracy: 0.843311\n",
      "Epoch 10, Batch  52 -Loss:     0.6268 Training Accuracy: 0.922958 Validation Accuracy: 0.847166\n",
      "Epoch 10, Batch  53 -Loss:     0.6779 Training Accuracy: 0.915457 Validation Accuracy: 0.842857\n",
      "Epoch 10, Batch  54 -Loss:     0.7376 Training Accuracy: 0.912153 Validation Accuracy: 0.839683\n",
      "Epoch 10, Batch  55 -Loss:     0.6369 Training Accuracy: 0.913589 Validation Accuracy: 0.837188\n",
      "Epoch 10, Batch  56 -Loss:     0.6558 Training Accuracy: 0.917756 Validation Accuracy: 0.832653\n",
      "Epoch 10, Batch  57 -Loss:     0.6023 Training Accuracy: 0.912497 Validation Accuracy: 0.815873\n",
      "Epoch 10, Batch  58 -Loss:     0.6589 Training Accuracy: 0.900342 Validation Accuracy: 0.795692\n",
      "Epoch 10, Batch  59 -Loss:     0.7538 Training Accuracy: 0.923992 Validation Accuracy: 0.823810\n",
      "Epoch 10, Batch  60 -Loss:     0.6625 Training Accuracy: 0.935056 Validation Accuracy: 0.842857\n",
      "Epoch 10, Batch  61 -Loss:     0.6946 Training Accuracy: 0.924452 Validation Accuracy: 0.828571\n",
      "Epoch 10, Batch  62 -Loss:     0.8570 Training Accuracy: 0.919251 Validation Accuracy: 0.826531\n",
      "Epoch 10, Batch  63 -Loss:     0.7060 Training Accuracy: 0.926004 Validation Accuracy: 0.838549\n",
      "Epoch 10, Batch  64 -Loss:     0.5736 Training Accuracy: 0.921866 Validation Accuracy: 0.837188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch  65 -Loss:     0.7381 Training Accuracy: 0.915055 Validation Accuracy: 0.828345\n",
      "Epoch 10, Batch  66 -Loss:     0.6009 Training Accuracy: 0.906463 Validation Accuracy: 0.819728\n",
      "Epoch 10, Batch  67 -Loss:     0.6010 Training Accuracy: 0.909681 Validation Accuracy: 0.824263\n",
      "Epoch 10, Batch  68 -Loss:     0.5346 Training Accuracy: 0.922613 Validation Accuracy: 0.837868\n",
      "Epoch 10, Batch  69 -Loss:     0.6094 Training Accuracy: 0.928590 Validation Accuracy: 0.843991\n",
      "Epoch 10, Batch  70 -Loss:     0.6930 Training Accuracy: 0.926061 Validation Accuracy: 0.839456\n",
      "Epoch 10, Batch  71 -Loss:     0.7078 Training Accuracy: 0.921032 Validation Accuracy: 0.837868\n",
      "Epoch 10, Batch  72 -Loss:     0.7800 Training Accuracy: 0.922843 Validation Accuracy: 0.840816\n",
      "Epoch 10, Batch  73 -Loss:     0.6342 Training Accuracy: 0.929567 Validation Accuracy: 0.846485\n",
      "Epoch 10, Batch  74 -Loss:     0.6636 Training Accuracy: 0.929682 Validation Accuracy: 0.843311\n",
      "Epoch 10, Batch  75 -Loss:     0.6474 Training Accuracy: 0.914595 Validation Accuracy: 0.816100\n",
      "Epoch 10, Batch  76 -Loss:     0.6377 Training Accuracy: 0.908417 Validation Accuracy: 0.809524\n",
      "Epoch 10, Batch  77 -Loss:     0.6730 Training Accuracy: 0.909595 Validation Accuracy: 0.812925\n",
      "Epoch 10, Batch  78 -Loss:     0.7102 Training Accuracy: 0.922555 Validation Accuracy: 0.835147\n",
      "Epoch 10, Batch  79 -Loss:     0.7131 Training Accuracy: 0.930946 Validation Accuracy: 0.847392\n",
      "Epoch 10, Batch  80 -Loss:     0.7017 Training Accuracy: 0.924164 Validation Accuracy: 0.841270\n",
      "Epoch 10, Batch  81 -Loss:     0.6279 Training Accuracy: 0.915658 Validation Accuracy: 0.836735\n",
      "Epoch 10, Batch  82 -Loss:     0.7130 Training Accuracy: 0.921320 Validation Accuracy: 0.836735\n",
      "Epoch 10, Batch  83 -Loss:     0.6839 Training Accuracy: 0.923417 Validation Accuracy: 0.838549\n",
      "Epoch 10, Batch  84 -Loss:     0.6812 Training Accuracy: 0.922124 Validation Accuracy: 0.832426\n",
      "Epoch 10, Batch  85 -Loss:     0.6420 Training Accuracy: 0.916463 Validation Accuracy: 0.824943\n",
      "Epoch 10, Batch  86 -Loss:     0.6293 Training Accuracy: 0.923733 Validation Accuracy: 0.833560\n",
      "Epoch 10, Batch  87 -Loss:     0.6711 Training Accuracy: 0.933418 Validation Accuracy: 0.843764\n",
      "Epoch 10, Batch  88 -Loss:     0.6362 Training Accuracy: 0.930803 Validation Accuracy: 0.838095\n",
      "Epoch 10, Batch  89 -Loss:     0.7381 Training Accuracy: 0.922584 Validation Accuracy: 0.825850\n",
      "Epoch 10, Batch  90 -Loss:     0.6269 Training Accuracy: 0.913934 Validation Accuracy: 0.818367\n",
      "Epoch 10, Batch  91 -Loss:     0.6410 Training Accuracy: 0.916923 Validation Accuracy: 0.824943\n",
      "Epoch 10, Batch  92 -Loss:     0.5869 Training Accuracy: 0.924883 Validation Accuracy: 0.834694\n",
      "Epoch 10, Batch  93 -Loss:     0.6614 Training Accuracy: 0.925946 Validation Accuracy: 0.839683\n",
      "Epoch 10, Batch  94 -Loss:     0.7059 Training Accuracy: 0.913187 Validation Accuracy: 0.825624\n",
      "Epoch 10, Batch  95 -Loss:     0.6264 Training Accuracy: 0.898100 Validation Accuracy: 0.811791\n",
      "Epoch 10, Batch  96 -Loss:     0.5642 Training Accuracy: 0.898790 Validation Accuracy: 0.816100\n",
      "Epoch 10, Batch  97 -Loss:     0.6135 Training Accuracy: 0.927498 Validation Accuracy: 0.842404\n",
      "Epoch 10, Batch  98 -Loss:     0.7502 Training Accuracy: 0.932929 Validation Accuracy: 0.852608\n",
      "Epoch 10, Batch  99 -Loss:     0.5778 Training Accuracy: 0.917871 Validation Accuracy: 0.839909\n",
      "Epoch 10, Batch 100 -Loss:     0.6605 Training Accuracy: 0.922153 Validation Accuracy: 0.845125\n",
      "Epoch 10, Batch 101 -Loss:     0.6540 Training Accuracy: 0.924222 Validation Accuracy: 0.854422\n",
      "Epoch 10, Batch 102 -Loss:     0.6827 Training Accuracy: 0.911348 Validation Accuracy: 0.846259\n",
      "Epoch 10, Batch 103 -Loss:     0.7331 Training Accuracy: 0.901290 Validation Accuracy: 0.828571\n",
      "Epoch 10, Batch 104 -Loss:     0.5727 Training Accuracy: 0.907095 Validation Accuracy: 0.829705\n",
      "Epoch 10, Batch 105 -Loss:     0.6174 Training Accuracy: 0.920802 Validation Accuracy: 0.847392\n",
      "Epoch 10, Batch 106 -Loss:     0.7356 Training Accuracy: 0.928877 Validation Accuracy: 0.857143\n",
      "Epoch 10, Batch 107 -Loss:     0.7646 Training Accuracy: 0.920659 Validation Accuracy: 0.851474\n",
      "Epoch 10, Batch 108 -Loss:     0.6430 Training Accuracy: 0.911032 Validation Accuracy: 0.844898\n",
      "Epoch 10, Batch 109 -Loss:     0.6050 Training Accuracy: 0.920802 Validation Accuracy: 0.858050\n",
      "Epoch 10, Batch 110 -Loss:     0.6416 Training Accuracy: 0.931061 Validation Accuracy: 0.863039\n",
      "Epoch 10, Batch 111 -Loss:     0.5672 Training Accuracy: 0.926348 Validation Accuracy: 0.852834\n",
      "Epoch 10, Batch 112 -Loss:     0.6321 Training Accuracy: 0.916463 Validation Accuracy: 0.837642\n",
      "Epoch 10, Batch 113 -Loss:     0.5849 Training Accuracy: 0.913302 Validation Accuracy: 0.834240\n",
      "Epoch 10, Batch 114 -Loss:     0.7905 Training Accuracy: 0.924136 Validation Accuracy: 0.843764\n",
      "Epoch 10, Batch 115 -Loss:     0.6353 Training Accuracy: 0.932412 Validation Accuracy: 0.850340\n",
      "Epoch 10, Batch 116 -Loss:     0.6623 Training Accuracy: 0.928935 Validation Accuracy: 0.848980\n",
      "Epoch 10, Batch 117 -Loss:     0.6434 Training Accuracy: 0.924481 Validation Accuracy: 0.841497\n",
      "Epoch 10, Batch 118 -Loss:     0.6365 Training Accuracy: 0.918733 Validation Accuracy: 0.839229\n",
      "Epoch 10, Batch 119 -Loss:     0.6226 Training Accuracy: 0.923130 Validation Accuracy: 0.843991\n",
      "Epoch 10, Batch 120 -Loss:     0.6421 Training Accuracy: 0.922900 Validation Accuracy: 0.835147\n",
      "Epoch 10, Batch 121 -Loss:     0.6193 Training Accuracy: 0.922354 Validation Accuracy: 0.831066\n",
      "Epoch 10, Batch 122 -Loss:     0.6921 Training Accuracy: 0.923935 Validation Accuracy: 0.831746\n",
      "Epoch 10, Batch 123 -Loss:     0.7606 Training Accuracy: 0.918274 Validation Accuracy: 0.833333\n",
      "Epoch 10, Batch 124 -Loss:     0.6575 Training Accuracy: 0.923360 Validation Accuracy: 0.836961\n",
      "Epoch 10, Batch 125 -Loss:     0.6594 Training Accuracy: 0.930343 Validation Accuracy: 0.844218\n",
      "Epoch 10, Batch 126 -Loss:     0.6443 Training Accuracy: 0.937240 Validation Accuracy: 0.856236\n",
      "Epoch 10, Batch 127 -Loss:     0.6222 Training Accuracy: 0.935573 Validation Accuracy: 0.857596\n",
      "Epoch 10, Batch 128 -Loss:     0.6808 Training Accuracy: 0.931550 Validation Accuracy: 0.852834\n",
      "Epoch 10, Batch 129 -Loss:     0.7083 Training Accuracy: 0.934079 Validation Accuracy: 0.850567\n",
      "Epoch 10, Batch 130 -Loss:     0.6252 Training Accuracy: 0.926521 Validation Accuracy: 0.844898\n",
      "Epoch 10, Batch 131 -Loss:     0.6735 Training Accuracy: 0.915544 Validation Accuracy: 0.839683\n",
      "Epoch 10, Batch 132 -Loss:     0.6712 Training Accuracy: 0.911061 Validation Accuracy: 0.836508\n",
      "Epoch 10, Batch 133 -Loss:     0.7336 Training Accuracy: 0.915917 Validation Accuracy: 0.836961\n",
      "Epoch 10, Batch 134 -Loss:     0.6813 Training Accuracy: 0.921348 Validation Accuracy: 0.842177\n",
      "Epoch 10, Batch 135 -Loss:     0.7163 Training Accuracy: 0.927182 Validation Accuracy: 0.846712\n",
      "Epoch 10, Batch 136 -Loss:     0.5582 Training Accuracy: 0.926377 Validation Accuracy: 0.843991\n",
      "Epoch 10, Batch 137 -Loss:     0.6419 Training Accuracy: 0.908589 Validation Accuracy: 0.815419\n",
      "Epoch 10, Batch 138 -Loss:     0.7880 Training Accuracy: 0.902210 Validation Accuracy: 0.811565\n",
      "Epoch 10, Batch 139 -Loss:     0.6262 Training Accuracy: 0.913791 Validation Accuracy: 0.823583\n",
      "Epoch 10, Batch 140 -Loss:     0.6512 Training Accuracy: 0.928791 Validation Accuracy: 0.844898\n",
      "Epoch 10, Batch 141 -Loss:     0.6276 Training Accuracy: 0.934337 Validation Accuracy: 0.843991\n",
      "Epoch 10, Batch 142 -Loss:     0.6690 Training Accuracy: 0.928073 Validation Accuracy: 0.838095\n",
      "Epoch 10, Batch 143 -Loss:     0.6656 Training Accuracy: 0.927383 Validation Accuracy: 0.837642\n",
      "Epoch 10, Batch 144 -Loss:     0.7627 Training Accuracy: 0.936895 Validation Accuracy: 0.848526\n",
      "Epoch 10, Batch 145 -Loss:     0.6864 Training Accuracy: 0.932584 Validation Accuracy: 0.854195\n",
      "Epoch 10, Batch 146 -Loss:     0.7633 Training Accuracy: 0.924164 Validation Accuracy: 0.853061\n",
      "Epoch 10, Batch 147 -Loss:     0.6391 Training Accuracy: 0.924509 Validation Accuracy: 0.853968\n",
      "Epoch 10, Batch 148 -Loss:     0.7568 Training Accuracy: 0.935429 Validation Accuracy: 0.856236\n",
      "Epoch 10, Batch 149 -Loss:     0.7201 Training Accuracy: 0.933073 Validation Accuracy: 0.844218\n",
      "Epoch 10, Batch 150 -Loss:     0.6917 Training Accuracy: 0.922354 Validation Accuracy: 0.824490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 151 -Loss:     0.6812 Training Accuracy: 0.920486 Validation Accuracy: 0.815873\n",
      "Epoch 10, Batch 152 -Loss:     0.7795 Training Accuracy: 0.928619 Validation Accuracy: 0.821542\n",
      "Epoch 10, Batch 153 -Loss:     0.6746 Training Accuracy: 0.930429 Validation Accuracy: 0.831973\n",
      "Epoch 10, Batch 154 -Loss:     0.6147 Training Accuracy: 0.926521 Validation Accuracy: 0.840590\n",
      "Epoch 10, Batch 155 -Loss:     0.7507 Training Accuracy: 0.934193 Validation Accuracy: 0.851247\n",
      "Epoch 10, Batch 156 -Loss:     0.6234 Training Accuracy: 0.940630 Validation Accuracy: 0.860998\n",
      "Epoch 10, Batch 157 -Loss:     0.7484 Training Accuracy: 0.939021 Validation Accuracy: 0.863492\n",
      "Epoch 10, Batch 158 -Loss:     0.7687 Training Accuracy: 0.925256 Validation Accuracy: 0.856463\n",
      "Epoch 10, Batch 159 -Loss:     0.6937 Training Accuracy: 0.914739 Validation Accuracy: 0.841723\n",
      "Epoch 10, Batch 160 -Loss:     0.6914 Training Accuracy: 0.916118 Validation Accuracy: 0.841950\n",
      "Epoch 10, Batch 161 -Loss:     0.5966 Training Accuracy: 0.922871 Validation Accuracy: 0.842857\n",
      "Epoch 10, Batch 162 -Loss:     0.6780 Training Accuracy: 0.935918 Validation Accuracy: 0.850340\n",
      "Epoch 10, Batch 163 -Loss:     0.5965 Training Accuracy: 0.940056 Validation Accuracy: 0.850113\n",
      "Epoch 10, Batch 164 -Loss:     0.5779 Training Accuracy: 0.940544 Validation Accuracy: 0.849206\n",
      "Epoch 10, Batch 165 -Loss:     0.7166 Training Accuracy: 0.938245 Validation Accuracy: 0.842177\n",
      "Epoch 10, Batch 166 -Loss:     0.6343 Training Accuracy: 0.933216 Validation Accuracy: 0.835828\n",
      "Epoch 10, Batch 167 -Loss:     0.6316 Training Accuracy: 0.931837 Validation Accuracy: 0.830159\n",
      "Epoch 10, Batch 168 -Loss:     0.7163 Training Accuracy: 0.930170 Validation Accuracy: 0.830612\n",
      "Epoch 10, Batch 169 -Loss:     0.6469 Training Accuracy: 0.937211 Validation Accuracy: 0.840590\n",
      "Epoch 10, Batch 170 -Loss:     0.6846 Training Accuracy: 0.934625 Validation Accuracy: 0.852834\n",
      "Epoch 10, Batch 171 -Loss:     0.6147 Training Accuracy: 0.927814 Validation Accuracy: 0.853061\n",
      "Epoch 10, Batch 172 -Loss:     0.6706 Training Accuracy: 0.925199 Validation Accuracy: 0.853515\n",
      "Epoch 10, Batch 173 -Loss:     0.5683 Training Accuracy: 0.930458 Validation Accuracy: 0.852154\n",
      "Epoch 10, Batch 174 -Loss:     0.6028 Training Accuracy: 0.938475 Validation Accuracy: 0.849206\n",
      "Epoch 10, Batch 175 -Loss:     0.5419 Training Accuracy: 0.929624 Validation Accuracy: 0.839683\n",
      "Epoch 10, Batch 176 -Loss:     0.7404 Training Accuracy: 0.925917 Validation Accuracy: 0.830386\n",
      "Epoch 10, Batch 177 -Loss:     0.6717 Training Accuracy: 0.925687 Validation Accuracy: 0.834014\n",
      "Epoch 10, Batch 178 -Loss:     0.7553 Training Accuracy: 0.934510 Validation Accuracy: 0.845805\n",
      "Epoch 10, Batch 179 -Loss:     0.6175 Training Accuracy: 0.939510 Validation Accuracy: 0.851474\n",
      "Epoch 10, Batch 180 -Loss:     0.6436 Training Accuracy: 0.931492 Validation Accuracy: 0.854875\n",
      "Epoch 10, Batch 181 -Loss:     0.7250 Training Accuracy: 0.913503 Validation Accuracy: 0.841270\n",
      "Epoch 10, Batch 182 -Loss:     0.6814 Training Accuracy: 0.917296 Validation Accuracy: 0.842177\n",
      "Epoch 10, Batch 183 -Loss:     0.6126 Training Accuracy: 0.930946 Validation Accuracy: 0.855556\n",
      "Epoch 10, Batch 184 -Loss:     0.6023 Training Accuracy: 0.934079 Validation Accuracy: 0.844898\n",
      "Epoch 10, Batch 185 -Loss:     0.6738 Training Accuracy: 0.923360 Validation Accuracy: 0.830839\n",
      "Epoch 10, Batch 186 -Loss:     0.7064 Training Accuracy: 0.913934 Validation Accuracy: 0.817007\n",
      "Epoch 10, Batch 187 -Loss:     0.6678 Training Accuracy: 0.924107 Validation Accuracy: 0.824943\n",
      "Epoch 10, Batch 188 -Loss:     0.7255 Training Accuracy: 0.931234 Validation Accuracy: 0.839456\n",
      "Epoch 10, Batch 189 -Loss:     0.6337 Training Accuracy: 0.930343 Validation Accuracy: 0.848526\n",
      "Epoch 10, Batch 190 -Loss:     0.6215 Training Accuracy: 0.928762 Validation Accuracy: 0.852381\n",
      "Epoch 10, Batch 191 -Loss:     0.7346 Training Accuracy: 0.931751 Validation Accuracy: 0.858277\n",
      "Epoch 10, Batch 192 -Loss:     0.6126 Training Accuracy: 0.931866 Validation Accuracy: 0.855556\n",
      "Epoch 10, Batch 193 -Loss:     0.6819 Training Accuracy: 0.928849 Validation Accuracy: 0.852834\n",
      "Epoch 10, Batch 194 -Loss:     0.6197 Training Accuracy: 0.927986 Validation Accuracy: 0.843084\n",
      "Epoch 10, Batch 195 -Loss:     0.6771 Training Accuracy: 0.926032 Validation Accuracy: 0.840363\n",
      "Epoch 10, Batch 196 -Loss:     0.6104 Training Accuracy: 0.929509 Validation Accuracy: 0.842857\n",
      "Epoch 10, Batch 197 -Loss:     0.6292 Training Accuracy: 0.931636 Validation Accuracy: 0.846712\n",
      "Epoch 10, Batch 198 -Loss:     0.7070 Training Accuracy: 0.926061 Validation Accuracy: 0.843311\n",
      "Epoch 10, Batch 199 -Loss:     0.7438 Training Accuracy: 0.922182 Validation Accuracy: 0.841723\n",
      "Epoch 10, Batch 200 -Loss:     0.6093 Training Accuracy: 0.924509 Validation Accuracy: 0.842630\n",
      "Epoch 10, Batch 201 -Loss:     0.6611 Training Accuracy: 0.930170 Validation Accuracy: 0.849660\n",
      "Epoch 10, Batch 202 -Loss:     0.6119 Training Accuracy: 0.931607 Validation Accuracy: 0.853288\n",
      "Epoch 10, Batch 203 -Loss:     0.6786 Training Accuracy: 0.930458 Validation Accuracy: 0.847846\n",
      "Epoch 10, Batch 204 -Loss:     0.6529 Training Accuracy: 0.933102 Validation Accuracy: 0.847392\n",
      "Epoch 10, Batch 205 -Loss:     0.7236 Training Accuracy: 0.935889 Validation Accuracy: 0.849206\n",
      "Epoch 10, Batch 206 -Loss:     0.6677 Training Accuracy: 0.939682 Validation Accuracy: 0.858050\n",
      "Epoch 10, Batch 207 -Loss:     0.6680 Training Accuracy: 0.940975 Validation Accuracy: 0.863946\n",
      "Epoch 10, Batch 208 -Loss:     0.6546 Training Accuracy: 0.942585 Validation Accuracy: 0.866667\n",
      "Epoch 10, Batch 209 -Loss:     0.6881 Training Accuracy: 0.934423 Validation Accuracy: 0.862132\n",
      "Epoch 10, Batch 210 -Loss:     0.6672 Training Accuracy: 0.920687 Validation Accuracy: 0.846712\n",
      "Epoch 10, Batch 211 -Loss:     0.7354 Training Accuracy: 0.923647 Validation Accuracy: 0.847166\n",
      "Epoch 10, Batch 212 -Loss:     0.6024 Training Accuracy: 0.931291 Validation Accuracy: 0.846259\n",
      "Epoch 10, Batch 213 -Loss:     0.6133 Training Accuracy: 0.935688 Validation Accuracy: 0.845351\n",
      "Epoch 10, Batch 214 -Loss:     0.6690 Training Accuracy: 0.921837 Validation Accuracy: 0.832880\n",
      "Epoch 10, Batch 215 -Loss:     0.5812 Training Accuracy: 0.901290 Validation Accuracy: 0.820862\n",
      "Epoch 10, Batch 216 -Loss:     0.6780 Training Accuracy: 0.919107 Validation Accuracy: 0.825170\n",
      "Epoch 10, Batch 217 -Loss:     0.7067 Training Accuracy: 0.930544 Validation Accuracy: 0.834014\n",
      "Epoch 10, Batch 218 -Loss:     0.6379 Training Accuracy: 0.922843 Validation Accuracy: 0.826077\n",
      "Epoch 10, Batch 219 -Loss:     0.7140 Training Accuracy: 0.914911 Validation Accuracy: 0.817460\n",
      "Epoch 10, Batch 220 -Loss:     0.5966 Training Accuracy: 0.915515 Validation Accuracy: 0.817460\n",
      "Epoch 10, Batch 221 -Loss:     0.6017 Training Accuracy: 0.923791 Validation Accuracy: 0.824943\n",
      "Epoch 10, Batch 222 -Loss:     0.7090 Training Accuracy: 0.933389 Validation Accuracy: 0.839002\n",
      "Epoch 10, Batch 223 -Loss:     0.6448 Training Accuracy: 0.925084 Validation Accuracy: 0.839456\n",
      "Epoch 10, Batch 224 -Loss:     0.5340 Training Accuracy: 0.905773 Validation Accuracy: 0.826531\n",
      "Epoch 10, Batch 225 -Loss:     0.7466 Training Accuracy: 0.905572 Validation Accuracy: 0.824036\n",
      "Epoch 10, Batch 226 -Loss:     0.6239 Training Accuracy: 0.920457 Validation Accuracy: 0.840590\n",
      "Epoch 10, Batch 227 -Loss:     0.7650 Training Accuracy: 0.933102 Validation Accuracy: 0.855102\n",
      "Epoch 10, Batch 228 -Loss:     0.7308 Training Accuracy: 0.937556 Validation Accuracy: 0.860317\n",
      "Epoch 10, Batch 229 -Loss:     0.6665 Training Accuracy: 0.937901 Validation Accuracy: 0.860998\n",
      "Epoch 10, Batch 230 -Loss:     0.6002 Training Accuracy: 0.933303 Validation Accuracy: 0.852381\n",
      "Epoch 10, Batch 231 -Loss:     0.6146 Training Accuracy: 0.930630 Validation Accuracy: 0.839683\n",
      "Epoch 10, Batch 232 -Loss:     0.6512 Training Accuracy: 0.929452 Validation Accuracy: 0.839456\n",
      "Epoch 10, Batch 233 -Loss:     0.6174 Training Accuracy: 0.923705 Validation Accuracy: 0.833787\n",
      "Epoch 10, Batch 234 -Loss:     0.6181 Training Accuracy: 0.916837 Validation Accuracy: 0.829025\n",
      "Epoch 10, Batch 235 -Loss:     0.6771 Training Accuracy: 0.921894 Validation Accuracy: 0.838549\n",
      "Epoch 10, Batch 236 -Loss:     0.5457 Training Accuracy: 0.933791 Validation Accuracy: 0.854422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 237 -Loss:     0.6317 Training Accuracy: 0.935544 Validation Accuracy: 0.858503\n",
      "Epoch 10, Batch 238 -Loss:     0.6687 Training Accuracy: 0.933331 Validation Accuracy: 0.858957\n",
      "Epoch 10, Batch 239 -Loss:     0.5930 Training Accuracy: 0.931377 Validation Accuracy: 0.858277\n",
      "Epoch 10, Batch 240 -Loss:     0.6617 Training Accuracy: 0.934222 Validation Accuracy: 0.865986\n",
      "Epoch 10, Batch 241 -Loss:     0.5775 Training Accuracy: 0.939079 Validation Accuracy: 0.876871\n",
      "Epoch 10, Batch 242 -Loss:     0.6745 Training Accuracy: 0.935314 Validation Accuracy: 0.874376\n",
      "Epoch 10, Batch 243 -Loss:     0.6473 Training Accuracy: 0.928159 Validation Accuracy: 0.867800\n",
      "Epoch 10, Batch 244 -Loss:     0.8079 Training Accuracy: 0.934538 Validation Accuracy: 0.873469\n",
      "Epoch 10, Batch 245 -Loss:     0.5528 Training Accuracy: 0.937642 Validation Accuracy: 0.872562\n",
      "Epoch 10, Batch 246 -Loss:     0.5547 Training Accuracy: 0.936061 Validation Accuracy: 0.864399\n",
      "Epoch 10, Batch 247 -Loss:     0.5828 Training Accuracy: 0.934854 Validation Accuracy: 0.860317\n",
      "Epoch 10, Batch 248 -Loss:     0.6214 Training Accuracy: 0.937498 Validation Accuracy: 0.862132\n",
      "Epoch 10, Batch 249 -Loss:     0.5986 Training Accuracy: 0.937010 Validation Accuracy: 0.856236\n",
      "Epoch 10, Batch 250 -Loss:     0.6510 Training Accuracy: 0.937958 Validation Accuracy: 0.857596\n",
      "Epoch 10, Batch 251 -Loss:     0.6594 Training Accuracy: 0.939912 Validation Accuracy: 0.858277\n",
      "Epoch 10, Batch 252 -Loss:     0.6093 Training Accuracy: 0.937642 Validation Accuracy: 0.854195\n",
      "Epoch 10, Batch 253 -Loss:     0.5974 Training Accuracy: 0.930659 Validation Accuracy: 0.847846\n",
      "Epoch 10, Batch 254 -Loss:     0.6163 Training Accuracy: 0.926894 Validation Accuracy: 0.842630\n",
      "Epoch 10, Batch 255 -Loss:     0.6377 Training Accuracy: 0.925860 Validation Accuracy: 0.841950\n",
      "Epoch 10, Batch 256 -Loss:     0.6770 Training Accuracy: 0.925860 Validation Accuracy: 0.844671\n",
      "Epoch 10, Batch 257 -Loss:     0.6414 Training Accuracy: 0.917641 Validation Accuracy: 0.830612\n",
      "Epoch 10, Batch 258 -Loss:     0.5638 Training Accuracy: 0.907210 Validation Accuracy: 0.819048\n",
      "Epoch 10, Batch 259 -Loss:     0.6759 Training Accuracy: 0.920572 Validation Accuracy: 0.823583\n",
      "Epoch 10, Batch 260 -Loss:     0.7584 Training Accuracy: 0.934941 Validation Accuracy: 0.843084\n",
      "Epoch 10, Batch 261 -Loss:     0.5571 Training Accuracy: 0.940113 Validation Accuracy: 0.851927\n",
      "Epoch 10, Batch 262 -Loss:     0.6084 Training Accuracy: 0.930659 Validation Accuracy: 0.848526\n",
      "Epoch 10, Batch 263 -Loss:     0.6523 Training Accuracy: 0.933906 Validation Accuracy: 0.852834\n",
      "Epoch 10, Batch 264 -Loss:     0.5210 Training Accuracy: 0.933475 Validation Accuracy: 0.858277\n",
      "Epoch 10, Batch 265 -Loss:     0.5736 Training Accuracy: 0.916549 Validation Accuracy: 0.843764\n",
      "Epoch 10, Batch 266 -Loss:     0.7054 Training Accuracy: 0.918676 Validation Accuracy: 0.847166\n",
      "Epoch 10, Batch 267 -Loss:     0.6013 Training Accuracy: 0.927958 Validation Accuracy: 0.849206\n",
      "Epoch 10, Batch 268 -Loss:     0.7859 Training Accuracy: 0.928446 Validation Accuracy: 0.848073\n",
      "Epoch 10, Batch 269 -Loss:     0.7493 Training Accuracy: 0.929567 Validation Accuracy: 0.840590\n",
      "Epoch 10, Batch 270 -Loss:     0.7892 Training Accuracy: 0.935286 Validation Accuracy: 0.845351\n",
      "Epoch 10, Batch 271 -Loss:     0.6224 Training Accuracy: 0.938303 Validation Accuracy: 0.851020\n",
      "Epoch 10, Batch 272 -Loss:     0.6926 Training Accuracy: 0.935975 Validation Accuracy: 0.846939\n",
      "Model saved\n",
      "Training Accuracy =  0.9359752\n",
      "Validation Accuracy =  0.8469388\n",
      "Loss =  0.69257987\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for epoch in range(epochs):\n",
    "        Xtrain, ytrain = shuffle(train_features, train_labels)\n",
    "        batch_count = 0\n",
    "        for offset in range(0, num_examples, batch_size):\n",
    "            batch_count += 1\n",
    "            end = offset + batch_size\n",
    "            batch_x, batch_y = Xtrain[offset:end], ytrain[offset:end]\n",
    "            \n",
    "            sess.run(training_operation, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: 0.5})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: 1.})\n",
    "            \n",
    "            train_acc = sess.run(accuracy_operation, feed_dict={\n",
    "                x: train_features,\n",
    "                y: train_labels,\n",
    "                keep_prob: 1.})\n",
    "            \n",
    "            valid_acc = sess.run(accuracy_operation, feed_dict={\n",
    "                x: valid_features,\n",
    "                y: valid_labels,\n",
    "                keep_prob: 1.})\n",
    "            #total_accuracy += (accuracy * len(batch_x))\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} -'\n",
    "                  'Loss: {:>10.4f} Training Accuracy: {:.6f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch_count,\n",
    "                loss,\n",
    "                train_acc,\n",
    "                valid_acc))\n",
    "            \n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")\n",
    "    print(\"Training Accuracy = \", train_acc)\n",
    "    print(\"Validation Accuracy = \", valid_acc)\n",
    "    print(\"Loss = \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Testing Accuracy: 0.847585141658783\n"
     ]
    }
   ],
   "source": [
    "# Calculate Test Accuracy\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    test_acc = sess.run(accuracy_operation, feed_dict={\n",
    "        x: test_features,\n",
    "        y: test_labels,\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "To give yourself more insight into how your model is working, download at least five pictures of German traffic signs from the web and use your model to predict the traffic sign type.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load new Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "import os, os.path\n",
    "from PIL import Image\n",
    "\n",
    "imgs = []\n",
    "path = './test-data/'\n",
    "valid_images = [\".jpg\",\".png\"]\n",
    "for filename in os.listdir(path):\n",
    "    ext = os.path.splitext(filename)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    imgs.append(np.asarray(Image.open(os.path.join(path,filename)).resize((32,32))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 3), (32, 32, 3), (32, 32, 3), (32, 32, 3), (32, 32, 3))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0].shape,imgs[1].shape,imgs[2].shape,imgs[3].shape,imgs[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('signnames.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    sign_labels = {}\n",
    "    for row in reader:\n",
    "        sign_index, sign_name = row\n",
    "        sign_labels[sign_index] = sign_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No entry', 'Road work', 'Speed limit (30km/h)', 'Stop', 'Yield']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_labels = [17, 25, 1, 14, 13] \n",
    "imgs_labels = [sign_labels[str(label)] for label in imgs_labels]\n",
    "imgs_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAADjCAYAAABzceSEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQwghhBBCCCGEEAXP/wer2mKb76DragAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23881c14ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the images\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 5]\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    plt.subplot(1, len(imgs), i+1)\n",
    "    plt.imshow(imgs[i])\n",
    "    plt.title(imgs_labels[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape and preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reshape\n",
    "imgs_pre = rgb2gray(np.array(imgs))\n",
    "imgs_pre = normalize_grayscale(imgs_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAADjCAYAAABzceSEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEOSJEmSJHXvF57TOGww09pwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2388855cda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the images\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 5]\n",
    "\n",
    "for i in range(len(imgs_pre)):\n",
    "    plt.subplot(1, len(imgs_pre), i+1)\n",
    "    plt.imshow(imgs_pre[i].reshape(32,32), cmap=\"gray\")\n",
    "    plt.title('Image: %d' % i)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n"
     ]
    }
   ],
   "source": [
    "### Run the predictions here and use the model to output the prediction for each image.\n",
    "### Make sure to pre-process the images with the same pre-processing pipeline used earlier.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    result_logits = sess.run(logits, feed_dict={x: np.array(imgs_pre), keep_prob : 1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the new images, print out the model's softmax probabilities to show the **certainty** of the model's predictions (limit the output to the top 5 probabilities for each image). [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#top_k) could prove helpful here. \n",
    "\n",
    "The example below demonstrates how tf.nn.top_k can be used to find the top k predictions for each image.\n",
    "\n",
    "`tf.nn.top_k` will return the values and indices (class ids) of the top k predictions. So if k=3, for each sign, it'll return the 3 largest probabilities (out of a possible 43) and the correspoding class ids.\n",
    "\n",
    "Take this numpy array as an example. The values in the array represent predictions. The array contains softmax probabilities for five candidate images with six possible classes. `tf.nn.top_k` is used to choose the three classes with the highest probability:\n",
    "\n",
    "```\n",
    "# (5, 6) array\n",
    "a = np.array([[ 0.24879643,  0.07032244,  0.12641572,  0.34763842,  0.07893497,\n",
    "         0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.08594638,  0.0178669 ,  0.18063401,\n",
    "         0.15899337],\n",
    "       [ 0.26076848,  0.23664738,  0.08020603,  0.07001922,  0.1134371 ,\n",
    "         0.23892179],\n",
    "       [ 0.11943333,  0.29198961,  0.02605103,  0.26234032,  0.1351348 ,\n",
    "         0.16505091],\n",
    "       [ 0.09561176,  0.34396535,  0.0643941 ,  0.16240774,  0.24206137,\n",
    "         0.09155967]])\n",
    "```\n",
    "\n",
    "Running it through `sess.run(tf.nn.top_k(tf.constant(a), k=3))` produces:\n",
    "\n",
    "```\n",
    "TopKV2(values=array([[ 0.34763842,  0.24879643,  0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.18063401],\n",
    "       [ 0.26076848,  0.23892179,  0.23664738],\n",
    "       [ 0.29198961,  0.26234032,  0.16505091],\n",
    "       [ 0.34396535,  0.24206137,  0.16240774]]), indices=array([[3, 0, 5],\n",
    "       [0, 1, 4],\n",
    "       [0, 5, 1],\n",
    "       [1, 3, 5],\n",
    "       [1, 4, 3]], dtype=int32))\n",
    "```\n",
    "\n",
    "Looking just at the first row we get `[ 0.34763842,  0.24879643,  0.12789202]`, you can confirm these are the 3 largest probabilities in `a`. You'll also notice `[3, 0, 5]` are the corresponding indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 43)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0 probabilities: [0.72783166 0.20286584 0.02022686 0.0132523  0.00938945] \n",
      " and predicted classes: [13 15  9 36 14]\n",
      "Predicted labels: [ Yield , No vehicles , No passing , Go straight or right , Stop ]\n",
      "Image 1 probabilities: [9.9711812e-01 5.7670800e-04 5.6804379e-04 4.6697137e-04 3.4418423e-04] \n",
      " and predicted classes: [25 29 33  9 19]\n",
      "Predicted labels: [ Road work , Bicycles crossing , Turn right ahead , No passing , Dangerous curve to the left ]\n",
      "Image 2 probabilities: [0.66351396 0.21605551 0.09717923 0.0081927  0.00712923] \n",
      " and predicted classes: [ 1  2 40 31  0]\n",
      "Predicted labels: [ Speed limit (30km/h) , Speed limit (50km/h) , Roundabout mandatory , Wild animals crossing , Speed limit (20km/h) ]\n",
      "Image 3 probabilities: [0.9488917  0.01577515 0.01502223 0.00495115 0.00298798] \n",
      " and predicted classes: [ 9 12 33 19 10]\n",
      "Predicted labels: [ No passing , Priority road , Turn right ahead , Dangerous curve to the left , No passing for vehicles over 3.5 metric tons ]\n",
      "Image 4 probabilities: [9.763327e-01 8.665003e-03 7.841111e-03 5.444173e-03 8.814716e-04] \n",
      " and predicted classes: [13  9 17 12 14]\n",
      "Predicted labels: [ Yield , No passing , No entry , Priority road , Stop ]\n"
     ]
    }
   ],
   "source": [
    "### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. \n",
    "### Feel free to use as many code cells as needed.\n",
    "# result_softmax = (5, 43)\n",
    "# result_top_k = (2, 5, 5)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result_softmax = sess.run(tf.nn.softmax(result_logits))\n",
    "    result_top_k = sess.run(tf.nn.top_k(result_softmax , k= 5, sorted=True))\n",
    "\n",
    "result_final = []\n",
    "for i in range(len(imgs)):\n",
    "    print('Image', i, 'probabilities:', result_top_k[0][i], '\\n and predicted classes:', result_top_k[1][i])\n",
    "    result_labels = [sign_labels[str(pred)] for pred in result_top_k[1][i]]\n",
    "    print('Predicted labels: [', result_labels[0], \",\", result_labels[1],\",\", result_labels[2],\",\", result_labels[3],\",\", result_labels[4],\"]\")\n",
    "    result_final.append(result_top_k[1][i][0])\n",
    "    \n",
    "#result_final = [Sign_labelresult_final]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Result:  ['No entry', 'Road work', 'Speed limit (30km/h)', 'Stop', 'Yield']\n",
      "Predicted Result:  ['Yield', 'Road work', 'Speed limit (30km/h)', 'No passing', 'Yield']\n",
      "Accuracy of prediction = % 60.0\n"
     ]
    }
   ],
   "source": [
    "### Calculate the accuracy for these 5 new images. \n",
    "### For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate on these new images.\n",
    "print('Expected Result: ', imgs_labels)\n",
    "result_final_labels = [sign_labels[str(result)] for result in result_final]\n",
    "print('Predicted Result: ', result_final_labels)\n",
    "count = 0\n",
    "for i in range(len(result_final)):\n",
    "    if result_final_labels[i] == imgs_labels[i]:\n",
    "        count = count + 1\n",
    "print(\"Accuracy of prediction = %\", (count/len(imgs_labels))*100)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Writeup\n",
    "\n",
    "Once you have completed the code implementation, document your results in a project writeup using this [template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) as a guide. The writeup can be in a markdown or pdf file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4 (Optional): Visualize the Neural Network's State with Test Images\n",
    "\n",
    " This Section is not required to complete but acts as an additional excersise for understaning the output of a neural network's weights. While neural networks can be a great learning device they are often referred to as a black box. We can understand what the weights of a neural network look like better by plotting their feature maps. After successfully training your neural network you can see what it's feature maps look like by plotting the output of the network's weight layers in response to a test stimuli image. From these plotted feature maps, it's possible to see what characteristics of an image the network finds interesting. For a sign, maybe the inner network feature maps react with high activation to the sign's boundary outline or to the contrast in the sign's painted symbol.\n",
    "\n",
    " Provided for you below is the function code that allows you to get the visualization output of any tensorflow weight layer you want. The inputs to the function should be a stimuli image, one used during training or a new one you provided, and then the tensorflow variable name that represents the layer's state during the training process, for instance if you wanted to see what the [LeNet lab's](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) feature maps looked like for it's second convolutional layer you could enter conv2 as the tf_activation variable.\n",
    "\n",
    "For an example of what feature map outputs look like, check out NVIDIA's results in their paper [End-to-End Deep Learning for Self-Driving Cars](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) in the section Visualization of internal CNN State. NVIDIA was able to show that their network's inner weights had high activations to road boundary lines by comparing feature maps from an image with a clear path to one without. Try experimenting with a similar test to show that your trained network's weights are looking for interesting features, whether it's looking at differences in feature maps from images with or without a sign, or even what feature maps look like in a trained network vs a completely untrained one on the same sign image.\n",
    "\n",
    "<figure>\n",
    " <img src=\"visualize_cnn.png\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output should look something like this (above)</p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Visualize your network's feature maps here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# image_input: the test image being fed into the network to produce the feature maps\n",
    "# tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output\n",
    "# plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it may be having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
